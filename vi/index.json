[{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Nhật Anh\nSố điện thoại: 0934560352\nEmail: lenhatanh2411@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Kỹ thuật phần mềm\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/3-blogstranslated/3.1-blog1/","title":"Bắt đầu với Amazon OpenSearch Service: T-shirt size tên miền của bạn cho phân tích nhật ký","tags":[],"description":"","content":"Ngày đăng: 2025‑09‑16 – Tác giả: Harsh Bansal, Aditya Challa, Raaga N.G trong Amazon OpenSearch Service, Intermediate (200),Technical How-to.\nKhi triển khai một miền Amazon OpenSearch Service, bạn cần xác định kích thước lưu trữ, loại và số lượng instance; quyết định chiến lược phân mảnh (sharding) và có sử dụng cluster manager hay không; đồng thời kích hoạt zone awareness. Nhìn chung, chúng ta xem xét dung lượng lưu trữ như là hướng dẫn để xác định số lượng instance, nhưng không phải các thông số khác. Ở bài viết này, chúng tôi đưa ra một số khuyến nghị dựa theo cách thức T‑shirt‑sizing cho khối lượng công việc phân tích nhật ký.\nĐặc điểm của phân tích nhật ký và khối lượng công việc streaming\nKhi sử dụng OpenSearch Service cho khối lượng công việc streaming, bạn gửi dữ liệu từ một hoặc nhiều nguồn vào OpenSearch Service để tạo chỉ mục do bạn định nghĩa\nDữ liệu nhật ký thường có đặc điểm chuỗi thời gian, do đó chiến lược đánh chỉ mục theo thời gian (chỉ mục theo ngày hoặc theo tuần) được khuyến nghị. Để quản lý nhật ký hiệu quả, bạn cần phải triển khai index patterns theo thời gian và thiết lập thời gian lưu giữ. Bạn cũng cần xác định thêm việc phân chia theo thời gian và thời gian lưu giữ cho dữ liệu để quản lý vòng đời của nó trong miền của mình.\nĐể minh họa, hãy giả sử bạn có một nguồn dữ liệu tạo ra luồng log liên tục và bạn đã cấu hình chỉ mục cuộn hàng ngày với thời gian lưu giữ 3 ngày. Khi log tới, OpenSearch Service sẽ tạo ra một chỉ mục mỗi ngày với các tên như stream1_2025.05.21, stream1_2025.05.22, … Với tiền tố stream1_* được gọi là một index pattern, tức là quy ước đặt tên giúp nhóm các chỉ mục liên quan lại với nhau.\nSơ đồ dưới đây cho thấy có ba primary shard cho mỗi chỉ mục hằng ngày. Các shard này được triển khai trên ba OpenSearch Service data instance, và mỗi primary shard có một replica tương ứng. (Để đơn giản, sơ đồ không minh họa rằng primary và replica shard luôn được đặt trên các instance khác nhau nhằm đảm bảo khả năng chịu lỗi)\nKhi OpenSearch Service xử lý các bản ghi nhật ký mới, chúng được gửi tới tất cả các primary shard liên quan và replica của chúng trong chỉ mục đang hoạt động, trong ví dụ này chỉ là chỉ mục của ngày hôm nay do cấu hình chỉ mục theo ngày.\nCó một số đặc điểm quan trọng về cách Dịch vụ OpenSearch xử lý các mục nhập mới của bạn:\nTổng số shard – Mỗi pattern của chỉ mục có tổng số shard bằng D × P × (1 + R), trong đó D là số ngày lưu giữ, P là số primary shard và R là số replica. Các shard này được phân phối trên các data node. Chỉ mục đang hoạt động – Kỹ thuật time‑slicing nghĩa là các bản ghi log mới chỉ được ghi vào chỉ mục của ngày hiện tại. Sử dụng tài nguyên – Khi gửi một yêu cầu _bulk với các bản ghi log, chúng được phân phối tới tất cả các shard trong chỉ mục đang hoạt động. Ví dụ với ba primary shard và một replica cho mỗi shard chính, tổng cộng có sáu shard xử lý dữ liệu đồng thời, cần 6 vCPU để xử lý hiệu quả một yêu cầu _bulk. Tương tự, OpenSearch Service phân phối truy vấn trên các shard của các chỉ mục liên quan. Nếu bạn truy vấn pattern này trong cả 3 ngày, sẽ có 9 shard tham gia và cần 9 vCPU để xử lý yêu cầu.\nĐiều này sẽ trở nên phức tạp hơn khi bạn bổ sung thêm nhiều data stream và index pattern. Với mỗi data stream hoặc index pattern bổ sung, bạn phải triển khai các shard cho từng chỉ mục hằng ngày và sử dụng vCPU để xử lý yêu cầu tương ứng với số shard được triển khai, như minh họa ở sơ đồ trước. Khi bạn gửi các yêu cầu đồng thời tới nhiều chỉ mục, mỗi shard của tất cả các chỉ mục liên quan đều phải xử lý những yêu cầu đó.\nDung lượng Cluster\nKhi số lượng index pattern và các yêu cầu đồng thời tăng lên, tài nguyên của cụm có thể nhanh chóng bị quá tải. OpenSearch Service bao gồm các hàng đợi nội bộ để đệm yêu cầu và giảm bớt nhu cầu xử lý đồng thời. Bạn có thể giám sát những hàng đợi này bằng API _cat/thread_pool, công cụ cho thấy độ sâu hàng đợi và giúp bạn hiểu khi nào cụm của mình đang tiến gần tới giới hạn dung lượng.\nMột yếu tố phức tạp khác là thời gian xử lý các bản cập nhật và truy vấn phụ thuộc vào nội dung của chúng. Khi yêu cầu đến, hàng đợi sẽ lấp đầy theo tốc độ bạn gửi. Chúng được giải phóng theo tốc độ được quyết định bởi số vCPU, thời gian từng yêu cầu và thời gian xử lý. Bạn có thể xen kẽ nhiều yêu cầu hơn nếu các yêu cầu đó được xử lý trong vài phần nghìn giây so với trong một giây. Bạn có thể sử dụng API _nodes/stats của OpenSearch để giám sát tải trung bình trên CPU. Để biết thêm về các giai đoạn truy vấn, hãy tham khảo bài A query, or There and Back Again trên blog OpenSearch.\nNếu bạn thấy độ sâu hàng đợi tăng lên, nghĩa là bạn đang bước vào “vùng cảnh báo”, nơi cụm vẫn xử lý được tải nhưng đã tới ngưỡng. Nếu tiếp tục, bạn có thể vượt quá các hàng đợi có sẵn và cần mở rộng thêm CPU. Nếu bạn bắt đầu thấy tải tăng, tương quan với độ sâu hàng đợi tăng, thì bạn cũng đang ở trong vùng \u0026ldquo;cảnh báo\u0026rdquo; và nên cân nhắc việc mở rộng quy mô.\nRecommendations Để xác định kích thước một miền, bạn có thể tham khảo các bước sau:\nXác định dung lượng lưu trữ cần thiết – Tổng lưu trữ = (dữ liệu nguồn hàng ngày tính theo byte × 1,45) × (số replica + 1) × số ngày lưu giữ. Hệ số 45 % bổ sung này gồm: 10 % cho việc kích thước chỉ mục lớn hơn dữ liệu gốc.\n5 % cho overhead của hệ điều hành (Linux dành riêng cho khôi phục hệ thống và bảo vệ chống phân mảnh ổ đĩa).\n20 % cho phần không gian dự phòng của OpenSearch trên mỗi instance (gộp segment, log và các thao tác nội bộ).\n10 % cho bộ đệm lưu trữ bổ sung (giảm thiểu ảnh hưởng của lỗi node và sự cố Availability Zone).\nXác định số lượng shard – Số lượng primary shard xấp xỉ bằng kích thước lưu trữ cần cho mỗi chỉ mục chia cho kích thước shard mong muốn. Làm tròn lên bội số gần nhất của số node dữ liệu để phân bố đều. Đối với phân tích nhật ký, lưu ý: Kích thước shard khuyến nghị: 30–50 GB. Mục tiêu tối ưu: 50 GB mỗi shard. Tính toán nhu cầu CPU – Tỷ lệ đề xuất là 1,25 vCPU:1 cho mỗi shard với khối lượng dữ liệu nhỏ. Đối với khối lượng lớn hơn, tỷ lệ cao hơn được khuyến nghị. Mục tiêu sử dụng là trung bình 60 %, tối đa 80 %. Chọn loại instance phù hợp – Dựa trên từng loại node: Cluster manager nodes: Dùng các instance dòng M của AWS Graviton (phù hợp với mọi khối lượng). Data nodes (khối lượng nhỏ đến lớn): Dùng instance dòng M hoặc R của AWS Graviton kết hợp Amazon Elastic Block Store (Amazon EBS). Data nodes (khối lượng rất lớn): Dùng instance dòng I với ổ NVMe SSD. Ví dụ về việc xác định kích thước miền:\nDung lượng log hàng ngày: 3 TB. Thời gian lưu giữ: 3 tháng (90 ngày). Số replica: 1. Chúng ta thực hiện phép tính sau.\nBảng sau đây khuyến nghị loại instance, khối lượng dữ liệu nguồn, dung lượng lưu trữ cần thiết cho 7 ngày lưu giữ, và số lượng active shard dựa trên các hướng dẫn đã nêu:\nT-Shirt Size Data (Per Day) Storage Needed (with 7 days Retention) Active Shards Data Nodes Primary Nodes XSmall 10 GB 175 GB 2 @ 50 GB 3 * r7g.large. search 3 * m7g.large. search Small 100 GB 1.75 TB 6 @ 50 GB 3 * r7g.xlarge. search 3 * m7g.large. search Medium 500 GB 8.75 TB 30 @ 50 GB 6 * r7g.2xlarge.search 3 * m7g.large. search Large 1 TB 17.5 TB 60 @ 50 GB 6 * r7g.4xlarge.search 3 * m7g.large. search XLarge 10 TB 175 TB 600 @ 50 GB 30 * i4g.8xlarge 3 * m7g.2xlarge.search XXL 80 TB 1.4 PB 2400 @ 50 GB 87 * I4g.16xlarge 3 * m7g.4xlarge.search Như với mọi khuyến nghị về sizing, các hướng dẫn này chỉ là điểm khởi đầu và được xây dựng dựa trên giả định. Khối lượng công việc (workload) của bạn sẽ khác, do đó nhu cầu thực tế của bạn cũng sẽ khác với các khuyến nghị này. Hãy đảm bảo rằng bạn triển khai, giám sát và điều chỉnh cấu hình khi cần.\nĐối với T-shirt sizing workload, trường hợp extra-small bao gồm tối đa 10 GB dữ liệu mỗi ngày từ một data stream duy nhất tới một index pattern duy nhất. Trường hợp small nằm trong khoảng 10–100 GB dữ liệu mỗi ngày. Trường hợp medium nằm trong khoảng 100–500 GB dữ liệu mỗi ngày, và tiếp tục tăng theo các mức lớn hơn. Số lượng instance mặc định cho mỗi domain là 80 đối với hầu hết các dòng instance. Tham khảo thêm chi tiết trong mục “Amazon OpenSearch Service quotas “.\nNgoài ra, hãy cân nhắc những biện pháp tốt nhất sau::\nChọn đúng tầng lưu trữ (Ultra Warm, Hot storage) phù hợp với nhu cầu trong OpenSearch Service. Tham khảo mục Choose the right storage tier for your needs in Amazon OpenSearch Service để biết chi tiết.\nSử dụng dòng OpenSearch Optimized (OR) cho các workload quy mô lớn cần độ trễ thấp với các tác vụ nặng về indexing. Tham khảo bài OpenSearch optimized instance (OR1) is game changing for indexing performance and cost để biết chi tiết. Cô lập việc ingest bằng cách sử dụng OpenSearch Ingestion pipeline cho các workload từ nhỏ đến lớn để giảm bớt gánh nặng vận hành khi quản lý pipeline ingestion. Sử dụng reserved instance để tiết kiệm chi phí dài hạn. Cân nhắc sử dụng Availability Zone awareness để đảm bảo tính sẵn sàng cao. Kết luận\nBài viết này đã cung cấp các hướng dẫn toàn diện về việc xác định kích thước miền OpenSearch Service cho workload phân tích log, bao quát nhiều khía cạnh quan trọng. Những khuyến nghị này đóng vai trò là điểm khởi đầu vững chắc, nhưng mỗi workload đều có những đặc thù riêng. Để đạt hiệu năng tối ưu, hãy cân nhắc triển khai thêm các tối ưu hóa như data tiering và storage tier. Đánh giá các tùy chọn tiết kiệm chi phí như reserved instance, và mở rộng triển khai dựa trên các chỉ số hiệu năng thực tế cũng như độ sâu hàng đợi. Bằng cách tuân theo các hướng dẫn này và chủ động giám sát hệ thống, bạn có thể xây dựng một miền OpenSearch Service hoạt động hiệu quả, đáp ứng nhu cầu phân tích log trong khi vẫn duy trì tính hiệu quả và tiết kiệm chi phí.\nHarsh Bansal Harsh là một Analytics và AI Solutions Architect tại Amazon Web Services. Bansal cộng tác chặt chẽ với khách hàng, giúp đỡ họ chuyển đổi lên các nền tảng đám mây và tối ưu hóa thiết lập các cụm để giúp khách hàng tăng hiệu suất và tiết kiệm chi phí. Trước khi tham gia AWS, Bansal hỗ trợ khách hàng tận dụng OpenSearch và Elasticsearch cho các yêu cầu phân tích nhật ký và tìm kiếm đa dạng. Aditya Challa Aditya là Senior Solutions Architect tại Amazon Web Services. Aditya yêu thích việc hỗ trợ khách hàng trong suốt hành trình AWS của họ vì anh ấy hiểu rằng hành trình luôn tuyệt vời hơn khi có người đồng hành. Anh ấy rất yêu thích du lịch, lịch sử, những kỳ quan kỹ thuật và học hỏi điều mới mẻ mỗi ngày. Raaga NG Raaga là Solutions Architect tại Amazon Web Services. Raaga là một chuyên gia công nghệ với hơn 5 năm kinh nghiệm chuyên về Phân tích. Raaga tâm huyết với việc giúp khách hàng AWS định hướng hành trình chuyển đổi lên đám mây. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.3-network/5.3.1-vpc/","title":"Cấu hình VPC, Subnets &amp; Routing","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ thiết lập môi trường mạng cô lập cho IELTS BandUp. Chúng ta sẽ khởi tạo một Virtual Private Cloud (VPC), phân chia nó thành các subnet trên nhiều Availability Zones, và cấu hình định tuyến để truy cập Internet.\n1. Khởi tạo VPC Đầu tiên, chúng ta cần một không gian mạng riêng tư.\nTruy cập VPC Dashboard. Chọn Create VPC. Chọn mục VPC only. Name tag: Điền band-up-vpc. IPv4 CIDR block: Điền 10.0.0.0/16 (Dải mạng này cung cấp 65,536 địa chỉ IP, đủ cho việc mở rộng sau này). Giữ nguyên các cài đặt khác và nhấn Create VPC. 2. Tạo Subnets (Phân vùng mạng) Tiếp theo, chúng ta chia VPC thành các mạng nhỏ hơn (Subnets) phân tán trên hai Availability Zones (AZs) để đảm bảo tính sẵn sàng cao (High Availability). Chúng ta sẽ tuân theo sơ đồ IP sau:\nTên Subnet Loại CIDR Block Availability Zone public-subnet-1 Public 10.0.0.0/24 ap-southeast-1a public-subnet-2 Public 10.0.1.0/24 ap-southeast-1b private-app-subnet-1 Private 10.0.2.0/24 ap-southeast-1a private-app-subnet-2 Private 10.0.3.0/24 ap-southeast-1b private-database-subnet-1 Database 10.0.4.0/24 ap-southeast-1a private-database-subnet-2 Database 10.0.5.0/24 ap-southeast-1b Các bước thực hiện:\nVào menu Subnets \u0026gt; Create subnet. Chọn VPC ID: band-up-vpc. Nhập Subnet name, Availability Zone, và IPv4 CIDR block cho từng subnet theo bảng trên. Lặp lại quy trình cho đến khi tạo đủ 6 subnets. 3. Tạo Internet Gateway (IGW) Mặc định, một VPC hoàn toàn khép kín. Để các tài nguyên trong Public Subnet có thể giao tiếp với thế giới bên ngoài, ta cần một Internet Gateway.\nVào menu Internet gateways \u0026gt; Create internet gateway. Name tag: Điền band-up-igw. Nhấn Create internet gateway. Sau khi tạo xong, nhấn Actions \u0026gt; Attach to VPC. Chọn band-up-vpc và nhấn Attach internet gateway. 4. Cấu hình Route Tables (Bảng định tuyến) Cuối cùng, ta cần điều hướng lưu lượng từ Public Subnets ra Internet Gateway.\nVào menu Route tables \u0026gt; Create route table. Name: public-route-table. VPC: band-up-vpc. Nhấn Create route table. Thêm Route ra Internet:\nChọn public-route-table vừa tạo. Chuyển sang tab Routes \u0026gt; Edit routes. Thêm một route mới: Destination: 0.0.0.0/0 (Tất cả lưu lượng). Target: Chọn Internet Gateway -\u0026gt; band-up-igw. Nhấn Save changes. Liên kết Subnets (Subnet Association):\nChuyển sang tab Subnet associations \u0026gt; Edit subnet associations. Tích chọn các Public Subnets (public-subnet-1 và public-subnet-2). Nhấn Save associations. 5. Kiểm tra cấu hình Để kiểm chứng kiến trúc mạng đã được thiết lập chính xác hay chưa, hãy quay lại VPC Dashboard, chọn band-up-vpc và xem tab Resource map. Bạn sẽ thấy một sơ đồ rõ ràng liên kết các Public Subnet với Route Table và Internet Gateway.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"1. Kiến trúc tổng quan Nền tảng IELTS BandUp được xây dựng trên một kiến trúc mạnh mẽ, có tính sẵn sàng cao (High Availability) trên AWS. Hệ thống được thiết kế để xử lý lưu lượng người dùng một cách an toàn, đồng thời đảm bảo độ trễ thấp khi truy cập tài liệu học tập và các tính năng AI.\n2. Các dịch vụ AWS cốt lõi Để đạt được các mục tiêu về khả năng mở rộng, bảo mật và hiệu năng, chúng tôi sử dụng các nhóm dịch vụ chính sau:\nMạng \u0026amp; Phân phối nội dung (Networking) Amazon VPC (Virtual Private Cloud): Lớp mạng nền tảng. Chúng tôi sử dụng VPC tùy chỉnh với các Public Subnet và Private Subnet riêng biệt để kiểm soát chặt chẽ luồng truy cập. NAT Gateway: Cho phép các tài nguyên trong Private Subnet (như Backend) kết nối ra Internet (để tải thư viện, gọi API ngoài) mà không để lộ IP ra môi trường Public. Application Load Balancer (ALB): Phân phối lưu lượng truy cập ứng dụng đến các container trên nhiều Availability Zones (AZ), đảm bảo khả năng chịu lỗi của hệ thống. Amazon Route 53: Dịch vụ DNS giúp định tuyến tên miền và quản lý lưu lượng truy cập người dùng. Tính toán \u0026amp; Container (Compute) Amazon ECS (Elastic Container Service) với Fargate: Công cụ điều phối container serverless. Chúng tôi sử dụng Fargate để vận hành cả Next.js Frontend và Spring Boot Backend, giúp loại bỏ gánh nặng quản lý máy chủ vật lý (EC2). Amazon ECR (Elastic Container Registry): Kho lưu trữ container được quản lý hoàn toàn, nơi chứa các Docker image của ứng dụng trước khi deploy. Cơ sở dữ liệu \u0026amp; Lưu trữ (Database \u0026amp; Storage) Amazon RDS (Relational Database Service): Sử dụng PostgreSQL với mô hình Multi-AZ (Primary và Standby) để đảm bảo an toàn dữ liệu và khả năng khôi phục sau thảm họa. Amazon ElastiCache (Redis): Đóng vai trò bộ nhớ đệm (cache) trong bộ nhớ, giúp tăng tốc độ truy vấn và quản lý phiên đăng nhập (session) của người dùng. Amazon S3 (Simple Storage Service): Lưu trữ tài nguyên tĩnh, file media (file nghe) và dữ liệu người dùng tải lên với độ bền cao. AI \u0026amp; Tích hợp Serverless Để vận hành các tính năng thông minh của BandUp (Chấm điểm Writing/Speaking, Tạo Flashcard), chúng tôi áp dụng kiến trúc Serverless:\nAmazon Bedrock \u0026amp; Google Gemini API: Các mô hình Generative AI cốt lõi dùng để phân tích bài làm và đưa ra phản hồi cá nhân hóa. AWS Lambda: Các hàm tính toán serverless đóng vai trò điều phối quy trình AI, kết nối ứng dụng với các mô hình ngôn ngữ lớn. Amazon SQS (Simple Queue Service): Hàng đợi thông điệp giúp phân tách (decouple) backend và lớp xử lý AI, cho phép xử lý bất đồng bộ và tránh quá tải hệ thống. Amazon API Gateway: Cổng giao tiếp bảo mật (RESTful API) để gọi các dịch vụ AI từ ứng dụng chính. DevOps \u0026amp; CI/CD AWS CodePipeline: Tự động hóa quy trình phát hành phần mềm, đảm bảo cập nhật nhanh chóng và tin cậy. AWS CodeBuild: Biên dịch mã nguồn, chạy kiểm thử và đóng gói phần mềm (Docker images) sẵn sàng cho việc triển khai. Bảo mật (Security) AWS WAF (Web Application Firewall): Bảo vệ ứng dụng web khỏi các lỗ hổng bảo mật phổ biến. AWS Secrets Manager: Lưu trữ và quản lý an toàn các thông tin nhạy cảm (mật khẩu database, API keys) trong suốt vòng đời ứng dụng. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.4-setup-fe/5.4.1-docker/","title":"Thiết lập ECR &amp; Đẩy Image","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ tiến hành đóng gói ứng dụng Frontend (Next.js) thành Docker container và đẩy (push) image đó lên Amazon Elastic Container Registry (ECR). Image này sẽ được ECS Fargate sử dụng để khởi chạy ứng dụng sau này.\n1. Chuẩn bị Dockerfile Chúng tôi sử dụng Dockerfile đa tầng (multi-stage) được tối ưu hóa cho Bun (một JavaScript runtime tốc độ cao) và Next.js. Cấu hình này giúp giảm kích thước image cuối cùng và tăng cường bảo mật.\nBase Image: oven/bun:1.1.26 Builder: Thực hiện biên dịch ứng dụng Next.js. Runner: Môi trường production nhẹ nhàng, mở cổng 3000. 2. Build Docker Image Chạy lệnh sau tại thư mục gốc của dự án để build image. Chúng ta sẽ đặt tag là band-up-frontend.\ndocker build -t band-up-frontend . Quá trình build sẽ cài đặt các thư viện phụ thuộc bằng bun install và biên dịch dự án.\n3. Kiểm tra Image tại Local Sau khi build xong, hãy kiểm tra xem image đã được tạo thành công hay chưa.\ndocker image ls Bạn sẽ thấy band-up-frontend với tag latest trong danh sách.\nChạy thử nghiệm: Bạn có thể chạy thử container trên máy local để đảm bảo ứng dụng khởi động đúng cách trước khi đẩy lên AWS.\ndocker run -p 3000:3000 band-up-frontend:latest 4. Đẩy Image lên Amazon ECR Bây giờ chúng ta cần tải image này lên AWS.\nBước 1: Tạo Repository\nTruy cập Amazon ECR \u0026gt; Repositories. Nhấn Create repository. Visibility settings: Chọn Private. Repository name: Nhập band-up-frontend. Nhấn Create repository. Bước 2: Push Image Sử dụng AWS CLI để xác thực và đẩy image. Hãy thay thế [AWS_ACCOUNT_ID] và [REGION] bằng thông tin tài khoản của bạn.\nĐăng nhập vào ECR:\naws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com Gán Tag cho Image:\ndocker tag band-up-frontend:latest [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:latest Đẩy Image lên ECR:\ndocker push [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:latest Sau khi quá trình push hoàn tất, image của bạn đã được lưu trữ an toàn trên AWS ECR và sẵn sàng để triển khai.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.5-setup-be/5.5.1-ecr/","title":"Thiết lập ECR &amp; Đẩy Image","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ đóng gói ứng dụng Backend (Spring Boot) và đẩy Docker image đã được tối ưu hóa lên Amazon ECR.\n1. Chiến lược Dockerfile Đối với Backend, chúng ta sử dụng chiến lược Multi-Stage Build với eclipse-temurin:21 (Java 21). Điều này giúp tạo ra image cuối cùng nhỏ gọn và bảo mật.\nStage 1 (Deps): Tải về các thư viện phụ thuộc (dependencies) của Maven. Stage 2 (Package): Build ứng dụng và trích xuất Spring Boot Layered Jar. Kỹ thuật này tách ứng dụng thành các lớp riêng biệt (dependencies, spring-boot-loader, code ứng dụng), giúp Docker cache hiệu quả các phần ít thay đổi. Stage 3 (Final): Sao chép các lớp đã trích xuất vào một JRE image nhẹ. Đồng thời tạo một user không có quyền quản trị (appuser) để tăng cường bảo mật. 2. Build Docker Image Chạy lệnh build tại thư mục gốc của dự án backend. Chúng ta đặt tag là band-up-backend.\ndocker build -t band-up-backend . Docker sẽ thực thi các bước biên dịch và đóng gói như đã định nghĩa.\n3. Tạo ECR Repository Chúng ta cần một kho chứa cho image này.\nTruy cập Amazon ECR \u0026gt; Create repository. Repository name: Nhập band-up-backend. Visibility: Private. Image tag mutability: Mutable. Nhấn Create repository. 4. Đẩy Image lên ECR (Push) Sau khi build xong và repository đã sẵn sàng, chúng ta tiến hành đẩy image.\nBước 1: Gán Tag (Tagging) Gán tag phiên bản (ví dụ: v1.0.0) cho image local.\ndocker tag band-up-backend:latest [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-backend:v1.0.0 Bước 2: Push lên ECR Tải các layer lên AWS.\ndocker push [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-backend:v1.0.0 5. Kiểm tra kết quả Truy cập Amazon ECR Console và chọn repository bandup-backend. Bạn sẽ thấy image với tag v1.0.0 đã được tải lên thành công.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Kick-off Chương Trình The First Cloud Journey (FCJ)” Mục Đích Của Sự Kiện Chính thức khởi động chương trình The First Cloud Journey (FCJ) kéo dài 12 tuần. Kết nối, làm quen giữa các thành viên, Mentors và Ban Tổ Chức (BTC). Giới thiệu tổng quan về tổ chức, mục tiêu học tập và lộ trình triển khai dự án. Hướng dẫn quy trình làm việc nhóm và tiến hành thành lập các nhóm thực hiện dự án. Danh Sách Diễn Giả Đại diện Ban Tổ Chức (BTC) - Giới thiệu về tầm nhìn và sứ mệnh của chương trình. Các Mentors tiêu biểu - Chia sẻ kinh nghiệm và lộ trình thành công trong lĩnh vực Cloud. Các thành viên cựu (Alumni) - Chia sẻ các bài học kinh nghiệm thực tế. Nội Dung Nổi Bật Khung chương trình và Lộ trình 12 tuần Trình bày chi tiết roadmap 12 tuần, từ kiến thức AWS cơ bản (VPC, EC2) đến triển khai dự án Serverless hoàn chỉnh. Đặt ra mục tiêu cụ thể về kiến thức và sản phẩm đầu ra (Minimum Viable Product - MVP). Quy tắc làm việc và Văn hóa tổ chức Quy định về kỷ luật, tham gia: Nhấn mạnh sự cam kết và trách nhiệm cá nhân trong suốt hành trình. Văn hóa chia sẻ và hỗ trợ: Xây dựng tinh thần cộng đồng mạnh mẽ giữa các thành viên. Quy trình thành lập nhóm và Dự án Hướng dẫn cách thức tạo nhóm hiệu quả (phân bổ vai trò, công cụ giao tiếp). Đưa ra định hướng ban đầu cho các dự án Cloud để các nhóm bắt đầu nghiên cứu. An toàn tài khoản AWS Hướng dẫn thiết lập bảo mật hai lớp (2FA) và các thao tác cơ bản để quản lý chi phí (Budget) ngay từ đầu. Những Gì Học Được Tư Duy và Cam Kết Tầm quan trọng của kỷ luật: Nhận thức rõ tính nghiêm túc và mức độ cam kết cần thiết để hoàn thành chương trình. Vai trò của cộng đồng: Giá trị của việc học hỏi và hỗ trợ từ các Mentors và thành viên khác. Kiến Thức Tổ Chức Mục tiêu của chương trình: Hiểu rõ những kiến thức và kỹ năng Cloud mà chương trình mong muốn trang bị cho học viên. Lộ trình học tập rõ ràng: Nắm được các module chính cần chinh phục trong 12 tuần. Kỹ Năng Thực Hành Đầu Tiên Quy trình lập nhóm: Hoàn thành việc tạo nhóm dự án cùng các thành viên mới. Bảo mật cơ bản: Nắm được các bước ban đầu để thiết lập tài khoản AWS an toàn và tối ưu chi phí. Ứng Dụng Vào Công Việc Ngay lập tức thành lập nhóm và phân công nhiệm vụ đầu tiên. Bắt đầu tìm hiểu về tổ chức và các khái niệm Cloud cơ bản. Thực hiện các thao tác cơ bản trên tài khoản AWS như thiết lập 2FA và Budget (theo Worklog Tuần 1). Trải nghiệm trong event Tham gia buổi Kick-off là một trải nghiệm tràn đầy năng lượng và định hướng rõ ràng. Đây là sự kiện đặt nền móng cho toàn bộ hành trình 12 tuần:\nKết nối và Năng lượng Cộng đồng Cảm giác được chào đón: Gặp gỡ và làm quen với tất cả thành viên trong FCJ, tạo ra môi trường học tập và làm việc nhóm tích cực. Mức độ nghiêm túc: Buổi Kick-off đã truyền tải rõ ràng sự cam kết của BTC, giúp tôi ý thức được sự nghiêm túc cần thiết trong quá trình thực tập. Lộ trình và Mục tiêu Rõ ràng về định hướng: Lần đầu tiên thấy được toàn bộ lộ trình 12 tuần một cách trực quan, giúp tôi lên kế hoạch học tập chủ động hơn. Giá trị của dự án: Hiểu được rằng mục tiêu cuối cùng không chỉ là học mà còn là tạo ra một sản phẩm Cloud thực tế. Bài học thực tiễn ban đầu Tầm quan trọng của 2FA và Budget: Được hướng dẫn trực tiếp về các thao tác bảo mật và quản lý chi phí AWS, những bài học rất quan trọng ngay từ ngày đầu sử dụng Cloud. Teamwork: Nhanh chóng thành lập nhóm và bắt đầu thảo luận về cách thức phối hợp. Kết luận Buổi Kick-off không chỉ là sự kiện giới thiệu mà còn là một buổi huấn luyện, cung cấp đủ thông tin và động lực để tôi tự tin bắt đầu hành trình 12 tuần chinh phục Cloud.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện đã hoàn thành xuất sắc mục tiêu: cung cấp thông tin, thiết lập kỷ luật, và khơi dậy sự hứng thú cho một hành trình học tập và phát triển chuyên sâu.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Tìm hiểu về tổ chức và các dịch vụ cơ bản của AWS. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham gia buổi kick-off của FCJ\n- Tìm hiểu về tổ chức\n- Tạo nhóm cùng thực hiện các dự án 06/09/2025 06/09/2025 3 - Tạo tài khoản AWS\n- Xem và vẽ lại kiến trúc mẫu trên phần mềm draw.io\n- Tìm hiểu về điện toán đám mây 09/09/2025 09/09/2025 cloudjourney.awsstudygroup.com 4 - Tìm hiểu về mục tiêu của chương trình The First Cloud Journey và website AWS\n- Thực hiện các thao tác đầu trên tài khoản đã tạo:\n+ Tạo budget\n+ Tạo groups\n+ Thiết lập bảo mật hai lớp\n- Tìm hiểu về Support Centre của website AWS, cách hoạt động và cách gửi yêu cầu hỗ trợ 10/09/2025 10/09/2025 cloudjourney.awsstudygroup.com 5 - Tạo VPC\n- Chỉnh cấu hình cho VPC\n- Tạo Subnet\n- Cấu hình Subnet public để tự động cấp phát IP công cộng\n- Tạo Internet Gateway\n- Cấu hình Internet Gateway để kết nối với VPC\n- Tạo Route Table\n- Cấu hình Route Table để kết nối với Internet Gateway\n- Cấu hình Subnet Associations thành công\n- Tạo Security Group (public)\n- Tạo Security Group (private) 11/09/2025 14/09/2025 cloudjourney.awsstudygroup.com Kết quả đạt được tuần 1 Tham gia buổi kick-off và làm quen với các thành viên trong First Cloud Journey. Hiểu về tổ chức và các mục tiêu của chương trình. Thành công tạo nhóm để thực hiện các dự án. Tạo tài khoản AWS thành công và thực hiện các thao tác cơ bản: Thiết lập budget. Tạo groups. Kích hoạt bảo mật hai lớp (2FA). Tìm hiểu và vẽ lại kiến trúc mẫu trên draw.io. Nắm được khái niệm cơ bản về điện toán đám mây. Hiểu cách sử dụng Support Centre của AWS và cách gửi yêu cầu hỗ trợ. Thành công thực hiện các tác vụ liên quan đến VPC: Tạo và cấu hình VPC. Tạo và cấu hình Subnet (bao gồm Subnet public với IP công cộng tự động). Tạo và gắn Internet Gateway vào VPC. Tạo và cấu hình Route Table, kết nối với Internet Gateway. Cấu hình Subnet Associations thành công. Tạo Security Group cho cả public và private. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trang này ghi lại toàn bộ Nhật ký công việc (Worklog) được thực hiện trong suốt chương trình thực tập First Cloud Journey (FCJ) tại AWS. Đây là tài liệu chi tiết hóa quá trình học tập, triển khai dự án Bandup IELTS, khắc phục lỗi hệ thống và tham gia các sự kiện chuyên môn trong vòng 12 tuần (khoảng 3 tháng).\nTrong 12 tuần này, tôi đã chuyển đổi từ việc làm quen với các khái niệm Cloud cơ bản sang việc xây dựng và tối ưu hóa một ứng dụng Serverless tích hợp AI hoàn chỉnh trên AWS, hoàn thành hơn 50 khóa học AWS Skill Builder trong quá trình này.\nTóm tắt công việc theo tuần: Tuần Công việc trọng tâm Tuần 1 Làm quen FCJ, tạo tài khoản AWS, và thiết lập môi trường mạng cơ bản (VPC, Subnets, Internet Gateway). Tuần 2 Nắm vững Amazon EC2 và VPC, hoàn thành các khóa AWS Skill Builder về IAM, Budgets, EC2, và tham gia sự kiện Cloud Day để học hỏi về AI/Data. Tuần 3 Khắc phục sự cố tài khoản AWS, cấu hình Hybrid DNS với Route 53 Resolver và VPC Peering, học CloudFormation và Cloud9 cho phát triển IaC. Tuần 4 Thành thạo AWS Transit Gateway cho quản lý mạng tập trung, nghiên cứu sâu EC2 Auto Scaling, Lightsail, và các dịch vụ Migration (DMS, VM Import/Export). Tuần 5 Phân tích và tối ưu chi phí AWS, thiết kế kiến trúc hạ tầng Serverless, học RDS, DynamoDB, ElastiCache, và thiết lập AWS Toolkit cho VS Code. Tuần 6 Thành thạo dịch vụ Storage AWS (S3, Glacier, Storage Gateway), nâng cao kỹ năng Python, hoàn thiện kiến trúc dự án, và tham gia webinar về DevSecOps và Amazon Q Developer. Tuần 7 Ôn tập toàn diện và củng cố kiến thức các dịch vụ AWS cơ bản (Compute, Storage, Networking, Database, Security) để chuẩn bị cho kỳ thi giữa kỳ. Tuần 8 Hoàn thành thi giữa kỳ, bắt đầu triển khai các chức năng CRUD nền tảng, nghiên cứu kiến trúc serverless (Lambda, API Gateway, DynamoDB), và thiết lập môi trường phát triển. Tuần 9 Chuyển đổi sang AWS SAM, tái cấu trúc các chức năng CRUD, tích hợp Docker cho môi trường build, và triển khai thành công dự án lên AWS vượt qua các thách thức gỡ lỗi Local. Tuần 10 Gỡ lỗi CORS và template validation errors, tích hợp Frontend/Backend, hoàn thành chức năng Read/Delete, giải quyết vấn đề xác thực Cognito, và tham gia AWS Cloud Mastery Series #1. Tuần 11 Triển khai kiến trúc Multi-Stack để tối ưu hóa, khắc phục triệt để lỗi CORS, và bắt đầu tích hợp AI Services (Lambda, Bedrock). Tuần 12 Hoàn thiện Lambda functions tích hợp AI, tích hợp Gemini API cho đánh giá IELTS, hoàn thành RAG pipeline cho tạo flashcard, và tham gia AWS Cloud Mastery Series cuối cùng. Lộ trình học AWS Skill Builder (Tuần 2-5) Danh mục Các khóa học đã hoàn thành Networking VPC, Route 53, VPC Peering, Transit Gateway, Networking Workshop Compute EC2, EC2 Auto Scaling, Lightsail, Lightsail Containers Security IAM, IAM Roles cho EC2 Database RDS, DynamoDB, ElastiCache Migration VM Import/Export, DMS, SCT, Elastic Disaster Recovery DevOps CloudFormation, Cloud9, AWS CLI, AWS Toolkit cho VS Code Quản lý chi phí AWS Budgets, Cost Explorer, Service Quotas, Right-Sizing Architecture Building Highly Available Web Applications Lộ trình học AWS Skill Builder (Tuần 6-10) Danh mục Các khóa học đã hoàn thành Storage Static Website Hosting với S3, AWS Backup, CloudFront Reliability Data Protection với AWS Backup Development AWS Toolkit cho VS Code, Serverless patterns Tiến trình Học tập Tuần 1-5: Nền tảng \u0026amp; Khám phá\nDịch vụ AWS cơ bản (EC2, S3, VPC, IAM) Networking fundamentals (VPC, Route 53, Transit Gateway) Tối ưu chi phí và thiết kế kiến trúc Infrastructure as Code (CloudFormation, Cloud9) Tuần 6-7: Củng cố \u0026amp; Đánh giá\nThành thạo dịch vụ Storage (S3, Glacier, Storage Gateway) Chiến lược disaster recovery và backup Ôn tập toàn diện cho kỳ thi Hoàn thành thi giữa kỳ Tuần 8-10: Triển khai \u0026amp; Deployment\nTriển khai kiến trúc Serverless (Lambda, API Gateway, DynamoDB) Áp dụng framework AWS SAM Tích hợp Docker cho builds nhất quán Tích hợp Frontend-Backend Production deployment và debugging Tuần 11-12: Tính năng Nâng cao \u0026amp; Tích hợp AI\nTối ưu hóa kiến trúc Multi-stack Tích hợp dịch vụ AI (Bedrock, Gemini API) Triển khai RAG pipeline Hoàn thiện dự án cuối cùng "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.6-ai-service/5.6.1-api-gateway/","title":"API Gateway","tags":[],"description":"","content":"Tổng Quan Tạo Amazon API Gateway làm entry point cho AI service requests.\nTạo REST API Điều hướng đến API Gateway → Create API → REST API Cài Đặt Giá Trị API name ielts-ai-api API type REST API Endpoint type Regional Tạo Resources và Methods Endpoints:\nMethod Path Description POST /writing/evaluate Submit writing sample POST /speaking/evaluate Submit audio recording POST /flashcards/generate Generate flashcard POST /upload/audio Upload audio POST /upload/document Upload document Cấu Hình SQS Integration Cho mỗi POST endpoint, cấu hình SQS integration:\nChọn method → Integration Request Integration type: AWS Service AWS Service: SQS HTTP method: POST Action: SendMessage Execution role: API Gateway role với SQS permissions Request Mapping Template:\nAction=SendMessage\u0026amp;MessageBody=$util.urlEncode($input.body)\u0026amp;QueueUrl=$util.urlEncode(\u0026#39;https://sqs.ap-southeast-1.amazonaws.com/{account}/ielts-writing-queue\u0026#39;) Enable CORS Chọn resource → Enable CORS Access-Control-Allow-Origin: * (hoặc specific domain) Access-Control-Allow-Methods: POST, GET, OPTIONS Deploy API Actions → Deploy API Stage name: prod Ghi lại invoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod AWS CLI Commands # Tạo REST API API_ID=$(aws apigateway create-rest-api \\ --name ielts-ai-api \\ --endpoint-configuration types=REGIONAL \\ --query \u0026#39;id\u0026#39; --output text) # Lấy root resource ROOT_ID=$(aws apigateway get-resources \\ --rest-api-id $API_ID \\ --query \u0026#39;items[?path==`/`].id\u0026#39; --output text) # Tạo /ai resource AI_RESOURCE=$(aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part ai \\ --query \u0026#39;id\u0026#39; --output text) # Tạo /ai/writing-assessment resource aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $AI_RESOURCE \\ --path-part writing-assessment Bước Tiếp Theo Tiến hành đến SQS Queues.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.7-cicd-pipeline/5.7.1-create-gwe/","title":"Kết nối repo GitLab &amp; tạo dự án CodeBuild","tags":[],"description":"","content":"Mục tiêu Cấu hình hai dự án CodeBuild (frontend và backend) và trigger từ sự kiện Release của GitLab để khởi chạy CodePipeline. CodePipeline gọi CodeBuild dựa trên frontend-buildspec.yml và backend-buildspec.yml có sẵn trong repository, sau đó deploy lên ECS.\nTài nguyên AWS Dự án CodeBuild: Frontend: Source = CodePipeline; Buildspec = frontend-buildspec.yml Backend: Source = CodePipeline; Buildspec = backend-buildspec.yml CodePipeline (bước sau) nhận artifact và deploy lên ECS Tạo dự án CodeBuild \u0026amp; kết nối repository GitLab Trong phần cấu hình tạo mới CodeBuild Project, chọn Default project. Ở mục Source, chọn GitLab và repository Band-Up. Giữ nguyên cấu hình mặc định cho Environment. Chỉ định buildspec của dự án Band-Up cho frontend/backend như hình: Gửi tạo và lặp lại cho dự án CodeBuild frontend/backend còn lại. Tóm tắt Bạn đã có hai dự án CodeBuild (frontend và backend) sẵn sàng được gọi bởi CodePipeline. Sự kiện Release từ GitLab có thể kích hoạt CodePipeline, sau đó chạy mỗi dự án với frontend-buildspec.yml và backend-buildspec.yml tương ứng. Ở các bước tiếp theo, CodePipeline sẽ lấy artifact sau build và deploy lên ECS.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “DX Talk#7: Reinventing DevSecOps with AWS Generative AI” Mục Đích Của Sự Kiện Khai thác góc nhìn chiến lược và thực tiễn về cuộc chuyển mình đầy mạnh mẽ của AI trong DevSecOps. Giới thiệu giải pháp tích hợp AI toàn diện: Từ tự động hóa quy trình đến kiểm tra bảo mật liên tục. \u0026ldquo;Mổ xẻ\u0026rdquo; các Case study từ CMC Global và AWS về cách áp dụng AI trong giải quyết các vấn đề bảo mật. Định hướng cho các DevSecOps Engineer trong thị trường đòi hỏi chuyên môn cao. Danh Sách Diễn Giả Anh Lê Thanh Đức – Cloud Delivery Manager, CMC Global Anh Dư Quốc Thành – Technical Leader, CMC Global Khách mời đặc biệt: Anh Văn Hoàng Kha – Cloud Engineer, AWS Community Builder Nội Dung Nổi Bật Giải pháp tích hợp AI toàn diện trong DevSecOps Tự động hóa quy trình, dự đoán rủi ro thông minh. Kiểm tra bảo mật liên tục trong quy trình CI/CD. Phản ứng nhanh với các mối đe dọa tiềm ẩn. Case study và Bài học thực tiễn Trực tiếp \u0026ldquo;mổ xẻ\u0026rdquo; các dự án từ CMC Global và AWS để học cách các doanh nghiệp áp dụng AI trong giải quyết các vấn đề bảo mật và vận hành hệ thống. Khám phá cách AI giúp gạt bỏ những “gatekeeper” cứng nhắc và quy trình phản hồi thủ công tốn kém. Định hướng sự nghiệp và nâng cao chuyên môn Thảo luận về việc liên tục cập nhật xu hướng và nâng cao chuyên môn là chìa khóa then chốt để kỹ sư chinh phục các dự án phức tạp. Những Gì Học Được Tích hợp AI và Tự động hóa Hiểu rõ về Giải pháp tích hợp AI toàn diện trong DevSecOps, bao gồm tự động hóa quy trình và kiểm tra bảo mật liên tục trong CI/CD. Nắm được cách AI có thể dự đoán rủi ro thông minh và tăng tốc độ phản ứng với các mối đe dọa. Tư duy DevSecOps hiện đại Nhận ra tầm quan trọng của việc tích hợp bảo mật vào SDLC (Software Development Life Cycle). Hiểu cách các công cụ phổ biến như Jenkins (CI/CD), SonarQube (SAST), OWASP ZAP (DAST), và Terraform (IaC) hoạt động. Công cụ Generative AI Khám phá Amazon Q Developer – trợ lý AI mạnh mẽ hỗ trợ code generation, testing, vulnerability scanning, và tối ưu hóa phát triển phần mềm trên AWS. Ứng Dụng Vào Công Việc (Từ Worklog Tuần 6) Áp dụng tư duy DevSecOps vào dự án hiện tại, tích hợp bảo mật ngay từ giai đoạn đầu phát triển. Nghiên cứu Amazon Q Developer để tích hợp vào workflow, hỗ trợ tạo code và kiểm tra lỗi bảo mật. Tìm hiểu các công cụ CI/CD và kiểm tra bảo mật SAST/DAST để đưa vào lộ trình phát triển dự án. Trải nghiệm trong event Workshop \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; mang đến một cái nhìn đa chiều, chiến lược và thực tiễn về tương lai của bảo mật và vận hành hệ thống Cloud:\nGóc nhìn từ chuyên gia Được lắng nghe những góc nhìn chiến lược từ các chuyên gia hàng đầu như Anh Lê Thanh Đức, Anh Dư Quốc Thành, và khách mời Anh Văn Hoàng Kha. Qua các Case Study, tôi hiểu cách các doanh nghiệp lớn áp dụng Generative AI để giải quyết các vấn đề bảo mật và vận hành phức tạp. Giá trị của AI trong DevSecOps Nhận thấy rõ khả năng của AI trong việc loại bỏ các rào cản thủ công (như gatekeeper cứng nhắc, ca trực 24/7), chuyển DevSecOps thành một quy trình tự động hóa và thông minh hơn. Sự kiện đã cung cấp giải pháp cụ thể cho việc tích hợp AI toàn diện, từ tự động hóa quy trình đến dự đoán rủi ro. Định hướng chuyên môn Nhấn mạnh tầm quan trọng của việc liên tục cập nhật xu hướng và nâng cao chuyên môn để kỹ sư DevSecOps có thể chinh phục các dự án phức tạp trong tương lai. Có cơ hội hỏi đáp trực tiếp cùng các diễn giả để giải đáp các thắc mắc về tích hợp AI vào dự án của mình. Kết luận Sự kiện là một nguồn thông tin quý giá, giúp tôi không chỉ hiểu về công nghệ mà còn về định hướng nghề nghiệp, đặc biệt là cách sử dụng các công cụ mạnh mẽ như Amazon Q Developer để tăng cường năng suất và tích hợp bảo mật vào quy trình phát triển.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện đã thành công trong việc khai thác góc nhìn chiến lược và thực tiễn về DevSecOps với Generative AI, truyền cảm hứng và cung cấp định hướng rõ ràng cho các kỹ sư trẻ.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/3-blogstranslated/3.2-blog2/","title":"Amazon SageMaker giới thiệu bộ lưu trữ chia sẻ dựa trên Amazon S3 để tăng cường cộng tác dự án","tags":[],"description":"","content":"Ngày đăng: 2025‑09‑16 – Tác giả: Hari Ramesh, Anagha Barve, Anchit Gupta, Saurabh Bhutyani và Zach Mitchell trong Amazon SageMaker Unified Studio, Amazon Simple Storage Service (S3), Announcements, Intermediate (200),Technical How-to.\nAWS gần đây đã công bố rằng Amazon SageMaker hiện cung cấp Amazon Simple Storage Service (Amazon S3) làm lựa chọn lưu trữ file mặc định cho các dự án mới trong Amazon SageMaker Unified Studio. Tính năng này giải quyết việc ngừng hỗ trợ AWS CodeCommit, đồng thời mang đến cho các nhóm một cách đơn giản và nhất quán để cộng tác trên các file dự án trong toàn bộ công cụ phát triển tích hợp của SageMaker.\nTùy chọn lưu trữ Amazon S3 mới này mang lại những lợi ích sau:\nHợp tác đơn giản – Chia sẻ file trực tiếp giữa các thành viên dự án mà không cần thao tác Git. Truy cập đồng nhất – File được truy cập nhất quán trên các công cụ SageMaker (JupyterLab, Query Editor, Visual ETL). Phân tách workspace rõ ràng – Có sẵn phân tách lưu trữ cá nhân với Amazon Elastic Block Store (Amazon EBS) volumes. Khả dụng toàn cầu – Hỗ trợ ở tất cả các AWS Region mà SageMaker có mặt. Mặc dù Amazon S3 là tùy chọn mặc định cho việc lưu trữ file, bạn vẫn có thể sử dụng Git version control nếu muốn có khả năng quản lý source code mạnh mẽ hơn.\nTrong bài viết này, chúng ta sẽ thảo luận về tính năng mới và cách bắt đầu sử dụng Amazon S3 shared storage trong SageMaker Unified Studio.\nTổng quan giải pháp\nKhi bạn tạo một SageMaker Unified Studio domain mới, dịch vụ sẽ tự động cấu hình Amazon S3 làm tùy chọn lưu trữ mặc định cho dự án. Mỗi dự án sẽ nhận được một vùng lưu trữ chung chuyên biệt trong Amazon S3, khả dụng cho các thành viên dự án, với cấu trúc:\n[bucket]/[domain-id]/[project-id]/shared/.\nCông cụ SageMaker (JupyterLab và Code Editor) cung cấp cho người dùng: Một EBS volume cá nhân để làm việc riêng trong JupyterLab và Code Editor. Một thư mục chia sẻ được mount, chứa không gian lưu trữ dùng chung của dự án trên Amazon S3. Phân tách rõ ràng giữa không gian cá nhân và không gian chia sẻ. Khả năng truy cập lưu trữ chia sẻ trong các công cụ phát triển tích hợp SageMaker: JupyterLab và Code Editor hiển thị file chia sẻ song song với file cá nhân. Query Editor lọc các SQL notebook có liên quan. Visual ETL cung cấp khả năng truy cập trực tiếp tới các workflow ETL (extract, transform, load) chia sẻ. Các file được lưu vào thư mục dùng chung sẽ ngay lập tức khả dụng và hiển thị cho các thành viên dự án. Người dùng vẫn có thể tiếp tục làm việc với file cá nhân trong EBS volumes (ví dụ trong JupyterLab và Code Editor) và có thể chuyển file sang vùng lưu trữ chia sẻ khi sẵn sàng cộng tác. Nếu bạn muốn dùng Git cho việc cộng tác, bạn vẫn có thể làm điều đó bằng cách tích hợp dự án với GitHub, GitLab, hoặc các repository được quản lý trên Bitbucket.\nTùy chọn di chuyển và kiểm soát phiên bản Đối với các nhóm hiện đang sử dụng Amazon CodeCommit, các dự án hiện có vẫn sẽ hoạt động bình thường. Các dự án mới sẽ mặc định sử dụng lưu trữ Amazon S3. Nếu bạn muốn có chức năng version control cho các dự án dựa trên Amazon S3, bạn có thể bật tính năng versioning trực tiếp trong Amazon S3.\nCác bước chuẩn bị Trước khi thực hiện các hướng dẫn trong phần tiếp theo, bạn cần hoàn thành các bước chuẩn bị sau:\nĐăng ký tài khoản AWS. Tạo người dùng có quyền quản trị (administrative access). Kích hoạt IAM Identity Center trong cùng AWS Region mà bạn muốn tạo SageMaker Unified Studio domain. Xác nhận xem SageMaker Unified Studio hiện có sẵn ở Region nào. Thiết lập Identity Provider (IdP) và đồng bộ hóa danh tính (identities) và nhóm (groups) với IAM Identity Center. Để biết thêm chi tiết, tham khảo phần IAM Identity Center Identity source tutorials. Bắt đầu sử dụng Amazon S3 Shared Storage Để bắt đầu sử dụng Amazon S3 shared storage, hãy hoàn thành các bước sau:\nTạo một SageMaker Unified Studio domain mới. Tạo một dự án mới (lưu trữ Amazon S3 sẽ được chọn mặc định làm tùy chọn lưu trữ file).\nMở dự án mới và chọn JupyterLab trong menu Build.\nLưu notebook mới mà bạn vừa tạo.\nĐổi tên file theo ý bạn.\nSau khi dự án được lưu, người dùng trong dự án có thể xem notebook đã lưu trong phần Project files theo đường dẫn S3:\n[bucket]/[domain-id]/[project-id]/shared/.\nBật kiểm soát phiên bản với Git Để bật version control bằng Git, hãy thực hiện các bước sau:\nTruy cập SageMaker console và tạo project profile mới.\nCung cấp đầy đủ thông tin cần thiết cho project profile của bạn.\nTrong phần Project files storage, tùy chọn Amazon S3 được chọn mặc định. Nếu muốn bật version control cho dự án, bạn có thể sử dụng các kết nối repository Git sẵn có bằng cách chọn Git repository. Sử dụng shared storage trong Query Editor Để sử dụng tính năng shared storage trong Query Editor, hãy thực hiện các bước sau:\nChọn Query Editor từ menu Build.\nSoạn truy vấn của bạn, sau đó trong menu Actions, chọn Save để lưu truy vấn vào vùng lưu trữ chia sẻ.\nQuay lại phần Project files, nơi bạn có thể xem các file query notebook nằm trong đường dẫn S3:\n[bucket]/[domain-id]/[project-id]/shared/. Sử dụng shared storage trong Visual ETL flows Để sử dụng tính năng shared storage trong Visual ETL flows, hãy thực hiện các bước sau:\nChọn Visual ETL flows từ menu Build.\nPhát triển workflow ETL của bạn và lưu mã vào dự án. Quay lại phần Project files, nơi bạn có thể xem các file nằm trong đường dẫn S3: [bucket]/[domain-id]/[project-id]/shared/jobs/uploads/\u0026lt;ETL name\u0026gt;. Dọn dẹp tài nguyên Hãy đảm bảo bạn xóa các tài nguyên SageMaker Unified Studio sau khi hoàn tất để tránh phát sinh chi phí không mong muốn. Quy trình bao gồm các bước sau:\nXóa các dự án (projects). Xóa domain. Xóa S3 bucket có tên dạng:\namazon-datazone-AWSACCOUNTID-AWSREGION-DOMAINID Kết luận Việc ra mắt tính năng Amazon S3 shared storage trong SageMaker là một bước tiến nữa trong việc đơn giản hóa trải nghiệm phát triển phân tích và học máy (ML) cho khách hàng. Bằng cách giảm độ phức tạp của các thao tác Git nhưng vẫn duy trì khả năng cộng tác mạnh mẽ, các nhóm có thể tập trung hơn vào việc xây dựng và triển khai các giải pháp phân tích và ML nhanh chóng hơn. Tính năng này hiện đã khả dụng tại các AWS Region có hỗ trợ SageMaker.\nĐể biết thông tin chi tiết về tính năng này, bao gồm hướng dẫn thiết lập và best practices, vui lòng tham khảo tài liệu Unified storage in Amazon SageMaker Unified Studio.\nHari Ramesh Hari là Senior Analytics Specialist Solutions Architect tại AWS. Ông tập trung vào việc xây dựng các nền tảng dữ liệu đám mây, cho phép trực tuyến theo thời gian thực, xử lý dữ liệu lớn và quản trị dữ liệu mạnh mẽ. Anagha Barve Anagha là Software Development Manager trong nhóm Amazon SageMaker Unified Studio. Nhóm của cô tập trung vào việc xây dựng các công cụ và trải nghiệm tích hợp cho các nhà phát triển bằng Amazon SageMaker Unified Studio. Trong thời gian rảnh rỗi, cô thích nấu ăn, làm vườn và du lịch. Zach Mitchell Zach là Sr. Big Data Architect. Anh ấy làm việc trong nhóm sản phẩm để tăng cường sự hiểu biết giữa các kỹ sư sản phẩm và khách hàng của họ đồng thời hướng dẫn khách hàng trong suốt hành trình phát triển hồ dữ liệu và các giải pháp dữ liệu khác trên các dịch vụ phân tích AWS. Saurabh Bhutyani Saurabh là Principal Analytics Specialist Solutions Architect tại AWS. Anh đam mê công nghệ mới. Anh gia nhập AWS vào năm 2019 và làm việc với khách hàng để cung cấp hướng dẫn kiến ​​trúc cho việc vận hành các trường hợp sử dụng AI tạo sinh, các giải pháp phân tích có thể mở rộng và kiến ​​trúc lưới dữ liệu bằng các dịch vụ AWS như Amazon Bedrock, Amazon SageMaker, Amazon EMR, Amazon Athena, AWS Glue, AWS Lake Formation và Amazon DataZone. Anchit Gupta Anchit là Senior Product Manager cho Amazon SageMaker Studio. Cô tập trung vào việc tạo điều kiện cho các quy trình làm việc khoa học dữ liệu và kỹ thuật dữ liệu tương tác từ bên trong SageMaker Studio IDE. Trong thời gian rảnh rỗi, cô thích nấu ăn, chơi cờ bàn/bài và đọc sách. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2 Hoàn thành Module 2, nắm vững kiến thức nền tảng về Amazon EC2 và VPC. Chuẩn bị và cấu hình các tài nguyên cần thiết để khởi tạo EC2. Tìm hiểu Amazon Route 53 và các khái niệm quản lý DNS. Tham gia sự kiện Cloud Day để học hỏi về AI và Data. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu sâu về kiến trúc VPC và các thành phần mạng.\n- Học nguyên tắc thiết kế kiến trúc AWS từ bài giảng của Mentor Gia Hung.\n- Hoàn thành AWS Skill Builder: Networking Essentials with Amazon VPC. 15/09/2025 16/09/2025 AWS VPC Documentation 3 - Tạo tài nguyên VPC để chuẩn bị cho việc triển khai EC2.\n- Khởi tạo EC2 instances từ các tài nguyên đã cấu hình.\n- Học về Security Groups và Network ACLs.\n- Hoàn thành: Compute Essentials with Amazon EC2. 16/09/2025 17/09/2025 AWS EC2 Documentation Introduction to Amazon EC2 Deploying FCJ Management Application with Auto Scaling Group 4 - Xử lý vấn đề xác thực tài khoản AWS bằng cách gửi giấy tờ xác minh.\n- Hoàn thành: Creating Your First AWS Account và Getting Help with AWS Support. 17/09/2025 20/09/2025 AWS Support\nYêu cầu Hỗ trợ từ AWS Support 5 - Tham gia sự kiện Cloud Day.\n- Thu thập kiến thức về xu hướng AI và Data.\n- Giao lưu với các mentor nổi bật trong cộng đồng AWS. 18/09/2025 18/09/2025 Cloud Day Event Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Creating Your First AWS Account Bắt đầu ✅ Managing Costs with AWS Budgets Quản lý chi phí ✅ Getting Help with AWS Support Hỗ trợ ✅ Access Management with AWS IAM Bảo mật ✅ Networking Essentials with Amazon VPC Mạng ✅ Compute Essentials with Amazon EC2 Compute ✅ Instance Profiling with IAM Roles for EC2 Bảo mật ✅ Kết quả đạt được tuần 2 Kỹ năng kỹ thuật đã tiếp thu:\nNắm vững kiến trúc VPC và các nguyên tắc cơ bản của EC2 Thành thạo quy trình chuẩn bị tài nguyên để triển khai EC2: Tạo và cấu hình Subnets để phân đoạn mạng Thiết lập Internet Gateway cho kết nối ra bên ngoài Cấu hình Route Tables để quản lý định tuyến traffic Triển khai Security Groups để kiểm soát traffic vào/ra Hiểu về IAM roles và instance profiles cho truy cập EC2 an toàn Học các chiến lược quản lý chi phí AWS sử dụng AWS Budgets Điểm nổi bật sự kiện Cloud Day:\nTham gia các phiên networking với mentors AWS và chuyên gia trong ngành Thu được kiến thức quý giá về xu hướng thị trường AI và Data Hiểu được tiềm năng tương lai và nhu cầu thị trường đối với công nghệ AI Nhận quà lưu niệm từ ban tổ chức sự kiện Bài học chính:\nVPC là nền tảng cho tất cả networking trên AWS - hiểu nó là cực kỳ quan trọng Security Groups hoạt động như tường lửa ảo ở cấp instance IAM roles loại bỏ nhu cầu hardcode credentials trong EC2 instances AWS Budgets giúp ngăn chặn chi phí không mong muốn thông qua giám sát chủ động "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Workshop này được thiết kế dành cho Kỹ sư DevOps, Kiến trúc sư Cloud và Lập trình viên Full-stack mong muốn tìm hiểu quy trình triển khai một ứng dụng hiện đại tích hợp AI trên nền tảng AWS.\nĐể hoàn thành tốt workshop này, người tham gia cần trang bị các kiến thức, kỹ năng và công cụ sau đây.\n1. Yêu cầu về kiến thức kỹ thuật Kiến thức nền tảng AWS (AWS Fundamentals) Thao tác trên Console: Làm quen với giao diện quản trị AWS Management Console. Dịch vụ cốt lõi: Hiểu biết cơ bản về dịch vụ tính toán như Amazon EC2 và AWS Fargate, các khái niệm mạng trong Amazon VPC, và lưu trữ với Amazon S3. IAM \u0026amp; Bảo mật: Hiểu về AWS Identity and Access Management (IAM), cụ thể là vai trò (Roles), chính sách (Policies), và nguyên tắc đặc quyền tối thiểu (least privilege). Container \u0026amp; Điều phối (Containerization \u0026amp; Orchestration) Docker: Thành thạo trong việc tạo Dockerfile, build images và chạy container trên môi trường local. Cần nắm vững các khái niệm như layers, cổng kết nối (ports) và biến môi trường. Tham khảo Tài liệu Docker. Khái niệm ECS: Làm quen với các thuật ngữ của Amazon ECS bao gồm Task Definitions, Services, Clusters, và sự khác biệt giữa hai loại hình khởi chạy EC2 và Fargate. DevOps \u0026amp; CI/CD Git: Thành thạo quản lý mã nguồn (commit, push, branching) để kích hoạt các quy trình tự động hóa. Luồng CI/CD: Hiểu về nguyên lý Tích hợp liên tục (Continuous Integration) và Chuyển giao liên tục (Continuous Delivery) sử dụng các công cụ như AWS CodePipeline và AWS CodeBuild. Kiến thức cơ bản về mạng (Networking) Giao thức: Hiểu về HTTP/HTTPS, phân giải tên miền DNS với Amazon Route 53, và các khái niệm cân bằng tải sử dụng Application Load Balancer. Bảo mật mạng: Kiến thức về địa chỉ IP (CIDR blocks) và kiểm soát lưu lượng sử dụng Security Groups. 2. Thiết lập môi trường Trước khi bắt đầu workshop, hãy đảm bảo môi trường phát triển cục bộ của bạn đã được cài đặt đầy đủ các công cụ sau:\nTài khoản AWS: Một tài khoản AWS đang hoạt động với quyền Quản trị viên (Administrator access) để khởi tạo tài nguyên. IDE: Một trình soạn thảo mã nguồn như Visual Studio Code hoặc IntelliJ IDEA. Công cụ dòng lệnh (Command Line Tools): AWS CLI (v2): Đã cài đặt và cấu hình với thông tin đăng nhập của bạn. Hướng dẫn cài đặt. Git: Đã cài đặt để sao chép (clone) kho mã nguồn. Tải về. Docker Desktop: Đang chạy trên máy local để kiểm tra hoặc build images nếu cần thiết. Tải Docker. 3. Hạn mức dịch vụ \u0026amp; Chi phí Lưu ý về chi phí: Workshop này sử dụng các tài nguyên không nằm trong gói miễn phí (AWS Free Tier), bao gồm:\nNAT Gateways (Phí theo giờ + Phí xử lý dữ liệu) Application Load Balancers ECS Fargate Tasks (Tính theo vCPU/Memory sử dụng) Amazon RDS \u0026amp; ElastiCache Vui lòng đảm bảo dọn dẹp tài nguyên ngay sau khi hoàn thành workshop để tránh phát sinh chi phí không mong muốn. Hướng dẫn dọn dẹp sẽ được cung cấp ở phần cuối của tài liệu này.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.3-network/5.3.2-alb/","title":"Cấu hình Application Load Balancer (ALB)","tags":[],"description":"","content":"Application Load Balancer (ALB) đóng vai trò là cổng vào duy nhất cho mọi lưu lượng truy cập đến nền tảng. Nó chịu trách nhiệm phân phối yêu cầu đến các container phù hợp (Frontend hoặc Backend) và xử lý mã hóa SSL.\n1. Tạo Security Group cho ALB Trước khi tạo Load Balancer, chúng ta cần một lớp tường lửa cho phép truy cập từ Internet.\nTruy cập EC2 Dashboard \u0026gt; Security Groups \u0026gt; Create security group. Security group name: alb-sg. Description: Allow http and https traffic. VPC: Chọn band-up-vpc. Inbound rules: Thêm các quy tắc sau để cho phép truy cập từ bất kỳ đâu: Type: HTTP | Port: 80 | Source: Anywhere-IPv4 (0.0.0.0/0). Type: HTTPS | Port: 443 | Source: Anywhere-IPv4 (0.0.0.0/0). Nhấn Create security group. 2. Tạo Target Group ALB cần biết nơi để chuyển tiếp lưu lượng truy cập. Chúng ta sẽ tạo Target Group cho dịch vụ Frontend trước (Backend sẽ cấu hình sau).\nTruy cập EC2 Dashboard \u0026gt; Target groups \u0026gt; Create target group. Choose a target type: Chọn IP addresses (Bắt buộc cho ECS Fargate). Target group name: target-bandup-fe. Protocol: HTTP. Port: 3000 (Next.js frontend của chúng ta chạy trên port 3000). VPC: Chọn band-up-vpc. Nhấn Next. Register targets: Vì chúng ta chưa triển khai ECS task nào, hãy bỏ qua bước này và nhấn Create target group. 3. Khởi tạo Application Load Balancer Bây giờ, chúng ta sẽ kết hợp mọi thứ vào Load Balancer.\nBước 1: Cấu hình cơ bản (Basic Configuration)\nTruy cập Load Balancers \u0026gt; Create load balancer. Chọn Application Load Balancer và nhấn Create. Load balancer name: bandup-public-alb. Scheme: Internet-facing (Cho phép truy cập công khai). IP address type: IPv4. Bước 2: Ánh xạ mạng (Network Mapping)\nVPC: Chọn band-up-vpc. Mappings: Chọn hai Availability Zones (ap-southeast-1a và ap-southeast-1b). Subnets: QUAN TRỌNG - Phải chọn các Public Subnets (public-subnet-1 và public-subnet-2) đã tạo ở phần trước. Lưu ý: Nếu chọn nhầm Private subnets, ALB sẽ không thể nhận truy cập từ Internet. Bước 3: Security Groups \u0026amp; Listeners\nSecurity groups: Bỏ chọn default và chọn alb-sg vừa tạo. Listeners and routing: Protocol: HTTP | Port: 80. Default action: Forward to target-bandup-fe. Nhấn Create load balancer. ALB của bạn đang được khởi tạo. Sau khi chuyển sang trạng thái Active, nó sẽ sẵn sàng điều hướng lưu lượng đến ứng dụng Frontend.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.5-setup-be/5.5.2-rds/","title":"Tạo PostgreSQL RDS","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ khởi tạo một Amazon RDS cho PostgreSQL. Đây sẽ là nơi lưu trữ dữ liệu bền vững chính cho nền tảng IELTS BandUp. Chúng ta sẽ cấu hình nó với tính sẵn sàng cao (High Availability) và bảo mật trong VPC.\n1. Cấu hình Security Group Trước khi tạo cơ sở dữ liệu, chúng ta cần xác định các quy tắc tường lửa.\nBước 1.1: Tạo Backend Security Group Nhóm này dành cho ECS Fargate tasks (lớp ứng dụng).\nTên: ecs-backend-sg. Inbound: Cho phép cổng 8080 (Mặc định của Spring Boot) từ ALB. Bước 1.2: Tạo RDS Security Group Nhóm này được gắn vào chính database.\nTên: rds-sg. Inbound: Cho phép lưu lượng PostgreSQL (Cổng 5432) chỉ từ ecs-backend-sg vừa tạo ở trên. Điều này đảm bảo chỉ ứng dụng của chúng ta mới có thể giao tiếp với database. 2. Tạo DB Subnet Group RDS cần biết những subnet nào nó được phép sử dụng. Chúng ta sẽ gom nhóm các subnet database riêng tư lại với nhau.\nTruy cập Amazon RDS \u0026gt; Subnet groups \u0026gt; Create DB subnet group. Tên: bandup-db-subnet-group. VPC: Chọn band-up-vpc. Add subnets: Chọn các Availability Zone và chọn private-database-subnet-1 cùng private-database-subnet-2. 3. Khởi tạo Database Bây giờ, chúng ta sẽ khởi tạo instance PostgreSQL.\nTruy cập Databases \u0026gt; Create database. Phương thức tạo: Standard create. Engine options: PostgreSQL (Phiên bản 17.6 hoặc mới nhất). Availability and durability: Chọn Multi-AZ DB instance. Tùy chọn này tạo một DB chính và một bản sao đồng bộ (standby) ở một Availability Zone khác để tự động chuyển đổi khi có sự cố. Settings: DB instance identifier: bandup-db. Master username: postgres. Credential management: Self managed. Master password: Đặt mật khẩu mạnh (hãy lưu lại để dùng sau này). Instance configuration: DB instance class: Burstable classes -\u0026gt; db.t4g.micro (Tiết kiệm chi phí cho workshop). Storage: gp3 (General Purpose SSD) với dung lượng 20 GiB. Connectivity: Compute resource: Chọn Don\u0026rsquo;t connect to an EC2 compute resource. VPC: band-up-vpc. DB subnet group: bandup-db-subnet-group (Đã tạo ở bước 2). Public access: No (Rất quan trọng để bảo mật). VPC security group: Chọn existing -\u0026gt; rds-sg. Database authentication: Password authentication. Monitoring: Bật Performance Insights (lưu trữ 7 ngày). Additional configuration: Initial database name: band_up (Quan trọng: Hibernate sẽ tìm tên DB này khi khởi động). Backup: Bật sao lưu tự động. Encryption: Bật mã hóa. Nhấn Create database. Quá trình khởi tạo sẽ mất vài phút để hoàn tất. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.4-setup-fe/5.4.2-ecr/","title":"Thiết lập ECR &amp; IAM Role","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ chuẩn bị hạ tầng AWS cần thiết để lưu trữ các container image. Quá trình này bao gồm việc kiểm tra trạng thái ban đầu, tạo IAM Role cần thiết cho tính năng sao chép của ECR, và khởi tạo repository.\n1. Kiểm tra trạng thái ECR Đầu tiên, kiểm tra trạng thái hiện tại của Private Registry. Ban đầu, chưa có repository nào được tạo.\n2. Tạo IAM Role cho ECR Chúng ta cần tạo một Service-Linked Role cho phép Amazon ECR thực hiện các hành động sao chép (replication) qua các region hoặc tài khoản khác.\nTruy cập IAM \u0026gt; Roles \u0026gt; Create role. Select trusted entity: Chọn AWS service. Service or use case: Chọn Elastic Container Registry từ danh sách. Use case: Chọn Elastic Container Registry - Replication để cho phép ECR sao chép image. Add permissions: Xác nhận rằng chính sách ECRReplicationServiceRolePolicy đã được đính kèm. Đây là policy mặc định cấp các quyền cần thiết. Name, review, and create: Tên role được đặt tự động là AWSServiceRoleForECRReplication. Xem lại cấu hình và tạo role. Kết quả: Role đã được tạo thành công và xuất hiện trong danh sách IAM Roles. 3. Tạo ECR Repository Tiếp theo, chúng ta tạo kho lưu trữ cho image frontend.\nTruy cập Amazon ECR \u0026gt; Create repository. General settings: Repository name: band-up-frontend. Visibility settings: Private. Image tag settings: Giữ chế độ Mutable để cho phép ghi đè các image tag. Kết quả: Repository band-up-frontend đã được tạo thành công với mã hóa mặc định AES-256. 4. Cấu hình Truy cập CLI (CLI Access) Để đẩy image từ máy local lên AWS, bạn cần quyền truy cập thông qua AWS CLI. Chúng ta sẽ tạo Access Key cho IAM User của bạn.\nTruy cập IAM Dashboard \u0026gt; Users \u0026gt; Chọn user của bạn (ví dụ: NamDang). Chuyển sang tab Security credentials và nhấn Create access key. Use case: Chọn Command Line Interface (CLI). Description tag: Nhập mô tả (ví dụ: ECR Push Key) và nhấn Create access key. Lấy khóa: Quan trọng! Hãy sao chép hoặc tải về Access Key ID và Secret Access Key ngay lập tức, vì bạn sẽ không thể xem lại Secret Key sau này. 5. Cấu hình AWS CLI Mở terminal trên máy của bạn và cấu hình AWS CLI với thông tin xác thực vừa tạo.\naws configure Nhập các thông tin sau khi được hỏi:\nAWS Access Key ID: [Dán Key ID của bạn] AWS Secret Access Key: [Dán Secret Key của bạn] Default region name: ap-southeast-1 Default output format: json 6. Đẩy Image lên ECR (Push) Khi CLI đã được cấu hình, chúng ta tiến hành xác thực Docker và đẩy image lên.\nBước 1: Đăng nhập vào ECR Chạy lệnh đăng nhập để xác thực Docker client với registry của AWS.\naws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin [Account-ID]https://www.google.com/search?q=.dkr.ecr.ap-southeast-1.amazonaws.com Kết quả mong đợi: Login Succeeded\nBước 2: Gán Tag cho Image Gán tag cho image local band-up-frontend:latest với đường dẫn URI đầy đủ của ECR và phiên bản (ví dụ: v1.0.0).\ndocker tag band-up-frontend:latest [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:v1.0.0 Bước 3: Thực hiện Push Chạy lệnh push để tải các layer của image lên AWS.\ndocker push [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:v1.0.0 7. Kiểm tra kết quả cuối cùng Quay lại Amazon ECR Console và mở repository band-up-frontend. Bạn sẽ thấy image với tag v1.0.0 đã xuất hiện trong danh sách.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.6-ai-service/5.6.2-sqs-queues/","title":"SQS Queues","tags":[],"description":"","content":"Tổng Quan Tạo Amazon SQS queues cho asynchronous AI processing với Dead Letter Queues cho failed messages.\nTạo Writing Assessment Queue Setting Value Name ielts-ai-dev-writing-evaluation Type Standard Visibility timeout 5 minutes Message retention 14 days Dead-letter queue ielts-ai-dev-writing-evaluation-dlq Max receives 3 Create Speaking Assessment Queue Setting Value Name ielts-ai-dev-speaking-evaluation Visibility timeout 15 minutes Dead-letter queue ielts-ai-dev-speaking-evaluation-dlq Create Flashcard Generation Queue Setting Value Name ielts-ai-dev-flashcard-generation Visibility timeout 15 minutes Dead-letter queue ielts-ai-dev-flashcard-generation-dlq AWS CLI Commands # Tạo Dead Letter Queue aws sqs create-queue --queue-name ielts-writing-dlq # Tạo main queue với DLQ aws sqs create-queue \\ --queue-name ielts-writing-queue \\ --attributes \u0026#39;{ \u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;300\u0026#34;, \u0026#34;MessageRetentionPeriod\u0026#34;: \u0026#34;1209600\u0026#34;, \u0026#34;RedrivePolicy\u0026#34;: \u0026#34;{\\\u0026#34;deadLetterTargetArn\\\u0026#34;:\\\u0026#34;arn:aws:sqs:ap-southeast-1:{account}:ielts-writing-dlq\\\u0026#34;,\\\u0026#34;maxReceiveCount\\\u0026#34;:\\\u0026#34;3\\\u0026#34;}\u0026#34; }\u0026#39; # Lặp lại cho speaking và flashcard queues aws sqs create-queue --queue-name ielts-speaking-dlq aws sqs create-queue --queue-name ielts-speaking-queue \\ --attributes \u0026#39;{\u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;900\u0026#34;}\u0026#39; aws sqs create-queue --queue-name ielts-flashcard-dlq aws sqs create-queue --queue-name ielts-flashcard-queue \\ --attributes \u0026#39;{\u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;900\u0026#34;}\u0026#39; Tóm Tắt Queue Queue Visibility Timeout DLQ Max Receives ielts-writing-queue 5 min ielts-writing-dlq 3 ielts-speaking-queue 15 min ielts-speaking-dlq 3 ielts-flashcard-queue 15 min ielts-flashcard-dlq 3 Bước Tiếp Theo Tiến hành đến Lambda Functions.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.7-cicd-pipeline/5.7.2-test-gwe/","title":"Tạo CodePipeline với trigger theo tag GitLab","tags":[],"description":"","content":"Thiết kế CodePipeline (Source → Build → Deploy) Build (CodeBuild) Project: dự án CodeBuild của dự án này (Source = CodePipeline) Environment variables: theo nhu cầu build của dự án Buildspec: dùng buildspec.yml có sẵn trong repository Hướng dẫn tạo CodePipeline Ở phần chọn tùy chọn tạo pipeline, chọn Build custom pipeline. Trong tab pipeline settings, đặt tên pipeline và dùng các thiết lập mặc định. Bật webhook events và thêm bộ lọc theo tag. Đặt mẫu tag là \u0026ldquo;v*\u0026rdquo;. Thêm dự án frontend/backend bằng AWS CodeBuild ở bước Build. Ở bước Deploy, chọn Amazon ECS làm nhà cung cấp triển khai. Chỉ định cluster và service để deploy. Điền file image definition như minh họa. Gửi tạo và hoàn tất, pipeline sẽ được tạo. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch: AWS Cloud Mastery Series #1 — AI/ML/GenAI on AWS Mục đích của sự kiện Cung cấp cái nhìn tổng quan về bối cảnh AI/ML tại Việt Nam. Giới thiệu chi tiết các dịch vụ AI/ML quan trọng của AWS, đặc biệt là Amazon SageMaker. Đi sâu vào Generative AI thông qua Amazon Bedrock, bao gồm các Foundation Models và các kỹ thuật triển khai hiện đại (RAG, Prompt Engineering). Nội dung nổi bật Sáng: AWS AI/ML Services Overview Giới thiệu: tổng quan về bối cảnh AI/ML tại Việt Nam và mục tiêu của workshop. Amazon SageMaker: nền tảng ML end-to-end của AWS. Quy trình ML: chuẩn bị dữ liệu (Data Preparation), gắn nhãn (Labeling), huấn luyện (Training), tinh chỉnh (Tuning), và triển khai mô hình (Deployment). Tích hợp MLOps. Live demo: walkthrough SageMaker Studio. Chiều: Generative AI with Amazon Bedrock Foundation Models: so sánh và hướng dẫn chọn giữa Claude, Llama, Titan, v.v. Prompt Engineering: Kỹ thuật nâng cao: Chain-of-Thought reasoning, Few-shot learning. Retrieval-Augmented Generation (RAG): Kiến trúc RAG và cách tích hợp với Knowledge Base bên ngoài. Bedrock Agents: xây dựng multi-step workflows và tích hợp công cụ. Guardrails: nguyên tắc an toàn và lọc nội dung. Live demo: xây dựng chatbot Generative AI sử dụng Bedrock. Những gì học được / Giá trị rút ra SageMaker: hiểu được SageMaker như một nền tảng toàn diện cho toàn bộ vòng đời ML (data prep → training → deployment). Bedrock \u0026amp; GenAI: nắm vai trò của Amazon Bedrock, biết so sánh các FM và hiểu các kỹ thuật cốt lõi như Prompt Engineering, RAG. Ứng dụng vào dự án: kiến thức về RAG và Bedrock Agents hữu ích để nâng cấp tính năng AI/Chatbot trong dự án Travel-Guided. Trải nghiệm Live Demo giúp thấy luồng triển khai thực tế và tốc độ prototyping với Bedrock. Trải nghiệm trong event Ấn tượng với các Live Demo, đặc biệt là xây dựng chatbot GenAI dùng Bedrock nhanh chóng. Cơ hội kết nối và trao đổi với các chuyên gia về AI/ML tại Việt Nam. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3 Khắc phục vấn đề tài khoản AWS và tạo tài khoản mới nếu cần. Thành thạo cấu hình Hybrid DNS với Route 53 Resolver. Triển khai và hiểu VPC Peering cho giao tiếp giữa các VPC. Thảo luận kế hoạch dự án và chọn ngôn ngữ lập trình với team. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 21/09/2025 23/09/2025 Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 3 - Hoàn thành Lab 10: Route 53 và cấu hình Hybrid DNS.\n- Khởi chạy máy chủ ảo để triển khai và kiểm tra DNS.\n- Hoàn thành: Hybrid DNS Management with Amazon Route 53. 24/09/2025 25/09/2025 FCJ Playlist 4 - Triển khai VPC Peering cho giao tiếp private giữa các VPC.\n- Tạo các tài nguyên cần thiết cho cấu hình VPC Peering.\n- Dọn dẹp tài nguyên sau khi hoàn thành.\n- Hoàn thành: Network Integration with VPC Peering. 25/09/2025 26/09/2025 AWS VPC Peering 5 - Tham gia họp nhóm để thảo luận kế hoạch dự án và chọn ngôn ngữ lập trình.\n- Đặt deadline cho các thành viên nghiên cứu công nghệ đã chọn. 28/09/2025 28/09/2025 Họp nhóm Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Hybrid DNS Management with Amazon Route 53 Mạng ✅ Network Integration with VPC Peering Mạng ✅ Networking on AWS Workshop Mạng ✅ Infrastructure as Code with AWS CloudFormation DevOps ✅ Cloud Development with AWS Cloud9 Phát triển ✅ Static Website Hosting with Amazon S3 Lưu trữ ✅ Kết quả đạt được tuần 3 Kỹ năng kỹ thuật đã tiếp thu:\nRoute 53 và Hybrid DNS:\nCấu hình thành công hạ tầng Hybrid DNS với Route 53 Resolver Tạo và cấu hình Outbound Endpoints để chuyển tiếp DNS queries Thiết lập Route 53 Resolver rules cho conditional DNS resolution Triển khai Inbound Endpoints cho DNS queries từ on-premises đến AWS Kết nối thành công với RD Gateway Server trong các bài thực hành VPC Peering:\nNắm vững khái niệm VPC Peering cho giao tiếp private giữa các VPC mà không qua internet công cộng Kích hoạt Cross-Zone and Cross-Region DNS Resolution trong VPC Peering: EC2 instances có thể phân giải DNS của instances trong VPCs được peering ra địa chỉ IP private Hiểu rằng nếu không có tính năng này, DNS queries trả về public IPs, định tuyến traffic qua internet Học quy trình dọn dẹp tài nguyên để tránh chi phí không cần thiết Infrastructure as Code:\nHọc cách provision tài nguyên AWS sử dụng CloudFormation templates Hiểu nguyên tắc quản lý hạ tầng declarative Khám phá AWS Cloud9 như môi trường phát triển trên cloud Hợp tác nhóm:\nTham gia họp nhóm để xác định hướng đi dự án Chọn ngôn ngữ lập trình cho dự án Thiết lập deadline cho các thành viên nghiên cứu công nghệ đã chọn Tiếp tục hành trình học tập với sự hỗ trợ của FCJ team Bài học chính:\nHybrid DNS cho phép phân giải DNS liền mạch giữa on-premises và AWS VPC Peering hiệu quả về chi phí để kết nối VPCs nhưng có giới hạn (không có transitive peering) CloudFormation templates đảm bảo triển khai hạ tầng nhất quán, có thể lặp lại AWS Cloud9 loại bỏ sự phức tạp của việc thiết lập môi trường phát triển local "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Phân tích nội dung media bằng các dịch vụ AI của AWS￼ Bài viết trình bày một kiến trúc AWS hướng sự kiện giúp tự động chuyển đổi dữ liệu âm thanh/video thô thành thông tin có cấu trúc và có thể tìm kiếm. Khi media được tải lên S3, Step Functions sẽ kích hoạt Amazon Transcribe để chuyển giọng nói thành văn bản và Amazon Bedrock để phân tích bằng AI, xác định quảng cáo, phỏng vấn và các phân đoạn quan trọng. Kết quả được lưu trong data lake, truy vấn bằng Athena, trực quan hóa bằng QuickSight và tìm kiếm bằng ngôn ngữ tự nhiên thông qua Amazon Q. Bài viết nhấn mạnh yêu cầu bảo mật mạnh, kiểm thử, tối ưu hóa và khả năng mở rộng. Giải pháp phù hợp cho các lĩnh vực như phát thanh – truyền hình, quản lý tri thức doanh nghiệp, giáo dục, pháp lý, y tế và dịch vụ khách hàng.\nBlog 2 - Cải thiện thời gian phản hồi của AI hội thoại cho ứng dụng doanh nghiệp với Amazon Bedrock streaming API và AWS AppSync Bài viết mô tả cách giảm độ trễ của AI hội thoại bằng cách stream phản hồi của LLM trên Amazon Bedrock thông qua AWS AppSync. Pipeline Lambda–SNS–Lambda gọi API converse_stream, sau đó đẩy các token phản hồi từng phần lên frontend thông qua AppSync subscriptions, giúp người dùng thấy câu trả lời ngay khi mô hình tạo ra. Cơ chế buffer giúp giảm số lượng cuộc gọi mạng, tăng tốc độ trong khi vẫn tuân thủ yêu cầu bảo mật cấp doanh nghiệp (VPC, OAuth, kiểm soát luồng dữ liệu). Một tập đoàn tài chính toàn cầu đã giảm thời gian phản hồi ban đầu từ ~10 giây xuống còn 2–3 giây. Terraform và mã mẫu cho phép triển khai nhanh chóng.\nBlog 3 - Nâng cao quyền riêng tư dữ liệu y tế thông qua hệ thống khử định danh ảnh y khoa dựa trên AI PixelGuard là hệ thống khử định danh hình ảnh y khoa trên AWS, sử dụng hơn 75 mô hình AI để loại bỏ hoặc làm mờ thông tin nhận dạng trong metadata và pixel mà vẫn bảo toàn giá trị lâm sàng. Giải pháp hỗ trợ nhiều định dạng (DICOM, JPEG, PNG, NIfTI), phát hiện văn bản burned-in bằng OCR và ML, và tạo file ánh xạ được mã hóa cho phép truy xuất ngược khi được ủy quyền. PixelGuard đảm bảo bảo mật thông qua SSO, API Gateway, Cognito và AWS KMS. Giải pháp giúp tổ chức tuân thủ HIPAA/GDPR, chia sẻ dữ liệu nghiên cứu an toàn và thúc đẩy phát triển AI trong lĩnh vực hình ảnh y khoa.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/3-blogstranslated/3.3-blog3/","title":"Multi-Region keys: Một cách tiếp cận mới cho nhân bản khóa trong AWS Payment Cryptography","tags":[],"description":"","content":"Ngày đăng: 2025‑09‑16 – Tác giả: Ruy Cavalcanti và Mark Cline trong Announcements, Financial Services, Industries, Intermediate (200), Security, Identity, \u0026amp; Compliance, Technical How-to\nTrong bài viết trước của chúng tôi (Phần 1 của loạt bài về nhân bản khóa), Automatically replicate your card payment keys across AWS Regions, chúng tôi đã khám phá một kiến trúc serverless hướng sự kiện sử dụng AWS PrivateLink để nhân bản an toàn các khóa thanh toán thẻ giữa các Region AWS. Giải pháp đó minh họa cách xây dựng framework nhân bản khóa mã hóa thanh toán tùy chỉnh.\nDựa trên phản hồi từ khách hàng mong muốn cách thức tự động cao hơn, không cần code, chúng tôi rất vui mừng công bố một tùy chọn bổ sung với Multi-Region keys cho AWS Payment Cryptography trong Phần 2 của loạt bài.\nVới tính năng mới này, bạn có thể tự động đồng bộ các khóa mã hóa thanh toán từ Region chính sang các Region khác mà bạn chọn, cải thiện khả năng chịu lỗi và tính sẵn sàng của ứng dụng thanh toán. Bạn cũng có thể lựa chọn giữa nhân bản ở cấp tài khoản (account-level) hoặc cấp khóa (key-level), mang lại linh hoạt hơn trong quản lý khóa thanh toán giữa các Region.\nMulti-Region keys: Tổng quan và lợi ích Tính năng mới nhân bản khóa Multi-Region cho AWS Payment Cryptography cung cấp cho bạn quyền kiểm soát linh hoạt đối với chiến lược nhân bản khóa thông qua các khả năng chính sau:\nQuyết định xem các khóa có được nhân bản hay không Lựa chọn các Region cụ thể để nhân bản khóa Quản lý các thay đổi cấu hình nhân bản Cấu hình nhân bản ở cấp tài khoản hoặc cấp khóa tùy theo nhu cầu kinh doanh Multi-Region keys mang đến nhiều lợi ích cho hoạt động thanh toán toàn cầu, bao gồm:\nTăng tính sẵn sàng: Truy cập khóa thanh toán ngay cả khi một Region không khả dụng. Khả năng phục hồi thảm họa: Duy trì hoạt động kinh doanh khi có sự cố bằng cách nhân bản khóa giữa các Region. Vận hành toàn cầu: Hỗ trợ xử lý thanh toán trên nhiều vùng địa lý. Quản lý đơn giản: Kiểm soát tập trung với khả năng phân tán. ID khóa nhất quán: ID khóa giống nhau giữa các Region giúp đơn giản hóa phát triển ứng dụng. Tùy chọn cấu hình Payment Cryptography cung cấp hai phương thức riêng biệt để cấu hình nhân bản khóa Multi-Region, giúp bạn linh hoạt trong việc triển khai chiến lược phù hợp nhất với tổ chức: bạn có thể chọn giữa cách tiếp cận rộng (cấp tài khoản) hoặc cách tiếp cận chi tiết hơn (cấp khóa).\nCấp tài khoản (Account-level) Với cấu hình cấp tài khoản, AWS sẽ tự động sao chép các khóa đối xứng có thể xuất (exportable symmetric keys) được tạo trong tài khoản Payment Cryptography của bạn từ Region chính mà bạn chỉ định sang các Region khác mà bạn chỉ định. Điều này giúp đơn giản hóa việc quản lý khóa trong các triển khai đa vùng, cung cấp tính sẵn có nhất quán của khóa trong các Region bạn chọn và giảm bớt chi phí vận hành quản lý khóa.\nĐể cấu hình nhân bản cấp tài khoản bằng AWS Command Line Interface (AWS CLI), sử dụng API mới enable-default-key-replication-regions để đặt các Region mà AWS sẽ nhân bản khóa của bạn. Để loại bỏ Region khỏi danh sách nhân bản mặc định, dùng API disable-default-key-replication-regions .\nLưu ý: Chỉ các khóa đối xứng được tạo sau khi nhân bản cấp tài khoản được bật mới được nhân bản.\nNhân bản cấp khóa (Key-level replication) Bằng cách sử dụng key-level replication, bạn có thể đạt được mức kiểm soát chi tiết hơn thông qua việc:\nChỉ định các khóa cụ thể là multi-Region keys. Xác định mục tiêu nhân bản tùy chỉnh cho từng khóa multi-Region. Duy trì các khóa riêng biệt cho từng Region khi cần thiết. Lưu ý: Trong mỗi Region, Payment Cryptography duy trì khả năng dự phòng của khóa trên nhiều Availability Zone để đảm bảo tính sẵn sàng cao. Multi-Region key replication mở rộng điều này ra phạm vi địa lý, giúp tăng cường khả năng chống chịu với sự cố mất kết nối giữa các Region trong khi vẫn giữ quyền kiểm soát vị trí lưu trữ khóa.\nBạn có thể chỉ định các Region nhân bản ngay khi tạo khóa bằng cách sử dụng tham số --replication-regions trong AWS CLI, thông qua các API create-key hoặc import-key. Đối với các khóa đã tồn tại, bạn có thể sử dụng các API mới add-key-replication-regions và remove-key-replication-regions để quản lý những Region nào sẽ nhận bản nhân bản của khóa.\nQuan trọng: Khi bạn chỉ định các Region nhân bản trong quá trình tạo khóa, các thiết lập này sẽ có độ ưu tiên cao hơn so với cấu hình nhân bản mặc định ở cấp tài khoản.\nCách hoạt động Hình 1 mô tả quy trình khi bạn nhân bản một khóa trong Payment Cryptography:\nKhóa được tạo trong Region chính mà bạn chỉ định. Payment Cryptography tự động nhân bản không đồng bộ (asynchronously) phần key material đến các Region được chọn làm bản sao. Các khóa nhân bản duy trì cùng một Key ID trên tất cả các Region — chỉ phần Region trong Amazon Resource Name (ARN) thay đổi. Khóa trong Region chính được gắn nhãn MultiRegionKeyType: PRIMARY Các khóa trong các Region nhân bản được gắn nhãn MultiRegionKeyType: REPLICA và có tham chiếu tới Region chính. Khi xóa một khóa, việc xóa này sẽ tự động lan truyền (cascade) từ khóa chính sang các bản sao ở các Region khác. | Hình 1: Minh họa quá trình nhân bản khóa từ us-east-1 sang us-west-2\nVí dụ: Tạo khóa multi-Region ở cấp khóa Ví dụ sau minh họa việc tạo card verification key (CVK) trong Region chính (us-east-1) với việc nhân bản sang us-west-2:\naws payment-cryptography create-key \\\n--exportable \\\n--key-attributes KeyAlgorithm=TDES_2KEY,\\\nKeyUsage=TR31_C0_CARD_VERIFICATION_KEY,\\\nKeyClass=SYMMETRIC_KEY,KeyModesOfUse=\u0026rsquo;{Generate=true,Verify=true}\u0026rsquo; \\\n--region us-east-1 \\\n--replication-regions us-west-2\nKết quả phản hồi cho thấy khóa đang được tạo và quá trình nhân bản đang diễn ra:\n{\n\u0026ldquo;Key\u0026rdquo;: {\n\u0026quot;KeyArn\u0026quot;: \u0026quot;arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk\u0026quot;, \u0026quot;KeyAttributes\u0026quot;: { \u0026quot;KeyUsage\u0026quot;: \u0026quot;TR31\\_C0\\_CARD\\_VERIFICATION\\_KEY\u0026quot;, \u0026quot;KeyClass\u0026quot;: \u0026quot;SYMMETRIC\\_KEY\u0026quot;, \u0026quot;KeyAlgorithm\u0026quot;: \u0026quot;TDES\\_2KEY\u0026quot;, \u0026quot;KeyModesOfUse\u0026quot;: { \u0026quot;Encrypt\u0026quot;: false, \u0026quot;Decrypt\u0026quot;: false, \u0026quot;Wrap\u0026quot;: false, \u0026quot;Unwrap\u0026quot;: false, \u0026quot;Generate\u0026quot;: true, \u0026quot;Sign\u0026quot;: false, \u0026quot;Verify\u0026quot;: true, \u0026quot;DeriveKey\u0026quot;: false, \u0026quot;NoRestrictions\u0026quot;: false } }, \u0026quot;KeyCheckValue\u0026quot;: \u0026quot;CC5EE2\u0026quot;, \u0026quot;KeyCheckValueAlgorithm\u0026quot;: \u0026quot;ANSI\\_X9\\_24\u0026quot;, \u0026quot;Enabled\u0026quot;: true, \u0026quot;Exportable\u0026quot;: true, \u0026quot;KeyState\u0026quot;: \u0026quot;CREATE\\_COMPLETE\u0026quot;, \u0026quot;KeyOrigin\u0026quot;: \u0026quot;AWS\\_PAYMENT\\_CRYPTOGRAPHY\u0026quot;, \u0026quot;CreateTimestamp\u0026quot;: \u0026quot;2025-08-21T15:25:54.475000-03:00\u0026quot;, \u0026quot;UsageStartTimestamp\u0026quot;: \u0026quot;2025-08-21T15:25:54.287000-03:00\u0026quot;, \u0026quot;MultiRegionKeyType\u0026quot;: \u0026quot;PRIMARY\u0026quot;, **\u0026quot;ReplicationStatus\u0026quot;: {** **\u0026quot;us-west-2\u0026quot;: {** **\u0026quot;Status\u0026quot;: \u0026quot;IN\\_PROGRESS\u0026quot;** **}** }, \u0026quot;UsingDefaultReplicationRegions\u0026quot;: false }\n}\nKhi quá trình nhân bản hoàn tất, trạng thái sẽ được cập nhật thành SYNCHRONIZED:\naws payment-cryptography get-key \\\n--key-identifier arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk \\\n--region us-east-1\nKết quả trả về cho thấy khóa chính đã đồng bộ hoàn tất:\n\u0026ldquo;ReplicationStatus\u0026rdquo;: {\n\u0026quot;us-west-2\u0026quot;: { \u0026quot;Status\u0026quot;: \u0026quot;SYNCHRONIZED\u0026quot; } } Bạn có thể truy cập khóa ở Region bản sao (us-west-2) bằng cách sử dụng cùng Key ID, chỉ thay đổi tên Region:\naws payment-cryptography get-key \\\n--key-identifier arn:aws:payment-cryptography:us-west-2:111122223333:key/qs6643jl4ohibtqk \\\n--region us-west-2\nKết quả trả về hiển thị khóa bản sao với tham chiếu đến Region chính (PrimaryRegion: us-east-1).\nNhững điều cần lưu ý Khi sử dụng multi-Region keys, có một số điểm quan trọng cần cân nhắc:\nChỉ hỗ trợ symmetric keys có thuộc tính exportable, không hỗ trợ asymmetric keys. Chi phí tính riêng cho từng Region — ví dụ, nhân bản sang 3 Region sẽ phát sinh chi phí cho khóa chính cộng thêm chi phí của mỗi khóa bản sao. Key alias và tags cần được quản lý riêng ở từng Region vì chúng không được nhân bản tự động. Khóa chính (primary key) có thể được chỉnh sửa hoặc cập nhật, trong khi khóa bản sao (replica) chỉ là bản read-only hỗ trợ các thao tác mật mã (cryptographic operations). Mọi thay đổi phải được thực hiện ở khóa chính và Payment Cryptography sẽ tự động đồng bộ sang các Region bản sao. Theo dõi trạng thái nhân bản để đảm bảo các thay đổi đã được đồng bộ thành công. Hành vi khi xóa khóa Khi lên lịch xóa khóa chính:\nTất cả các khóa bản sao sẽ bị xóa ngay lập tức. Khóa chính sẽ chuyển sang trạng thái pending deletion trong tối thiểu 3 ngày, trong thời gian này có thể hủy xóa (cancel deletion). Nếu bạn khôi phục khóa chính, bạn cần bật lại nhân bản để tái tạo các bản sao ở các Region mong muốn. Sau khi thời gian 3 ngày trôi qua, khóa chính sẽ bị xóa vĩnh viễn và không thể phục hồi. Việc xóa một replica key chỉ ảnh hưởng đến Region đó, không ảnh hưởng đến khóa chính hoặc các bản sao khác. Mô hình nhất quán cuối cùng (Eventual consistency) Nhân bản khóa đa vùng hoạt động theo mô hình eventual consistency — nghĩa là các thay đổi có thể không xuất hiện ngay lập tức trên tất cả các Region.\nDo đó, ứng dụng nên được thiết kế để xử lý mô hình này và không giả định rằng khóa hoặc thay đổi sẽ có sẵn ngay lập tức ở các Region bản sao.\nNếu ứng dụng của bạn yêu cầu tính nhất quán mạnh (strong consistency), hãy triển khai cơ chế polling bằng cách sử dụng API GetKey để xác minh rằng các thay đổi đã được đồng bộ trước khi tiến hành các thao tác mã hóa.\nGhi nhật ký và giám sát (Logging and monitoring) Payment Cryptography ghi lại hoạt động API thông qua AWS CloudTrail, hiện đã bao gồm các sự kiện (event) và thuộc tính (attribute) mới dành riêng cho tính năng Multi-Region key replication.\nSự kiện CloudTrail mới Dịch vụ này ghi nhận một loại sự kiện mới có tên SynchronizeMultiRegionKey, xuất hiện ở cả Region chính và Region bản sao.\nSự kiện ở Region chính: Mỗi Region bản sao được định nghĩa sẽ tạo ra hai sự kiện SynchronizeMultiRegionKey trong Region chính:\nMột sự kiện liên quan đến quá trình export khóa.\n\u0026ldquo;serviceEventDetails\u0026rdquo;: {\n\u0026ldquo;keyArn\u0026rdquo;: \u0026ldquo;arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk\u0026rdquo;,\n\u0026ldquo;replicationRegion\u0026rdquo;: \u0026ldquo;us-west-2\u0026rdquo;,\n\u0026ldquo;replicationType\u0026rdquo;: \u0026ldquo;ExportKeyReplica\u0026rdquo;\n},\nMột sự kiện liên quan đến quá trình import khóa.\n\u0026ldquo;serviceEventDetails\u0026rdquo;: {\n\u0026ldquo;keyArn\u0026rdquo;: \u0026ldquo;arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk\u0026rdquo;,\n\u0026ldquo;replicationRegion\u0026rdquo;: \u0026ldquo;us-west-2\u0026rdquo;,\n\u0026ldquo;replicationType\u0026rdquo;: \u0026ldquo;ImportKeyReplica\u0026rdquo;\n},\nSự kiện ở Region bản sao: Mỗi Region bản sao ghi lại một sự kiện SynchronizeMultiRegionKey tương ứng với quá trình import khóa:\n\u0026ldquo;eventName\u0026rdquo;: \u0026ldquo;SynchronizeMultiRegionKey\u0026rdquo;,\n\u0026ldquo;awsRegion\u0026rdquo;: \u0026ldquo;us-west-2\u0026rdquo;,\n\u0026ldquo;serviceEventDetails\u0026rdquo;: {\n\u0026quot;keyArn\u0026quot;: \u0026quot;arn:aws:payment-cryptography:us-west-2:111122223333:key/qs6643jl4ohibtqk\u0026quot;, \u0026quot;replicationRegion\u0026quot;: \u0026quot;us-west-2\u0026quot;, **\u0026quot;replicationType\u0026quot;: \u0026quot;ImportKeyReplica\u0026quot;** }, Thuộc tính CloudTrail mới Các API quản lý khóa (key management APIs) giờ đây bao gồm những thuộc tính mới để phản ánh hoạt động của Multi-Region replication.\nVí dụ, sự kiện CreateKey trong Region chính (us-east-1) nay có thêm thuộc tính:\n\u0026ldquo;requestParameters\u0026rdquo;: {\n**\u0026quot;replicationRegions\u0026quot;: \\[\u0026quot;us-west-2\u0026quot;\\]** }\nSự kiện CreateKey trong Region bản sao (us-west-2) sẽ phản ánh quá trình khởi tạo khóa replica tương ứng, với các thông tin tương tự về KeyUsage, Algorithm và KeyCheckValue.\nBắt đầu sử dụng Để bắt đầu sử dụng Multi-Region key replication trong Payment Cryptography, hãy thực hiện các bước sau:\nXác định Region chính (primary Region).\nXác định các Region bản sao (replica Regions) và quyết định xem bạn sẽ dùng cấu hình account-level hay key-level.\nTạo symmetric key có thể export (exportable symmetric key) mới hoặc cập nhật các khóa hiện có để bật tính năng Multi-Region replication.\nCập nhật ứng dụng của bạn để sử dụng Key ID nhất quán giữa các Region.\nKết luận Tính năng Multi-Region key replication mới trong AWS Payment Cryptography nâng cao khả năng nhân bản khóa tự động, giúp cải thiện khả năng chịu lỗi, tính sẵn sàng, và đơn giản hóa việc quản lý khóa thanh toán toàn cầu. Tính năng này đảm bảo rằng các payment cryptography keys của bạn luôn khả dụng mọi lúc, mọi nơi, đồng thời cung cấp sự linh hoạt trong việc lựa chọn chiến lược nhân bản giữa account-level và key-level, giúp tổ chức tối ưu hiệu năng, bảo mật, và chi phí trong môi trường đa vùng (multi-Region).\nRuy Cavalcanti Ruy là Senior Security Architect là chuyên gia trong ngành tài chính Mỹ Latinh tại AWS. Ông đã làm việc trong lĩnh vực CNTT và Bảo mật hơn 19 năm, giúp khách hàng xây dựng kiến ​​trúc bảo mật và giải quyết các thách thức về bảo vệ dữ liệu và tuân thủ. Khi không phải thiết kế các giải pháp bảo mật, ông thích chơi guitar, nấu món thịt nướng kiểu Brazil và dành thời gian cho gia đình và bạn bè. Mark Cline Mark là Trưởng phòng Quản lý Sản phẩm tại AWS Payments, nơi ông có hơn 15 năm kinh nghiệm trong lĩnh vực dịch vụ tài chính trên nhiều trường hợp sử dụng và lĩnh vực khác nhau. Ông hợp tác với các ngân hàng, tổ chức tài chính và nhà cung cấp công nghệ hàng đầu để giảm bớt gánh nặng cho hệ thống thanh toán, cho phép khách hàng tập trung vào đổi mới. Khi không bận rộn với việc đơn giản hóa thanh toán, bạn có thể thấy ông đang huấn luyện các đội bóng chày nhỏ hoặc chạy bộ. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.4-setup-fe/5.4.3-sg/","title":"Cấu hình Security Group","tags":[],"description":"","content":"Các container Frontend của chúng ta hoạt động trong Private Subnet. Để cho phép chúng nhận lưu lượng truy cập, ta cần cấu hình Security Group đóng vai trò như một bức tường lửa ảo.\nTuân thủ nguyên tắc bảo mật (best practices), chúng ta sẽ chỉ cho phép truy cập từ Application Load Balancer (ALB) vào cổng 3000. Mọi truy cập trực tiếp từ Internet hoặc các nguồn khác đều sẽ bị chặn.\n1. Tạo Security Group Truy cập EC2 Dashboard \u0026gt; Security Groups \u0026gt; Create security group. Basic details (Thông tin cơ bản): Security group name: ecs-private-sg. Description: security group for ecs. VPC: Chọn band-up-vpc. 2. Cấu hình Inbound Rules (Quy tắc chiều vào) Đây là bước quan trọng nhất. Chúng ta cần cho phép ALB giao tiếp với ứng dụng Next.js.\nInbound rules: Nhấn Add rule. Type: Custom TCP. Port range: 3000 (Cổng mà ứng dụng Next.js đang lắng nghe). Source: Chọn Custom và tìm chọn Security Group ID của ALB (ví dụ: alb-sg). Lưu ý: Bằng cách chọn ID của Security Group thay vì dải IP, chúng ta đảm bảo rằng chỉ có lưu lượng xuất phát từ Load Balancer mới được chấp nhận. Outbound rules (Quy tắc chiều ra): Giữ nguyên mặc định (Allow all traffic) để container có thể tải các gói tin hoặc gọi API bên ngoài. Nhấn Create security group. Security Group hiện đã sẵn sàng để được gắn vào ECS Task trong bước tiếp theo.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.3-network/","title":"Hạ tầng Mạng &amp; Bảo mật","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ xây dựng lớp mạng nền tảng và các thiết lập bảo mật cốt lõi cho IELTS BandUp.\nMột kiến trúc mạng vững chắc là yếu tố then chốt để bảo vệ dữ liệu người dùng và đảm bảo tính sẵn sàng cao của hệ thống. Thay vì sử dụng các cài đặt mạng mặc định, chúng ta sẽ xây dựng một Virtual Private Cloud (VPC) tùy chỉnh, được thiết kế chuyên biệt cho môi trường production. Thiết lập này cho phép kiểm soát chặt chẽ luồng truy cập giữa các thành phần ứng dụng (Frontend, Backend, Database) và Internet.\nNgoài ra, chúng ta sẽ cấu hình các VPC Endpoints để cho phép các container trong mạng nội bộ giao tiếp an toàn với các dịch vụ AWS (như ECR và S3) mà không cần đi qua Internet công cộng, giúp tối ưu hóa cả về bảo mật lẫn hiệu năng mạng.\nCác bước thực hiện Chúng ta sẽ chia quy trình thiết lập hạ tầng thành các nhiệm vụ chính sau:\nVPC \u0026amp; Kết nối: Khởi tạo môi trường mạng cô lập, phân chia thành các Subnet Public/Private và cấu hình Internet Gateway (IGW) cho kết nối ra bên ngoài. Cân bằng tải (ALB): Thiết lập Application Load Balancer và các Target Group để phân phối lưu lượng truy cập đến các ECS task sau này. Bảo mật IAM: Cấp phát ecsTaskExecutionRole để ủy quyền cho Fargate container thực hiện các tác vụ như tải image và ghi log. Cấu hình VPC Endpoints: Thiết lập kết nối riêng tư đến các dịch vụ AWS (ECR, CloudWatch, S3) để bảo mật lưu lượng nội bộ. Nội dung Cấu hình VPC, Subnets \u0026amp; Routing Cài đặt Application Load Balancer (ALB) IAM Roles cho ECS Thiết lập VPC Endpoints "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.3-network/5.3.3-iam/","title":"IAM Roles cho ECS","tags":[],"description":"","content":"Để Amazon ECS có thể quản lý các container, dịch vụ này cần được cấp một số quyền hạn nhất định. Chúng ta phải tạo một IAM Role để ủy quyền cho ECS agent thực hiện các tác vụ như kéo (pull) container image từ Amazon ECR và gửi log đến Amazon CloudWatch thay mặt cho bạn.\nTạo ecsTaskExecutionRole Truy cập IAM Dashboard. Ở thanh điều hướng bên trái, chọn Roles. Nhấn Create role. Bước 1: Thực thể tin cậy (Trusted Entity)\nTrusted entity type: Chọn AWS service. Service or use case: Chọn Elastic Container Service. Chọn Elastic Container Service Task trong các tùy chọn hiện ra. Nhấn Next. Bước 2: Thêm quyền (Permissions)\nTrong thanh tìm kiếm, gõ AmazonECSTaskExecutionRolePolicy. Tích vào ô vuông cạnh tên chính sách AmazonECSTaskExecutionRolePolicy. Lưu ý: Đây là chính sách được AWS quản lý, cung cấp đủ quyền để kéo image từ ECR và tải log lên CloudWatch. Nhấn Next. Bước 3: Đặt tên và Xem lại\nRole name: Nhập ecsTaskExecutionRole. Kiểm tra lại cấu hình và nhấn Create role. Sau khi tạo xong, Role này đã sẵn sàng để gán cho các ECS Task Definition trong các phần tiếp theo của workshop.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.5-setup-be/5.5.3-redis/","title":"Tạo ElastiCache (Redis/Valkey)","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ khởi tạo một kho dữ liệu in-memory để xử lý việc quản lý session và caching cho backend. Chúng ta sẽ sử dụng Amazon ElastiCache với engine Valkey (một nhánh mã nguồn mở hiệu năng cao của Redis được AWS hỗ trợ).\n1. Cấu hình Security Group Đầu tiên, tạo Security Group để cho phép backend giao tiếp với cache cluster.\nTruy cập EC2 \u0026gt; Security Groups \u0026gt; Create security group. Name: redis-sg. Inbound rules: Cho phép lưu lượng Custom TCP tại cổng 6379 từ nguồn là ecs-backend-sg. (Lưu ý: Hãy đảm bảo tạo SG này trước khi vào giao diện ElastiCache).\n2. Tạo Subnet Group Chúng ta cần xác định các subnet mà cache node sẽ hoạt động.\nTruy cập Amazon ElastiCache \u0026gt; Subnet groups \u0026gt; Create subnet group. Name: bandup-cached-subnet-group. VPC: Chọn band-up-vpc. Subnets: Chọn private-database-subnet-1 và private-database-subnet-2 (Availability Zones ap-southeast-1a và 1b). 3. Tạo ElastiCache Cluster Bây giờ chúng ta tiến hành khởi tạo cluster.\nTruy cập ElastiCache \u0026gt; Caches \u0026gt; Create cache. Engine: Chọn Valkey - recommended (Tương thích với Redis OSS). Deployment option: Chọn Node-based cluster (Cho phép kiểm soát loại instance). Creation method: Cluster cache. Cấu hình Cluster: Cluster mode: Disabled (Cấu trúc primary-replica đơn giản là đủ). Name: bandup-redis. Description: in memory db for bandup. Cấu hình Node: Node type: cache.t3.micro (Tiết kiệm chi phí cho workshop). Number of replicas: 0 (Chạy node đơn lẻ). Kết nối (Connectivity): Network type: IPv4. Subnet groups: Chọn bandup-cached-subnet-group. Bảo mật \u0026amp; Mã hóa: Encryption at rest: Enabled (Default key). Encryption in transit: Enabled. Access control: No access control (Chúng ta dựa vào Security Group để bảo mật). Security groups: Chọn redis-sg đã tạo trước đó. Sao lưu: Bật sao lưu tự động (Retention: 1 ngày). Nhấn Create. Trạng thái của cluster sẽ chuyển sang Creating. Sau khi chuyển sang Available, hãy ghi lại Primary Endpoint (có dạng ...cache.amazonaws.com:6379) để sử dụng cấu hình cho backend.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.6-ai-service/5.6.3-lambda-functions/","title":"Lambda Functions","tags":[],"description":"","content":"Tổng Quan Tầng AI Service bao gồm bốn Lambda functions cung cấp sức mạnh cho nền tảng học IELTS. Các functions này xử lý yêu cầu bất đồng bộ qua SQS queues và tích hợp với Google Gemini API và Amazon Bedrock để đánh giá bằng AI.\nLambda Function 1: Writing Evaluator Đánh giá bài luận IELTS Writing Task 1 và Task 2 sử dụng Gemini API với điểm band chi tiết.\nCài Đặt Giá Trị Function name bandup-writing-evaluator Runtime Python 3.11 Memory 1024 MB Timeout 5 phút Trigger SQS (bandup-writing-queue) AI Model Google Gemini 2.0 Flash Triển Khai Chính:\nimport json import os import boto3 import logging from typing import Dict, Any logger = logging.getLogger() logger.setLevel(logging.INFO) # Import từ Lambda layer from lambda_shared.gemini_client import GeminiClient from secrets_helper import get_gemini_api_key def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Đánh giá bài luận IELTS Writing sử dụng Gemini API.\u0026#34;\u0026#34;\u0026#34; # Parse SQS message hoặc API Gateway request if is_sqs_event(event): request_data, job_id = parse_sqs_message(event) update_job_status(job_id, \u0026#39;processing\u0026#39;, \u0026#39;writing\u0026#39;) else: request_data = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) # Lấy API key an toàn từ Secrets Manager gemini_api_key = get_gemini_api_key() # Lấy từ AWS Secrets Manager gemini_client = GeminiClient(api_key=gemini_api_key) # Trích xuất parameters từ request user_id = request_data.get(\u0026#39;user_id\u0026#39;) essay_content = request_data.get(\u0026#39;essay_content\u0026#39;) task_type = request_data.get(\u0026#39;task_type\u0026#39;, \u0026#39;TASK_2\u0026#39;) # Xây dựng prompt đánh giá prompt = build_writing_prompt(essay_content, task_type) # Gọi Gemini API để đánh giá response = gemini_client.generate_evaluation( prompt=prompt, feature=\u0026#39;writing_task2\u0026#39;, max_retries=3, timeout=60 ) # Parse và validate band scores evaluation = parse_gemini_response(response[\u0026#39;content\u0026#39;]) # Xây dựng kết quả với tiêu chí IELTS result = { \u0026#39;session_id\u0026#39;: request_data.get(\u0026#39;session_id\u0026#39;), \u0026#39;overall_band\u0026#39;: evaluation.get(\u0026#39;overall_band\u0026#39;), \u0026#39;task_achievement_band\u0026#39;: evaluation[\u0026#39;task_achievement\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;coherence_band\u0026#39;: evaluation[\u0026#39;coherence_cohesion\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;lexical_band\u0026#39;: evaluation[\u0026#39;lexical_resource\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;grammar_band\u0026#39;: evaluation[\u0026#39;grammatical_range_accuracy\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;feedback\u0026#39;: evaluation } # Lưu vào DynamoDB dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(os.environ.get(\u0026#39;DYNAMODB_EVALUATIONS\u0026#39;)) table.put_item(Item={ \u0026#39;evaluation_id\u0026#39;: result[\u0026#39;session_id\u0026#39;], \u0026#39;user_id\u0026#39;: user_id, \u0026#39;evaluation_type\u0026#39;: \u0026#39;writing\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, **result }) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(result)} Mẫu Prompt Gemini:\ndef build_writing_prompt(essay_content: str, task_type: str) -\u0026gt; str: return f\u0026#34;\u0026#34;\u0026#34;You are an experienced IELTS examiner. Evaluate this essay: Task Type: {task_type} ESSAY: {essay_content} Evaluate using IELTS band descriptors (1-9, 0.5 increments): 1. Task Achievement - Addresses all parts of task 2. Coherence and Cohesion - Logical organization 3. Lexical Resource - Vocabulary range and accuracy 4. Grammatical Range and Accuracy - Sentence structures RESPOND IN JSON FORMAT: {{ \u0026#34;overall_band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;task_achievement\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;coherence_cohesion\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;lexical_resource\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;grammatical_range_accuracy\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;quoted_examples\u0026#34;: [{{\u0026#34;quote\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;issue\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;suggestion\u0026#34;: \u0026#34;...\u0026#34;}}] }}\u0026#34;\u0026#34;\u0026#34; Lambda Function 2: Speaking Evaluator Đánh giá IELTS Speaking sử dụng Gemini native audio processing - rẻ hơn 72% và nhanh gấp 2 lần so với AWS Transcribe.\nCài Đặt Giá Trị Function name bandup-speaking-evaluator Runtime Python 3.11 Memory 2048 MB Timeout 5 phút Trigger SQS (bandup-speaking-queue) AI Model Gemini 2.5 Flash (Native Audio) Triển Khai Chính:\nimport json import os import boto3 import logging from typing import Dict, Any, Tuple logger = logging.getLogger() # Import từ Lambda layer from lambda_shared.gemini_client import GeminiClient from secrets_helper import get_gemini_api_key def download_audio_from_s3(audio_url: str) -\u0026gt; Tuple[bytes, str]: \u0026#34;\u0026#34;\u0026#34;Tải file audio từ S3 và xác định MIME type.\u0026#34;\u0026#34;\u0026#34; s3_client = boto3.client(\u0026#39;s3\u0026#39;) # Parse S3 URL: s3://bucket-name/path/to/file.mp3 parts = audio_url.replace(\u0026#39;s3://\u0026#39;, \u0026#39;\u0026#39;).split(\u0026#39;/\u0026#39;, 1) bucket, key = parts[0], parts[1] response = s3_client.get_object(Bucket=bucket, Key=key) audio_bytes = response[\u0026#39;Body\u0026#39;].read() # Xác định MIME type từ extension mime_types = {\u0026#39;.mp3\u0026#39;: \u0026#39;audio/mp3\u0026#39;, \u0026#39;.wav\u0026#39;: \u0026#39;audio/wav\u0026#39;, \u0026#39;.m4a\u0026#39;: \u0026#39;audio/m4a\u0026#39;} ext = \u0026#39;.\u0026#39; + key.split(\u0026#39;.\u0026#39;)[-1].lower() mime_type = mime_types.get(ext, \u0026#39;audio/mp3\u0026#39;) return audio_bytes, mime_type def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Đánh giá IELTS Speaking sử dụng Gemini native audio.\u0026#34;\u0026#34;\u0026#34; # Parse request request_data = parse_request(event) # Lấy API key từ Secrets Manager gemini_api_key = get_gemini_api_key() gemini_client = GeminiClient(api_key=gemini_api_key) # Trích xuất parameters audio_url = request_data.get(\u0026#39;audio_url\u0026#39;) part = request_data.get(\u0026#39;part\u0026#39;, \u0026#39;PART_1\u0026#39;) questions = request_data.get(\u0026#39;questions\u0026#39;, []) # Bước 1: Tải audio từ S3 audio_bytes, mime_type = download_audio_from_s3(audio_url) logger.info(f\u0026#34;Đã tải {len(audio_bytes)} bytes, MIME: {mime_type}\u0026#34;) # Bước 2: Gửi audio trực tiếp đến Gemini (MỘT lần gọi API) # Không cần AWS Transcribe - Gemini xử lý audio trực tiếp evaluation = gemini_client.evaluate_audio( audio_bytes=audio_bytes, part=part, questions=questions, mime_type=mime_type, max_retries=3, timeout=120 ) # Bước 3: Xây dựng response với tiêu chí IELTS Speaking result = { \u0026#39;session_id\u0026#39;: request_data.get(\u0026#39;session_id\u0026#39;), \u0026#39;transcript\u0026#39;: evaluation.get(\u0026#39;transcript\u0026#39;), \u0026#39;duration\u0026#39;: evaluation.get(\u0026#39;duration_seconds\u0026#39;), \u0026#39;overall_band\u0026#39;: evaluation.get(\u0026#39;overall_band\u0026#39;), \u0026#39;fluency_band\u0026#39;: evaluation[\u0026#39;fluency_coherence\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;lexical_band\u0026#39;: evaluation[\u0026#39;lexical_resource\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;grammar_band\u0026#39;: evaluation[\u0026#39;grammatical_range_accuracy\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;pronunciation_band\u0026#39;: evaluation[\u0026#39;pronunciation\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;model_used\u0026#39;: \u0026#39;gemini-2.5-flash-audio\u0026#39;, \u0026#39;estimated_cost\u0026#39;: evaluation[\u0026#39;usage\u0026#39;][\u0026#39;cost\u0026#39;] } # Lưu vào DynamoDB save_evaluation(result, request_data.get(\u0026#39;user_id\u0026#39;)) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(result)} So Sánh Chi Phí:\nPhương Pháp Chi Phí / 3-phút Audio Độ Trễ Gemini Native Audio ~$0.021 30-45s AWS Transcribe + LLM ~$0.076 60-90s Tiết Kiệm 72% Nhanh gấp 2x Lambda Function 3: Flashcard Generator (RAG) Tạo flashcards từ tài liệu PDF sử dụng RAG pipeline nhẹ với Titan Embeddings (in-memory vector store, tối ưu cho Lambda package \u0026lt;50MB).\nCài Đặt Giá Trị Function name bandup-flashcard-generator Runtime Python 3.11 Memory 1024 MB Timeout 10 phút Trigger SQS (bandup-flashcard-queue) AI Model Gemini + Amazon Titan Embeddings V2 Luồng RAG Pipeline:\n┌─────────────┐ ┌──────────────┐ ┌─────────────────┐ │ PDF Upload │ ──▶ │ Chunking │ ──▶ │ Titan Embeddings│ │ (S3) │ │ (3000 chars) │ │ (Bedrock) │ └─────────────┘ └──────────────┘ └────────┬────────┘ │ ▼ ┌─────────────┐ ┌──────────────┐ ┌─────────────────┐ │ Flashcards │ ◀── │ Gemini │ ◀── │ In-Memory Store │ │ (JSON) │ │ Generation │ │ (Cosine Sim) │ └─────────────┘ └──────────────┘ └─────────────────┘ Triển Khai Chính:\nimport json import os import boto3 import time import google.generativeai as genai from typing import Dict, Any, List from concurrent.futures import ThreadPoolExecutor, as_completed logger = logging.getLogger() # Global instance cho warm starts (tối ưu Lambda) _rag_instance = None _s3_client = None def get_s3_client(): \u0026#34;\u0026#34;\u0026#34;Lấy cached S3 client.\u0026#34;\u0026#34;\u0026#34; global _s3_client if _s3_client is None: _s3_client = boto3.client(\u0026#39;s3\u0026#39;) return _s3_client def get_rag_instance(api_key: str): \u0026#34;\u0026#34;\u0026#34;Lấy cached RAG instance cho warm starts.\u0026#34;\u0026#34;\u0026#34; global _rag_instance if _rag_instance is None: _rag_instance = RAG( api_key=api_key, chunk_size=int(os.environ.get(\u0026#39;RAG_CHUNK_SIZE\u0026#39;, \u0026#39;500\u0026#39;)), chunk_overlap=int(os.environ.get(\u0026#39;RAG_CHUNK_OVERLAP\u0026#39;, \u0026#39;100\u0026#39;)) ) logger.info(\u0026#34;Cold start: RAG instance created\u0026#34;) else: logger.info(\u0026#34;Warm start: Reusing RAG instance\u0026#34;) return _rag_instance def download_pdf_from_s3(bucket: str, key: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Tải PDF từ S3 về /tmp.\u0026#34;\u0026#34;\u0026#34; s3 = get_s3_client() local_path = f\u0026#34;/tmp/{key.split(\u0026#39;/\u0026#39;)[-1]}\u0026#34; s3.download_file(bucket, key, local_path) return local_path def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Tạo flashcard dựa trên RAG (nhẹ).\u0026#34;\u0026#34;\u0026#34; start_time = time.time() is_async = is_sqs_event(event) # Parse request if is_async: request, job_id = parse_sqs_message(event) update_job_status(job_id, \u0026#39;processing\u0026#39;) else: request = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) if isinstance(event.get(\u0026#39;body\u0026#39;), str) else event # Lấy S3 location pdf_url = request.get(\u0026#39;pdf_url\u0026#39;) s3_bucket, s3_key = parse_s3_url(pdf_url) # Lấy API key từ Secrets Manager secret_arn = os.environ.get(\u0026#39;GEMINI_API_KEY_SECRET_ARN\u0026#39;) secrets_client = boto3.client(\u0026#39;secretsmanager\u0026#39;) api_key = secrets_client.get_secret_value(SecretId=secret_arn)[\u0026#39;SecretString\u0026#39;] # Lấy parameters num_cards = int(request.get(\u0026#39;num_cards\u0026#39;, 10)) difficulty = request.get(\u0026#39;difficulty\u0026#39;, \u0026#39;MEDIUM\u0026#39;) question_types = request.get(\u0026#39;question_types\u0026#39;, [\u0026#39;DEFINITION\u0026#39;, \u0026#39;VOCABULARY\u0026#39;, \u0026#39;COMPREHENSION\u0026#39;]) # Bước 1: Tải PDF từ S3 local_pdf = download_pdf_from_s3(s3_bucket, s3_key) # Bước 2: Index document với RAG (Titan Embeddings + in-memory store) rag = get_rag_instance(api_key) rag._vector_store = None # Reset cho document mới rag._chunks = [] index_result = rag.index_document(local_pdf, document_id=s3_key) logger.info(f\u0026#34;Đã index {index_result[\u0026#39;chunk_count\u0026#39;]} chunks từ {index_result[\u0026#39;page_count\u0026#39;]} trang\u0026#34;) # Bước 3: Truy xuất chunks liên quan (hybrid approach) if index_result[\u0026#39;chunk_count\u0026#39;] \u0026lt;= 15: # Document nhỏ: dùng representative chunks chunks = rag.get_representative_chunks(num_chunks=min(10, index_result[\u0026#39;chunk_count\u0026#39;])) retrieval_method = \u0026#34;representative\u0026#34; else: # Document lớn: dùng smart keyword-based queries chunks = rag.retrieve_with_smart_queries(top_k_per_query=3) retrieval_method = \u0026#34;smart_queries\u0026#34; # Bước 4: Tạo flashcards với Gemini prompt = generate_flashcards_prompt(chunks, num_cards, difficulty, question_types) flashcard_result = call_gemini(prompt, api_key) # Dọn dẹp os.remove(local_pdf) # Xây dựng response total_time = time.time() - start_time response_body = { \u0026#39;status\u0026#39;: \u0026#39;success\u0026#39;, \u0026#39;set_id\u0026#39;: request.get(\u0026#39;set_id\u0026#39;), \u0026#39;user_id\u0026#39;: request.get(\u0026#39;user_id\u0026#39;), \u0026#39;document\u0026#39;: { \u0026#39;s3_bucket\u0026#39;: s3_bucket, \u0026#39;s3_key\u0026#39;: s3_key, \u0026#39;page_count\u0026#39;: index_result[\u0026#39;page_count\u0026#39;], \u0026#39;chunk_count\u0026#39;: index_result[\u0026#39;chunk_count\u0026#39;] }, \u0026#39;retrieval\u0026#39;: { \u0026#39;method\u0026#39;: retrieval_method, \u0026#39;chunks_used\u0026#39;: len(chunks), \u0026#39;keywords\u0026#39;: index_result.get(\u0026#39;keywords\u0026#39;, [])[:5] }, \u0026#39;flashcards\u0026#39;: flashcard_result.get(\u0026#39;flashcards\u0026#39;, []), \u0026#39;total_cards\u0026#39;: len(flashcard_result.get(\u0026#39;flashcards\u0026#39;, [])), \u0026#39;metrics\u0026#39;: { \u0026#39;total_time_ms\u0026#39;: round(total_time * 1000) } } # Lưu vào DynamoDB (bảng bandup-flashcard-sets) dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(os.environ.get(\u0026#39;DYNAMODB_FLASHCARD_SETS\u0026#39;)) table.put_item(Item={ \u0026#39;set_id\u0026#39;: request.get(\u0026#39;set_id\u0026#39;), \u0026#39;user_id\u0026#39;: request.get(\u0026#39;user_id\u0026#39;), \u0026#39;document_id\u0026#39;: s3_key, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;flashcards\u0026#39;: json.dumps(response_body[\u0026#39;flashcards\u0026#39;]), \u0026#39;total_cards\u0026#39;: response_body[\u0026#39;total_cards\u0026#39;], \u0026#39;page_count\u0026#39;: index_result[\u0026#39;page_count\u0026#39;], \u0026#39;chunk_count\u0026#39;: index_result[\u0026#39;chunk_count\u0026#39;], \u0026#39;created_at\u0026#39;: int(time.time()) }) if is_async: return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;OK\u0026#39;} return create_response(200, response_body) Titan Embeddings với Xử Lý Song Song:\nclass TitanEmbeddings: \u0026#34;\u0026#34;\u0026#34;Amazon Titan Text Embeddings V2 qua Bedrock với xử lý song song.\u0026#34;\u0026#34;\u0026#34; MODEL_ID = \u0026#34;amazon.titan-embed-text-v2:0\u0026#34; def __init__(self, region: str = None): self.region = region or os.environ.get(\u0026#39;BEDROCK_REGION\u0026#39;, \u0026#39;us-east-1\u0026#39;) self._client = None @property def client(self): if self._client is None: self._client = boto3.client(\u0026#39;bedrock-runtime\u0026#39;, region_name=self.region) return self._client def embed(self, text: str) -\u0026gt; List[float]: \u0026#34;\u0026#34;\u0026#34;Lấy embedding cho single text sử dụng Titan V2.\u0026#34;\u0026#34;\u0026#34; response = self.client.invoke_model( modelId=self.MODEL_ID, body=json.dumps({ \u0026#34;inputText\u0026#34;: text[:8000], # Độ dài input tối đa \u0026#34;dimensions\u0026#34;: 512, \u0026#34;normalize\u0026#34;: True }), contentType=\u0026#34;application/json\u0026#34;, accept=\u0026#34;application/json\u0026#34; ) result = json.loads(response[\u0026#39;body\u0026#39;].read()) return result[\u0026#39;embedding\u0026#39;] def embed_batch_parallel(self, texts: List[str], max_workers: int = 10) -\u0026gt; List[List[float]]: \u0026#34;\u0026#34;\u0026#34;Embed nhiều texts SONG SONG sử dụng ThreadPoolExecutor.\u0026#34;\u0026#34;\u0026#34; embeddings = [None] * len(texts) with ThreadPoolExecutor(max_workers=max_workers) as executor: futures = {executor.submit(self.embed, t): i for i, t in enumerate(texts)} for future in as_completed(futures): idx = futures[future] embeddings[idx] = future.result() return embeddings RAG Pipeline (In-Memory):\nimport math import fitz # PyMuPDF class RAG: \u0026#34;\u0026#34;\u0026#34;RAG nhẹ sử dụng Titan Embeddings + in-memory cosine similarity.\u0026#34;\u0026#34;\u0026#34; def __init__(self, api_key: str, chunk_size: int = 3000, chunk_overlap: int = 300): self.api_key = api_key self.chunk_size = chunk_size self.chunk_overlap = chunk_overlap self._chunks = [] self._embeddings = [] self._titan = TitanEmbeddings() self._keywords = [] def index_document(self, pdf_path: str, document_id: str = None) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Index PDF với Titan V2 embeddings (xử lý song song).\u0026#34;\u0026#34;\u0026#34; # Tải các trang PDF pages = [] with fitz.open(pdf_path) as doc: for page_num, page in enumerate(doc): text = page.get_text() if text.strip(): pages.append({\u0026#39;content\u0026#39;: text, \u0026#39;page\u0026#39;: page_num + 1}) # Chunk text với overlap self._chunks = [] for page in pages: chunks = self._chunk_text(page[\u0026#39;content\u0026#39;]) for chunk in chunks: self._chunks.append({ \u0026#39;text\u0026#39;: chunk, \u0026#39;page\u0026#39;: page[\u0026#39;page\u0026#39;] }) # Trích xuất keywords cho smart query generation all_text = \u0026#34; \u0026#34;.join([c[\u0026#39;text\u0026#39;] for c in self._chunks]) self._keywords = self._extract_keywords(all_text, top_n=20) # Tạo embeddings song song (10 Bedrock calls đồng thời) texts = [c[\u0026#39;text\u0026#39;] for c in self._chunks] self._embeddings = self._titan.embed_batch_parallel(texts, max_workers=10) return { \u0026#39;page_count\u0026#39;: len(pages), \u0026#39;chunk_count\u0026#39;: len(self._chunks), \u0026#39;keywords\u0026#39;: self._keywords[:10] } def _cosine_similarity(self, a: List[float], b: List[float]) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34;Tính cosine similarity giữa hai vectors.\u0026#34;\u0026#34;\u0026#34; dot_product = sum(x * y for x, y in zip(a, b)) norm_a = math.sqrt(sum(x * x for x in a)) norm_b = math.sqrt(sum(x * x for x in b)) if norm_a == 0 or norm_b == 0: return 0.0 return dot_product / (norm_a * norm_b) def similarity_search(self, query: str, top_k: int = 5) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm chunks tương tự sử dụng in-memory cosine similarity.\u0026#34;\u0026#34;\u0026#34; query_embedding = self._titan.embed(query) # Tính similarities similarities = [] for i, embedding in enumerate(self._embeddings): score = self._cosine_similarity(query_embedding, embedding) similarities.append((i, score)) # Sắp xếp theo similarity (giảm dần) và trả về top-k similarities.sort(key=lambda x: x[1], reverse=True) results = [] for rank, (idx, score) in enumerate(similarities[:top_k]): chunk = self._chunks[idx] results.append({ \u0026#39;text\u0026#39;: chunk[\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: chunk[\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: score, \u0026#39;rank\u0026#39;: rank + 1 }) return results def generate_smart_queries(self, num_queries: int = 5) -\u0026gt; List[str]: \u0026#34;\u0026#34;\u0026#34;Tạo queries theo document sử dụng keywords đã trích xuất.\u0026#34;\u0026#34;\u0026#34; kw = self._keywords queries = [] if len(kw) \u0026gt;= 2: queries.append(f\u0026#34;definition and explanation of {kw[0]} and {kw[1]}\u0026#34;) if len(kw) \u0026gt;= 4: queries.append(f\u0026#34;key concepts about {kw[2]} {kw[3]}\u0026#34;) if len(kw) \u0026gt;= 6: queries.append(f\u0026#34;important information regarding {kw[4]} {kw[5]}\u0026#34;) return queries[:num_queries] def retrieve_with_smart_queries(self, top_k_per_query: int = 3) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Truy xuất chunks sử dụng nhiều smart queries cho coverage tốt hơn.\u0026#34;\u0026#34;\u0026#34; queries = self.generate_smart_queries() seen_texts = set() all_results = [] for query in queries: results = self.similarity_search(query, top_k=top_k_per_query) for r in results: if r[\u0026#39;text\u0026#39;] not in seen_texts: seen_texts.add(r[\u0026#39;text\u0026#39;]) all_results.append(r) return sorted(all_results, key=lambda x: x[\u0026#39;score\u0026#39;], reverse=True) def get_representative_chunks(self, num_chunks: int = 10) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Lấy chunks phân bố đều trong document.\u0026#34;\u0026#34;\u0026#34; if len(self._chunks) \u0026lt;= num_chunks: return [{\u0026#39;text\u0026#39;: c[\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: c[\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: 1.0} for c in self._chunks] step = len(self._chunks) // num_chunks return [{\u0026#39;text\u0026#39;: self._chunks[i * step][\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: self._chunks[i * step][\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: 1.0} for i in range(num_chunks)] Prompt Tạo Flashcard:\ndef generate_flashcards_prompt(chunks: List[Dict], num_cards: int, difficulty: str, question_types: List[str]) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Xây dựng prompt cho Gemini tạo flashcard.\u0026#34;\u0026#34;\u0026#34; context = \u0026#34;\\n\\n\u0026#34;.join([ f\u0026#34;[Chunk {i+1}] (Page {c.get(\u0026#39;page\u0026#39;, \u0026#39;?\u0026#39;)}):\\n{c[\u0026#39;text\u0026#39;]}\u0026#34; for i, c in enumerate(chunks) ]) return f\u0026#34;\u0026#34;\u0026#34;Based on the following document excerpts, generate {num_cards} flashcards. CONTEXT: {context} REQUIREMENTS: - Difficulty: {difficulty} - Generate exactly {num_cards} flashcards - Each flashcard should have a clear question and concise answer - Focus on key concepts, definitions, and important facts - Use these question types: {\u0026#34;, \u0026#34;.join(question_types)} OUTPUT FORMAT (JSON): {{ \u0026#34;flashcards\u0026#34;: [ {{ \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;DEFINITION\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;{difficulty}\u0026#34;, \u0026#34;source_chunk\u0026#34;: 1 }} ] }} Return ONLY valid JSON.\u0026#34;\u0026#34;\u0026#34; def call_gemini(prompt: str, api_key: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Gọi Gemini API để tạo flashcard.\u0026#34;\u0026#34;\u0026#34; import google.generativeai as genai genai.configure(api_key=api_key) model = genai.GenerativeModel( model_name=os.environ.get(\u0026#39;GEMINI_MODEL\u0026#39;, \u0026#39;gemini-2.0-flash\u0026#39;), generation_config={ \u0026#39;temperature\u0026#39;: 0.3, \u0026#39;max_output_tokens\u0026#39;: 4096 } ) response = model.generate_content(prompt) text = response.text # Trích xuất JSON nếu được wrap trong markdown if \u0026#39;```json\u0026#39; in text: text = text.split(\u0026#39;```json\u0026#39;)[1].split(\u0026#39;```\u0026#39;)[0] return json.loads(text.strip()) Lambda Function 4: S3 Upload Handler Tạo presigned URLs để upload file an toàn lên S3.\nCài Đặt Giá Trị Function name bandup-s3-upload Runtime Python 3.11 Memory 256 MB Timeout 30 giây Trigger API Gateway (sync) Triển Khai Chính:\nimport json import os import boto3 from datetime import datetime from typing import Dict, Any s3_client = boto3.client(\u0026#39;s3\u0026#39;) def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Tạo presigned URL cho S3 upload.\u0026#34;\u0026#34;\u0026#34; request = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) user_id = request.get(\u0026#39;user_id\u0026#39;) filename = request.get(\u0026#39;filename\u0026#39;) content_type = request.get(\u0026#39;content_type\u0026#39;, \u0026#39;application/octet-stream\u0026#39;) upload_type = request.get(\u0026#39;upload_type\u0026#39;, \u0026#39;general\u0026#39;) # Xác định bucket dựa trên upload type bucket_map = { \u0026#39;speaking_audio\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_AUDIO\u0026#39;), \u0026#39;flashcard_pdf\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_DOCUMENTS\u0026#39;), \u0026#39;writing_essay\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_DOCUMENTS\u0026#39;), } bucket = bucket_map.get(upload_type) # Tạo S3 key có tổ chức timestamp = datetime.now().strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;) key = f\u0026#34;uploads/{upload_type}/{user_id}/{timestamp}_{filename}\u0026#34; # Tạo presigned PUT URL (hết hạn sau 15 phút) upload_url = s3_client.generate_presigned_url( \u0026#39;put_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: bucket, \u0026#39;Key\u0026#39;: key, \u0026#39;ContentType\u0026#39;: content_type}, ExpiresIn=900 ) # Tạo presigned GET URL (hết hạn sau 1 giờ) get_url = s3_client.generate_presigned_url( \u0026#39;get_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: bucket, \u0026#39;Key\u0026#39;: key}, ExpiresIn=3600 ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: {\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;}, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;upload_url\u0026#39;: upload_url, \u0026#39;get_url\u0026#39;: get_url, \u0026#39;file_url\u0026#39;: f\u0026#34;s3://{bucket}/{key}\u0026#34;, \u0026#39;expires_in\u0026#39;: 900 }) } Quản Lý Secrets An Toàn Tất cả Lambda functions sử dụng AWS Secrets Manager để lấy API keys:\n# secrets_helper.py (trong Lambda Layer) import boto3 import os from functools import lru_cache @lru_cache(maxsize=1) def get_gemini_api_key() -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Lấy Gemini API key từ Secrets Manager (có cache).\u0026#34;\u0026#34;\u0026#34; client = boto3.client(\u0026#39;secretsmanager\u0026#39;) secret_arn = os.environ.get(\u0026#39;GEMINI_API_KEY_SECRET_ARN\u0026#39;) response = client.get_secret_value(SecretId=secret_arn) return response[\u0026#39;SecretString\u0026#39;] Best Practices Bảo Mật:\nKhông bao giờ hardcode API keys trong Lambda code Sử dụng AWS Secrets Manager cho tất cả credentials nhạy cảm Rotate secrets định kỳ sử dụng automatic rotation Sử dụng IAM roles với least-privilege permissions IAM Role cho Lambda Functions { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;BedrockAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;bedrock:InvokeModel\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:bedrock:*:*:foundation-model/amazon.titan-embed-text-v2*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:*:*:table/bandup-evaluations\u0026#34;, \u0026#34;arn:aws:dynamodb:*:*:table/bandup-flashcard-sets\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3Access\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::bandup-*/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SQSAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;sqs:ReceiveMessage\u0026#34;, \u0026#34;sqs:DeleteMessage\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:*:*:bandup-*-queue\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SecretsAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;secretsmanager:GetSecretValue\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:*:*:secret:bandup/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchLogs\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:log-group:/aws/lambda/bandup-*\u0026#34; } ] } Bảng DynamoDB Các Lambda functions lưu kết quả vào hai bảng DynamoDB:\nBảng Sử Dụng Bởi Mục Đích bandup-evaluations Writing + Speaking Evaluators Lưu điểm band IELTS, feedback, transcripts bandup-flashcard-sets Flashcard Generator Lưu flashcards và document metadata Schema Bảng Evaluations (Writing \u0026amp; Speaking):\n# Sử dụng bởi Writing Evaluator table.put_item(Item={ \u0026#39;evaluation_id\u0026#39;: session_id, # Partition Key \u0026#39;user_id\u0026#39;: user_id, # Sort Key \u0026#39;evaluation_type\u0026#39;: \u0026#39;writing\u0026#39;, # \u0026#39;writing\u0026#39; hoặc \u0026#39;speaking\u0026#39; \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;overall_band\u0026#39;: \u0026#39;7.0\u0026#39;, \u0026#39;task_achievement_band\u0026#39;: \u0026#39;7.0\u0026#39;, # Chỉ Writing \u0026#39;fluency_band\u0026#39;: \u0026#39;6.5\u0026#39;, # Chỉ Speaking \u0026#39;pronunciation_band\u0026#39;: \u0026#39;7.0\u0026#39;, # Chỉ Speaking \u0026#39;transcript\u0026#39;: \u0026#39;...\u0026#39;, # Chỉ Speaking \u0026#39;feedback\u0026#39;: json.dumps(feedback), \u0026#39;created_at\u0026#39;: timestamp }) Schema Bảng Flashcard Sets:\n# Sử dụng bởi Flashcard Generator table.put_item(Item={ \u0026#39;set_id\u0026#39;: set_id, # Partition Key \u0026#39;user_id\u0026#39;: user_id, # Sort Key \u0026#39;document_id\u0026#39;: document_id, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;flashcards\u0026#39;: json.dumps(flashcards), \u0026#39;total_cards\u0026#39;: 10, \u0026#39;page_count\u0026#39;: 5, \u0026#39;chunk_count\u0026#39;: 12, \u0026#39;created_at\u0026#39;: timestamp }) Biến Môi Trường Biến Mô Tả Ví Dụ GEMINI_API_KEY_SECRET_ARN Secrets Manager ARN arn:aws:secretsmanager:...:secret:bandup/gemini-api-key DYNAMODB_EVALUATIONS Bảng evaluations (Writing + Speaking) bandup-evaluations DYNAMODB_FLASHCARD_SETS Bảng flashcard sets bandup-flashcard-sets S3_BUCKET_AUDIO Audio bucket bandup-audio-bucket S3_BUCKET_DOCUMENTS Documents bucket bandup-documents-bucket BEDROCK_REGION Bedrock region cho Titan us-east-1 RAG_CHUNK_SIZE Chunk size cho RAG 3000 RAG_CHUNK_OVERLAP Chunk overlap 300 GEMINI_MODEL Tên Gemini model gemini-2.0-flash Deploy Lambda Functions # Đóng gói với dependencies cd rag_flashcard pip install -r requirements.txt -t package/ cp lambda_handler.py rag_pipeline.py package/ cd package \u0026amp;\u0026amp; zip -r ../function.zip . \u0026amp;\u0026amp; cd .. # Tạo Lambda function aws lambda create-function \\ --function-name bandup-flashcard-generator \\ --runtime python3.11 \\ --handler lambda_handler.lambda_handler \\ --role arn:aws:iam::${AWS_ACCOUNT_ID}:role/bandup-lambda-role \\ --timeout 600 \\ --memory-size 1024 \\ --zip-file fileb://function.zip \\ --environment Variables=\u0026#34;{ GEMINI_API_KEY_SECRET_ARN=arn:aws:secretsmanager:${AWS_REGION}:${AWS_ACCOUNT_ID}:secret:bandup/gemini-api-key, BEDROCK_REGION=us-east-1, RAG_CHUNK_SIZE=3000 }\u0026#34; # Thêm SQS trigger aws lambda create-event-source-mapping \\ --function-name bandup-flashcard-generator \\ --event-source-arn arn:aws:sqs:${AWS_REGION}:${AWS_ACCOUNT_ID}:bandup-flashcard-queue \\ --batch-size 1 Bước Tiếp Theo Tiến hành đến DynamoDB để cấu hình các bảng database.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch: AWS Cloud Mastery Series #2 — DevOps on AWS Mục đích của sự kiện Củng cố tư duy và nguyên tắc văn hóa DevOps (DevOps culture and principles). Giới thiệu chi tiết các dịch vụ AWS hỗ trợ CI/CD: CodeCommit, CodeBuild, CodeDeploy, CodePipeline. Đào sâu về Infrastructure as Code (IaC) với CloudFormation và AWS CDK. Khám phá dịch vụ Container (ECS, EKS, App Runner) và công cụ giám sát (CloudWatch, X-Ray). Nội dung nổi bật Sáng: CI/CD Pipeline \u0026amp; Infrastructure as Code (08:30 – 12:00) DevOps Mindset: nhấn mạnh các nguyên tắc cốt lõi và các chỉ số DORA (Deployment Frequency, MTTR\u0026hellip;). CI/CD Services: Source control: AWS CodeCommit và chiến lược Git (GitFlow vs. Trunk-based). Build \u0026amp; Test: AWS CodeBuild. Deployment: AWS CodeDeploy với các chiến lược Blue/Green, Canary, Rolling. Orchestration: tự động hóa luồng với AWS CodePipeline. Demo: walkthrough một CI/CD pipeline hoàn chỉnh. IaC: AWS CloudFormation: templates, stacks, drift detection. AWS CDK: constructs, reusable patterns, multi-language support. Demo \u0026amp; Discussion: triển khai bằng cả CloudFormation và CDK; thảo luận lựa chọn công cụ phù hợp. Chiều: Container, Observability \u0026amp; Best Practices (13:00 – 17:00) Container Services: Docker: cơ bản về containerization. Amazon ECR: lưu trữ, quét (scanning), quản lý lifecycle image. ECS \u0026amp; EKS: chiến lược triển khai, scaling, orchestration. App Runner: alternative PaaS for containers. Monitoring \u0026amp; Observability: AWS CloudWatch: metrics, logs, alarms, dashboards. AWS X-Ray: distributed tracing cho microservices. Best practices: Feature flags, A/B testing. Incident management và postmortems. Demo \u0026amp; Case study: so sánh chiến lược deploy cho microservices. Những gì học được DevOps Culture: nắm vững các chỉ số DORA và tư duy tự động hóa. CI/CD: hiểu cách các AWS Code services phối hợp; nắm các chiến lược deployment nâng cao (Blue/Green, Canary). IaC: có kiến thức nền tảng về CloudFormation và CDK — hữu ích để tối ưu template và kiến trúc multi-stack. Observability: tầm quan trọng của giám sát toàn diện bằng CloudWatch và X-Ray để debug lỗi (CORS, Lambda, v.v.). Container services (ECS/EKS) cung cấp định hướng cho kiến trúc phức tạp trong dự án. Phần demo CI/CD \u0026amp; IaC rất thực tế, giúp nhóm hiểu cách tối ưu hóa quá trình triển khai. Trải nghiệm trong event Workshop chi tiết, cung cấp nhiều kiến thức thực tiễn và áp dụng ngay. Phần demo và case study hữu ích cho việc áp dụng vào dự án. Cơ hội kết nối với cộng đồng và chuyên gia. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4 Theo kịp tiến độ học tập của nhóm về các dịch vụ AWS. Thành thạo thiết lập và cấu hình AWS Transit Gateway. Hiểu sâu về Amazon EC2 và các dịch vụ compute liên quan. Học Git cơ bản để hợp tác nhóm hiệu quả. Workshop: Bắt đầu VPC \u0026amp; Network Setup cho hạ tầng Bandup IELTS. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Khám phá AWS Transit Gateway: khái niệm, quy trình thiết lập và tài nguyên cần thiết.\n- So sánh sự khác biệt giữa VPC Peering và Transit Gateway.\n- Hoàn thành: Centralized Network Management with AWS Transit Gateway. 29/09/2025 30/09/2025 AWS Transit Gateway 3 - Nghiên cứu sâu về Amazon EC2 qua các bài giảng Module 3.\n- Học EC2 Auto Scaling cho quản lý tài nguyên tự động.\n- Hoàn thành: Scaling Applications with EC2 Auto Scaling. 01/10/2025 02/10/2025 FCJ Playlist 4 - Học và thực hành các lệnh Git (commit, push, pull) cho hợp tác nhóm.\n- Khám phá Amazon Lightsail cho các giải pháp compute đơn giản.\n- Hoàn thành: Simplified Computing with Amazon Lightsail. 03/10/2025 04/10/2025 Git Tutorial 5 - Đề xuất ý tưởng và phân công nhiệm vụ cho team để chuẩn bị proposal.\n- Nghiên cứu các chiến lược migration cho AWS.\n- Hoàn thành: VM Migration with AWS VM Import/Export.\n- Hoạt động Workshop: Tạo VPC với CIDR 10.0.0.0/16 và cấu hình DNS support. 05/10/2025 06/10/2025 Họp nhóm, Workshop 5.3 Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Centralized Network Management with AWS Transit Gateway Mạng ✅ Scaling Applications with EC2 Auto Scaling Compute ✅ Simplified Computing with Amazon Lightsail Compute ✅ Container Deployment with Amazon Lightsail Containers Containers ✅ VM Migration with AWS VM Import/Export Migration ✅ Database Migration with AWS DMS and SCT Migration ✅ Disaster Recovery with AWS Elastic Disaster Recovery Reliability ✅ Monitoring with Amazon CloudWatch Operations ✅ Kết quả đạt được tuần 4 Kỹ năng kỹ thuật đã tiếp thu:\nAWS Transit Gateway:\nThành thạo thiết lập và cấu hình Transit Gateway Hiểu các ưu điểm chính so với VPC Peering: Hỗ trợ topology multi-VPC phức tạp (mô hình hub-and-spoke) Cho phép transitive routing giữa các mạng được kết nối Đơn giản hóa quản lý mạng ở quy mô lớn Hỗ trợ VPN và Direct Connect attachments Học quản lý route table của Transit Gateway Amazon EC2 Deep Dive:\nHiểu toàn diện các tính năng chính của EC2: Elasticity: Scale tài nguyên lên/xuống theo nhu cầu Cấu hình linh hoạt: Nhiều instance types cho các workloads khác nhau Tối ưu chi phí: Mô hình On-Demand, Reserved, Spot instances Thành thạo EC2 Auto Scaling cho điều chỉnh tài nguyên tự động Hiểu Instance Store như block storage tạm thời cho EC2 Khám phá Amazon Lightsail như giải pháp đơn giản cho ứng dụng quy mô nhỏ Học về Lightsail Containers để triển khai container dễ dàng Dịch vụ Migration:\nHiểu AWS Application Migration Service (MGN) cho migration server Học VM Import/Export để migration máy ảo lên AWS Khám phá Database Migration Service (DMS) và Schema Conversion Tool (SCT) Nghiên cứu chiến lược disaster recovery với AWS Elastic Disaster Recovery DevOps và Monitoring:\nThành thạo các lệnh Git (commit, push, pull) và workflows nhóm Học CloudWatch cơ bản để monitor tài nguyên AWS Hợp tác nhóm:\nĐề xuất thành công ý tưởng và phân công nhiệm vụ cho proposal Team sẵn sàng bắt đầu giai đoạn implementation Thiết lập vai trò và trách nhiệm rõ ràng cho từng thành viên Tiến độ Workshop - VPC \u0026amp; Network Setup:\nTạo VPC với CIDR 10.0.0.0/16 trong region ap-southeast-1 Thiết kế kiến trúc subnet: Public subnets (10.0.1.0/24, 10.0.2.0/24) và Private subnets cho App (10.0.11.0/24, 10.0.12.0/24) và DB (10.0.21.0/24, 10.0.22.0/24) across hai AZs Cấu hình Internet Gateway cho public subnet internet access Thiết lập route tables cho proper traffic routing Bắt đầu cấu hình security groups cho multi-tier architecture Bài học chính:\nTransit Gateway thiết yếu cho quản lý kiến trúc multi-VPC phức tạp EC2 Auto Scaling đảm bảo ứng dụng xử lý được tải biến động hiệu quả Lightsail hoàn hảo cho workloads đơn giản mà không cần sự phức tạp của AWS Dịch vụ migration cung cấp nhiều đường dẫn để di chuyển workloads lên AWS Thiết kế VPC với public/private subnets riêng biệt cung cấp security isolation Triển khai Multi-AZ đảm bảo high availability từ network layer "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.5-setup-be/5.5.4-task/","title":"Tạo Service &amp; Task","tags":[],"description":"","content":"Trong bước cuối cùng của quá trình triển khai backend, chúng ta sẽ định nghĩa cấu hình chạy cho ứng dụng Spring Boot và khởi tạo nó dưới dạng một ECS Service ổn định.\n1. Tạo Task Definition Truy cập Amazon ECS \u0026gt; Task definitions \u0026gt; Create new task definition. Cấu hình Task definition: Family: bandup-backend. Launch type: AWS Fargate. OS/Architecture: Linux/X86_64. Task size: 1 vCPU và 2 GB Memory. Lưu ý: Ứng dụng Java (Spring Boot) thường yêu cầu nhiều bộ nhớ hơn Node.js để quản lý JVM heap hiệu quả. Task Role \u0026amp; Execution Role: Chọn ecsTaskExecutionRole. Chi tiết Container:\nName: bandup-be-container. Image URI: Nhập ECR URI (.../band-up-backend:v1.0.0). Container Port: 8080 (Cổng mặc định của Spring Boot). Cấu hình Biến môi trường (Thực hành tốt): Thay vì nhập thủ công các biến nhạy cảm (Database URL, Username, Password) dưới dạng văn bản thuần, chúng ta sẽ tải chúng từ một file bảo mật được lưu trữ trên S3.\nEnvironment files: Nhập S3 ARN của file .env (ví dụ: arn:aws:s3:::bandup2025-fcj/.env). Yêu cầu: Đảm bảo ecsTaskExecutionRole của bạn đã có quyền đọc (GetObjects) đối với file S3 này. 2. Tạo ECS Service Triển khai task definition vào cluster.\nTruy cập bandup-cluster \u0026gt; Services \u0026gt; Create. Cấu hình Deployment: Compute options: FARGATE. Family: bandup-backend (Chọn Revision mới nhất). Service name: bandup-backend-service. Desired tasks: 1. Mạng (Networking): VPC: band-up-vpc. Subnets: Chọn Private Subnets (private-subnet-1, private-subnet-2). Security group: Chọn ecs-backend-sg (Đã tạo ở bước 5.5.2). Cân bằng tải (Load Balancing): Load balancer: Chọn bandup-public-alb. Listener: Sử dụng listener có sẵn 80:HTTP. Target group: Tạo target group mới tên là target-bandup-be. Thông tin Container: Đảm bảo lưu lượng được chuyển đến cổng 8080. Nhấn Create. Dịch vụ sẽ tiến hành cấp phát tài nguyên Fargate, kéo image về, tải biến môi trường từ S3 và đăng ký container vào ALB. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.4-setup-fe/5.4.4-task/","title":"Tạo Task Definition &amp; Service","tags":[],"description":"","content":"Trong bước cuối cùng của phần triển khai Frontend, chúng ta sẽ định nghĩa cách ứng dụng chạy (Task Definition) và triển khai nó dưới dạng một dịch vụ (ECS Service) có khả năng mở rộng, được kết nối trực tiếp với Load Balancer.\n1. Tạo Task Definition Task Definition đóng vai trò như một bản thiết kế (blueprint) cho ứng dụng.\nTruy cập Amazon ECS \u0026gt; Task definitions \u0026gt; Create new task definition. Cấu hình Task definition: Task definition family: bandup-frontend. Launch type: AWS Fargate. OS/Architecture: Linux/X86_64. Task size: .5 vCPU và 1 GB Memory (Đủ cho ứng dụng Next.js). Task Role \u0026amp; Task Execution Role: Chọn ecsTaskExecutionRole (Đã tạo ở phần 5.3.3). Chi tiết Container: Name: bandup-fe-container. Image URI: Nhập ECR URI chúng ta đã push trước đó (ví dụ: .../band-up-frontend:v1.0.0). Container port: 3000. Nhấn Create. 2. Tạo ECS Service Bây giờ chúng ta sẽ triển khai bản thiết kế này vào Cluster.\nTruy cập Clusters \u0026gt; Chọn bandup-cluster. Tại tab Services, nhấn Create. Bước 1: Môi trường (Environment)\nCompute options: Launch type -\u0026gt; FARGATE. Task definition: bandup-frontend (Revision 1). Service name: bandup-frontend-service. Desired tasks: 1 (Số lượng container muốn chạy). Bước 2: Mạng (Networking)\nVPC: band-up-vpc. Subnets: Chọn các Private Subnets (private-subnet-1, private-subnet-2). Security group: Chọn ecs-private-sg (Cho phép traffic từ ALB). Bước 3: Cân bằng tải (Load Balancing)\nLoad balancer type: Application Load Balancer. Load balancer: Chọn bandup-public-alb. Container to load balance: bandup-fe-container 3000:3000. Listener: Chọn Create new listener tại Port 80 (HTTP). Target group: Chọn Use an existing target group -\u0026gt; target-bandup-fe. Nhấn Create. Dịch vụ sẽ bắt đầu triển khai container của bạn. Hãy đợi đến khi trạng thái chuyển sang Active và Task status là Running. 3. Kiểm tra kết quả Khi dịch vụ đã ổn định, hãy mở trình duyệt web và truy cập vào DNS name của Application Load Balancer.\nBạn sẽ thấy trang chủ của IELTS BandUp tải thành công, được phục vụ từ container nằm an toàn trong private subnet.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.3-network/5.3.4-endpoints/","title":"Thiết lập VPC Endpoints","tags":[],"description":"","content":"Để đảm bảo an toàn bảo mật, các dịch vụ backend chạy trong Private Subnet không nên truy cập các dịch vụ AWS quan trọng thông qua Internet công cộng. Thay vào đó, chúng ta sử dụng AWS PrivateLink (VPC Endpoints) để giữ lưu lượng này hoàn toàn bên trong mạng lưới của AWS.\nChúng ta sẽ tạo 4 Endpoints:\nInterface Endpoints: Cho ECR (Docker \u0026amp; API) và CloudWatch Logs. Gateway Endpoint: Cho Amazon S3. 1. Tạo Interface Endpoints (ECR \u0026amp; CloudWatch) Chúng ta sẽ bắt đầu tạo endpoint cho ECR Docker (ecr.dkr). Quy trình này hoàn toàn tương tự cho ECR API (ecr.api) và CloudWatch (logs).\nBước 1: Chọn dịch vụ\nTruy cập VPC Dashboard \u0026gt; Endpoints \u0026gt; Create endpoint. Name tag: ecr-endpoint (cho Docker). Service category: Chọn AWS services. Services: Tìm kiếm ecr.dkr và chọn com.amazonaws.ap-southeast-1.ecr.dkr. Bước 2: Cấu hình VPC \u0026amp; Subnets\nVPC: Chọn band-up-vpc. Subnets: Chọn các Availability Zone và tích chọn các Private Subnets (private-app-subnet-1 và private-app-subnet-2). Lưu ý: Bước này sẽ tạo các Network Interface (ENI) trong private subnet đóng vai trò là cổng kết nối. Bước 3: Chọn Security Group\nSecurity groups: Chọn Security Group cho phép lưu lượng HTTPS (Port 443) từ VPC của bạn. Trong workshop này, bạn có thể chọn default security group nếu nó cho phép inbound traffic từ nội bộ VPC. Nhấn Create endpoint. Bước 4: Lặp lại cho ECR API và CloudWatch Lặp lại các bước trên để tạo thêm 2 Interface Endpoints:\nECR API: Tìm kiếm ecr.api -\u0026gt; Đặt tên: ecr-api-endpoint. CloudWatch Logs: Tìm kiếm logs -\u0026gt; Đặt tên: cloudwatch-endpoint. 2. Tạo Gateway Endpoint (S3) Đối với Amazon S3, chúng ta sử dụng Gateway Endpoint. Loại này tiết kiệm chi phí hơn và sử dụng bảng định tuyến (Route Table) thay vì card mạng ảo.\nNhấn Create endpoint. Name tag: s3-endpoint. Services: Tìm kiếm s3 và chọn com.amazonaws.ap-southeast-1.s3 (Loại: Gateway). VPC: Chọn band-up-vpc. Route tables: Tích chọn các Route Table được liên kết với Private Subnets. Nhấn Create endpoint. 3. Kiểm tra kết quả Sau khi hoàn tất, quay lại danh sách Endpoints. Bạn sẽ thấy 4 endpoint đang hoạt động, đảm bảo kết nối bảo mật cho hạ tầng hệ thống.\necr-endpoint (Interface) ecr-api-endpoint (Interface) cloudwatch-endpoint (Interface) s3-endpoint (Gateway) "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.4-setup-fe/","title":"Triển khai Frontend (ECS Fargate)","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ tiến hành triển khai Frontend của IELTS BandUp (ứng dụng Next.js) lên hạ tầng AWS Cloud.\nChúng ta sẽ sử dụng Amazon Elastic Container Service (ECS) với loại hình khởi chạy Fargate. Cách tiếp cận serverless này cho phép vận hành các container mà không cần quản lý các máy chủ EC2 vật lý bên dưới. Dịch vụ Frontend sẽ được đặt trong các Private Subnet để đảm bảo bảo mật, nhưng vẫn cho phép người dùng truy cập thông qua Application Load Balancer (ALB) đã cấu hình ở phần trước.\nCác bước thực hiện Để triển khai thành công Frontend, chúng ta sẽ tuân theo quy trình sau:\nContainer Registry (ECR): Tạo kho lưu trữ (repository) để chứa các Docker image và đẩy mã nguồn từ máy local lên AWS. Cấu hình Bảo mật (Security Group): Thiết lập các quy tắc tường lửa, đảm bảo Frontend container chỉ nhận lưu lượng truy cập từ ALB. ECS Task \u0026amp; Service: Thiết lập bản thiết kế (Task Definition) cho container (CPU, RAM, Biến môi trường) và khởi chạy nó dưới dạng một Service ổn định. Nội dung Đóng gói ứng dụng với Docker Thiết lập ECR \u0026amp; Đẩy Image Cấu hình Security Group Tạo Task Definition \u0026amp; Service "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" Event 1: Kick-off Chương Trình The First Cloud Journey (FCJ) Thời gian tổ chức: 06/09/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Khởi động chương trình FCJ, kết nối các thành viên, giới thiệu lộ trình 12 tuần, hướng dẫn thành lập nhóm và bảo mật tài khoản AWS. Kết quả/Bài học: Hiểu rõ tầm quan trọng của kỷ luật, cam kết, quy trình lập nhóm, bảo mật tài khoản AWS và bắt đầu hành trình học tập với động lực rõ ràng. Event 2: DX Talk#7: Reinventing DevSecOps with AWS Generative AI Thời gian tổ chức: 16/10/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Khai thác chiến lược AI trong DevSecOps, phân tích case study từ CMC Global và AWS, giới thiệu các công cụ CI/CD, SAST/DAST và Amazon Q Developer. Kết quả/Bài học: Hiểu giải pháp tích hợp AI trong DevSecOps, ứng dụng các công cụ vào dự án thực tế, định hướng phát triển chuyên môn DevSecOps. Event 3: AWS Cloud Mastery Series #1 — AI/ML/GenAI on AWS Thời gian tổ chức: 15/11/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Tổng quan AI/ML tại Việt Nam, giới thiệu dịch vụ AI/ML của AWS, demo xây dựng chatbot GenAI với Bedrock. Kết quả/Bài học: Hiểu về SageMaker, Bedrock, ứng dụng AI/ML vào dự án, trải nghiệm live demo và kết nối chuyên gia. Event 4: AWS Cloud Mastery Series #2 — DevOps on AWS Thời gian tổ chức: 17/11/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Củng cố tư duy DevOps, giới thiệu dịch vụ CI/CD, IaC, Container, giám sát hệ thống, demo CI/CD pipeline và IaC. Kết quả/Bài học: Chiến lược deployment, kiến thức IaC, giám sát hệ thống, áp dụng thực tiễn vào dự án. Event 5: AWS Cloud Mastery Series #3 — Theo AWS Well-Architected Security Pillar Thời gian tổ chức: 29/11/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Giới thiệu Security Pillar, hướng dẫn 5 trụ cột bảo mật Cloud, best practices, playbook xử lý sự cố, demo IAM Identity Center, Secrets Manager. Kết quả/Bài học: Nắm nguyên tắc bảo mật, quản lý IAM nâng cao, bảo vệ dữ liệu, xây dựng playbook xử lý sự cố, định hướng học tiếp về bảo mật Cloud. Event 6: Vietnam Cloud Day HCMC Connect Edition Thời gian tổ chức: 18/09/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Track 1 — AI, Data \u0026amp; Infrastructure Modernization: Xây dựng Data Foundation cho AI, lộ trình Generative AI trên AWS, AI-Driven Development Lifecycle (AI-DLC), bảo mật cho GenAI và AI Agents. Kết quả/Bài học: Hiểu rõ cách thiết kế nền tảng dữ liệu cho AI, nhận diện các công cụ và dịch vụ hỗ trợ GenAI (ví dụ Bedrock), nắm các chiến lược bảo mật đặc thù cho GenAI và các cân nhắc kiến trúc (Serverless vs Container) cho dự án. Event 7: AI-Driven Development Life Cycle: Tái tưởng tượng Kỹ thuật Phần mềm Thời gian tổ chức: 18/09/2025 Địa điểm: Thành Phố Hồ Chí Minh / Online Vai trò: Người tham dự Nội dung chính: Giới thiệu AI-Driven Development Life Cycle (AI-DLC), một phương pháp chuyển đổi đặt AI làm cộng tác viên trung tâm trong toàn bộ quy trình phát triển phần mềm. Sự kiện bao gồm ba giai đoạn (Inception, Construction, Operations), thực thi do AI với giám sát con người, và giới thiệu Kiro—một AI-native IDE với phát triển dựa trên spec, hooks cho giám sát tự động, và đồng bộ hóa giữa specs và code. Kết quả/Bài học: Hiểu cách AI-DLC tái tưởng tượng kỹ thuật phần mềm bằng cách đặt AI ở trung tâm của phát triển, học về cấu trúc ba giai đoạn với sự cộng tác AI-con người, nhận ra tiềm năng cho chu kỳ phát triển chuyển từ tuần sang giờ/ngày, và hiểu biết về công cụ sẵn sàng sản xuất của Kiro kết nối prototyping và hệ thống sản xuất. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.6-ai-service/5.6.4-dynamodb/","title":"DynamoDB","tags":[],"description":"","content":"Tổng Quan Tạo hai bảng DynamoDB để lưu kết quả Lambda function:\nBảng Sử Dụng Bởi Mục Đích bandup-evaluations Writing + Speaking Evaluators Lưu điểm band IELTS, feedback, transcripts bandup-flashcard-sets Flashcard Generator Lưu flashcards và document metadata Bảng 1: Evaluations Table Lưu kết quả từ cả hai Lambda functions Writing Evaluator và Speaking Evaluator.\nCài Đặt Giá Trị Table name bandup-evaluations Partition key evaluation_id (String) Sort key user_id (String) Billing mode On-demand (PAY_PER_REQUEST) Schema Bảng:\nAttribute Type Mô Tả evaluation_id String Session ID duy nhất (PK) user_id String User identifier (SK) evaluation_type String writing hoặc speaking status String processing, completed, failed overall_band String Điểm band IELTS tổng (ví dụ: \u0026ldquo;7.0\u0026rdquo;) task_achievement_band String Chỉ Writing coherence_band String Chỉ Writing lexical_band String Cả Writing và Speaking grammar_band String Cả Writing và Speaking fluency_band String Chỉ Speaking pronunciation_band String Chỉ Speaking transcript String Chỉ Speaking - audio đã transcribe feedback String JSON-encoded detailed feedback model_used String AI model sử dụng để đánh giá created_at Number Unix timestamp Ví Dụ Item (Writing):\n{ \u0026#34;evaluation_id\u0026#34;: \u0026#34;eval-abc123\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;evaluation_type\u0026#34;: \u0026#34;writing\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;overall_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;task_achievement_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;coherence_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;lexical_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;grammar_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;feedback\u0026#34;: \u0026#34;{\\\u0026#34;strengths\\\u0026#34;:[...],\\\u0026#34;weaknesses\\\u0026#34;:[...]}\u0026#34;, \u0026#34;model_used\u0026#34;: \u0026#34;gemini-writing_task2\u0026#34;, \u0026#34;created_at\u0026#34;: 1733644800 } Ví Dụ Item (Speaking):\n{ \u0026#34;evaluation_id\u0026#34;: \u0026#34;speak-xyz789\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;evaluation_type\u0026#34;: \u0026#34;speaking\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;overall_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;fluency_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;lexical_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;grammar_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;pronunciation_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;transcript\u0026#34;: \u0026#34;Well, I\u0026#39;d like to talk about...\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;120.5\u0026#34;, \u0026#34;word_count\u0026#34;: 185, \u0026#34;feedback\u0026#34;: \u0026#34;{\\\u0026#34;fluency\\\u0026#34;:{...},\\\u0026#34;pronunciation\\\u0026#34;:{...}}\u0026#34;, \u0026#34;model_used\u0026#34;: \u0026#34;gemini-2.5-flash-audio\u0026#34;, \u0026#34;created_at\u0026#34;: 1733644800 } Bảng 2: Flashcard Sets Table Lưu kết quả từ Lambda function Flashcard Generator.\nCài Đặt Giá Trị Table name bandup-flashcard-sets Partition key set_id (String) Sort key user_id (String) Billing mode On-demand (PAY_PER_REQUEST) Schema Bảng:\nAttribute Type Mô Tả set_id String ID bộ flashcard duy nhất (PK) user_id String User identifier (SK) document_id String S3 key của tài liệu nguồn status String processing, completed, failed flashcards String JSON-encoded array của flashcards total_cards Number Số lượng flashcards được tạo page_count Number Số trang trong PDF nguồn chunk_count Number Số text chunks đã index created_at Number Unix timestamp Ví Dụ Item:\n{ \u0026#34;set_id\u0026#34;: \u0026#34;flashcard-set-123\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;document_id\u0026#34;: \u0026#34;uploads/documents/user-456/vocab-guide.pdf\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;flashcards\u0026#34;: \u0026#34;[{\\\u0026#34;question\\\u0026#34;:\\\u0026#34;What is...\\\u0026#34;,\\\u0026#34;answer\\\u0026#34;:\\\u0026#34;...\\\u0026#34;}]\u0026#34;, \u0026#34;total_cards\u0026#34;: 15, \u0026#34;page_count\u0026#34;: 8, \u0026#34;chunk_count\u0026#34;: 24, \u0026#34;created_at\u0026#34;: 1733644800 } Tạo Tables với AWS CLI # Tạo bảng evaluations (Writing + Speaking) aws dynamodb create-table \\ --table-name bandup-evaluations \\ --attribute-definitions \\ AttributeName=evaluation_id,AttributeType=S \\ AttributeName=user_id,AttributeType=S \\ --key-schema \\ AttributeName=evaluation_id,KeyType=HASH \\ AttributeName=user_id,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --tags Key=Project,Value=bandup Key=Environment,Value=production # Tạo bảng flashcard sets aws dynamodb create-table \\ --table-name bandup-flashcard-sets \\ --attribute-definitions \\ AttributeName=set_id,AttributeType=S \\ AttributeName=user_id,AttributeType=S \\ --key-schema \\ AttributeName=set_id,KeyType=HASH \\ AttributeName=user_id,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --tags Key=Project,Value=bandup Key=Environment,Value=production Bật Point-in-Time Recovery Bật PITR để bảo vệ dữ liệu:\n# Bật PITR cho bảng evaluations aws dynamodb update-continuous-backups \\ --table-name bandup-evaluations \\ --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true # Bật PITR cho bảng flashcard sets aws dynamodb update-continuous-backups \\ --table-name bandup-flashcard-sets \\ --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true Query Patterns Lấy lịch sử đánh giá của user:\nresponse = table.query( IndexName=\u0026#39;user_id-created_at-index\u0026#39;, # Nếu có GSI KeyConditionExpression=Key(\u0026#39;user_id\u0026#39;).eq(\u0026#39;user-456\u0026#39;), ScanIndexForward=False, # Mới nhất trước Limit=10 ) Lấy đánh giá cụ thể theo ID:\nresponse = table.get_item( Key={ \u0026#39;evaluation_id\u0026#39;: \u0026#39;eval-abc123\u0026#39;, \u0026#39;user_id\u0026#39;: \u0026#39;user-456\u0026#39; } ) Lấy flashcard sets của user:\nresponse = table.query( KeyConditionExpression=Key(\u0026#39;user_id\u0026#39;).eq(\u0026#39;user-456\u0026#39;), FilterExpression=Attr(\u0026#39;status\u0026#39;).eq(\u0026#39;completed\u0026#39;) ) Biến Môi Trường Lambda Cấu hình Lambda functions để sử dụng các bảng này:\nLambda Function Biến Môi Trường Giá Trị Writing Evaluator DYNAMODB_EVALUATIONS bandup-evaluations Speaking Evaluator DYNAMODB_EVALUATIONS bandup-evaluations Flashcard Generator DYNAMODB_FLASHCARD_SETS bandup-flashcard-sets IAM Policy cho Lambda Access { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/bandup-evaluations\u0026#34;, \u0026#34;arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/bandup-flashcard-sets\u0026#34; ] } ] } Bước Tiếp Theo Tiến hành đến Bedrock Integration để cấu hình Amazon Titan Embeddings.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Bài thu hoạch: AWS Cloud Mastery Series #3 — Theo AWS Well-Architected Security Pillar Mục đích của sự kiện Giới thiệu vai trò của Security Pillar trong AWS Well-Architected Framework. Hướng dẫn 5 trụ cột cốt lõi của bảo mật Cloud: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection và Incident Response. Cung cấp các best practices và kịch bản thực tế (Playbook) để bảo vệ ứng dụng trên Cloud. Nội dung nổi bật Pillar 1 — Identity \u0026amp; Access Management Nguyên tắc: Least Privilege, Zero Trust, Defense in Depth. IAM hiện đại: tránh long-term credentials, ưu tiên Roles và Policies. IAM Identity Center: SSO và quản lý Permission Sets. Bảo mật multi-account: SCP (Service Control Policies) và Permission Boundaries. Mini demo: validate IAM policy và mô phỏng quyền truy cập. Pillar 2 — Detection Giám sát liên tục: CloudTrail (org-level), GuardDuty, Security Hub. Logging ở mọi tầng: VPC Flow Logs, ALB/S3 logs. Tự động hóa cảnh báo: sử dụng EventBridge. Pillar 3 — Infrastructure Protection Bảo mật mạng: VPC segmentation (private vs public). Phòng thủ: Security Groups vs NACLs; dùng WAF, Shield, Network Firewall. Workload security: bảo mật EC2, ECS/EKS cơ bản. Pillar 4 — Data Protection Mã hóa: encryption at-rest \u0026amp; in-transit (S3, EBS, RDS, DynamoDB). Quản lý khóa và secrets: KMS, Secrets Manager, Parameter Store. Phân loại dữ liệu (data classification) và guardrails truy cập. Pillar 5 — Incident Response Vòng đời IR: quy trình xử lý sự cố theo AWS. IR playbook \u0026amp; automation. Kịch bản mẫu: compromised IAM key, S3 public exposure, EC2 malware detection. Tự động phản hồi bằng Lambda/Step Functions. Những gì học được Nắm được 5 trụ cột Security Pillar và nguyên tắc Shared Responsibility Model. IAM nâng cao: sử dụng IAM Identity Center, SCPs và tránh long-term credentials. Data security: tầm quan trọng của KMS và quản lý secrets. Incident Response: xây dựng playbook và tự động hóa phản hồi bằng serverless. Trải nghiệm trong event Buổi workshop là phần tổng kết của chuỗi, cung cấp kiến thức bảo mật trước khi hoàn thiện dự án. Phần trình bày về IAM Identity Center và Secrets Manager giúp giải quyết vấn đề xác thực Sub ID và quản lý khóa API của nhóm. Kịch bản IR (ví dụ S3 public exposure) rất hữu ích cho việc củng cố chính sách bảo mật dự án. Buổi Q\u0026amp;A giúp định hướng lộ trình học tiếp theo (Security Specialty). "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5 Xác định và giải quyết chi phí AWS bất thường trên tài khoản. Thiết kế và phân chia kiến trúc hạ tầng cho dự án. Bắt đầu cấu hình dự án ban đầu và phân bổ vai trò team. Khám phá AWS Skill Builder và nâng cao học tập về các chủ đề tối ưu hóa. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phân tích và xác định nguyên nhân chi phí bất thường trên tài khoản AWS.\n- Hoàn thành: Cost and Usage Management và Managing Quotas with Service Quotas. 07/10/2025 08/10/2025 AWS Cost Explorer 3 - Thiết kế và phân chia kiến trúc hạ tầng dự án.\n- Đề xuất các template kiến trúc cơ bản cho team tham khảo.\n- Hoàn thành: Building Highly Available Web Applications. 09/10/2025 10/10/2025 FCJ Community 4 - Xây dựng code skeleton và cấu hình các file dự án ban đầu.\n- Thiết lập môi trường phát triển.\n- Hoàn thành: Development Environment with AWS Toolkit for VS Code. 11/10/2025 13/10/2025 VS Code + AWS Toolkit 5 - Đăng ký AWS Skill Builder và khám phá các khóa học.\n- Nghiên cứu kỹ thuật tối ưu EC2.\n- Hoàn thành: Right-Sizing with EC2 Resource Optimization. 11/10/2025 12/10/2025 AWS Skill Builder Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Cost and Usage Management Tối ưu chi phí ✅ Managing Quotas with Service Quotas Operations ✅ Billing Console Delegation Quản lý chi phí ✅ Right-Sizing with EC2 Resource Optimization Tối ưu chi phí ✅ Development Environment with AWS Toolkit for VS Code Phát triển ✅ Building Highly Available Web Applications Kiến trúc ✅ Database Essentials with Amazon RDS Database ✅ NoSQL Database Essentials with Amazon DynamoDB Database ✅ In-Memory Caching with Amazon ElastiCache Database ✅ Command Line Operations with AWS CLI Operations ✅ Kết quả đạt được tuần 5 Kỹ năng kỹ thuật đã tiếp thu:\nTối ưu chi phí:\nXác định nguyên nhân chi phí AWS bất thường: Xóa không hoàn toàn tài nguyên EC2 (EBS volumes, Elastic IPs) Thiếu kiểm soát tài khoản người dùng và IAM permissions Tài nguyên chạy ở các regions không sử dụng Học các best practices quản lý chi phí AWS: AWS Budgets để cảnh báo chi phí chủ động Cost Explorer để phân tích patterns chi tiêu Service Quotas để quản lý giới hạn tài khoản Billing Console Delegation cho visibility chi phí team Đề xuất các biện pháp tối ưu chi phí cho team Thiết kế kiến trúc:\nThiết kế thành công kiến trúc hạ tầng dự án Tạo các template kiến trúc tham khảo cho team áp dụng Áp dụng nguyên tắc High Availability: Triển khai Multi-AZ Chiến lược load balancing Patterns replication database Design patterns fault-tolerant Môi trường phát triển:\nThiết lập AWS Toolkit cho VS Code để phát triển streamlined Thành thạo AWS CLI cho command-line operations Xây dựng code skeleton vững chắc với các file cấu hình ban đầu Thiết lập nền tảng dự án cho hợp tác team Dịch vụ Database:\nHiểu Amazon RDS cho nhu cầu relational database Học DynamoDB cho NoSQL workloads Khám phá ElastiCache cho in-memory caching (Redis/Memcached) Áp dụng tiêu chí chọn database dựa trên use cases Tiến độ dự án:\nĐăng ký và kích hoạt tài khoản AWS Skill Builder Bắt đầu khám phá các khóa học nâng cao và learning paths Kiến trúc hạ tầng đã hoàn thiện và documented Môi trường phát triển đã cấu hình và sẵn sàng coding Bài học chính:\nTối ưu chi phí bắt đầu từ visibility - sử dụng Cost Explorer hàng ngày Right-sizing EC2 instances có thể giảm chi phí 30-50% High availability yêu cầu planning across multiple AZs AWS Toolkit cho VS Code cải thiện đáng kể developer productivity Chọn database phụ thuộc vào data model, scale, và access patterns Service Quotas ngăn ngừa các giới hạn capacity không mong muốn "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.5-setup-be/","title":"Triển khai Backend (ECS Fargate)","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ triển khai IELTS BandUp Backend, một ứng dụng Spring Boot đóng vai trò là lớp xử lý logic cốt lõi của nền tảng.\nKhác với Frontend, Backend yêu cầu các cơ chế lưu trữ và bộ nhớ đệm (caching) để hoạt động hiệu quả. Do đó, trước khi khởi chạy các container trên ECS Fargate, chúng ta bắt buộc phải thiết lập hạ tầng dữ liệu (PostgreSQL và Redis). Dịch vụ Backend sẽ được đặt trong các Private Subnet, được bảo vệ nghiêm ngặt bởi Security Group và sẽ giao tiếp với các dịch vụ AI thông qua AWS SDK.\nCác bước thực hiện Để triển khai hệ thống backend hoàn chỉnh, chúng ta sẽ tuân theo trình tự sau:\nContainer Registry (ECR): Đóng gói ứng dụng Spring Boot và đẩy Docker image lên kho lưu trữ ECR riêng tư. Cơ sở dữ liệu quan hệ (RDS): Khởi tạo Amazon RDS for PostgreSQL để lưu trữ dữ liệu người dùng, kết quả bài thi và nội dung học tập. Bộ nhớ đệm (ElastiCache): Thiết lập cụm Amazon ElastiCache (Redis) để quản lý phiên đăng nhập (session) và tăng tốc độ truy xuất dữ liệu. ECS Task \u0026amp; Service: Định nghĩa cấu hình task (bao gồm các biến môi trường kết nối Database) và khởi chạy dịch vụ. Nội dung Thiết lập ECR \u0026amp; Đẩy Image Tạo PostgreSQL RDS Tạo ElastiCache (Redis) Tạo Service \u0026amp; Task "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Hệ Thống Tự Học IELTS - Workshop Hạ Tầng AWS Tổng Quan Workshop toàn diện này hướng dẫn bạn xây dựng hạ tầng AWS sẵn sàng cho production cho Hệ Thống Tự Học IELTS. Bạn sẽ học cách triển khai ứng dụng web có tính sẵn sàng cao, khả năng mở rộng và bảo mật sử dụng các dịch vụ AWS hiện đại và các phương pháp tốt nhất.\nKiến trúc triển khai theo mô hình active-passive Multi-AZ trên Amazon ECS, với lớp dịch vụ AI serverless cho việc đánh giá thông minh và tạo nội dung.\nNhững Gì Bạn Sẽ Xây Dựng Sau khi hoàn thành workshop này, bạn sẽ triển khai được:\nThành Phần Dịch Vụ AWS Mục Đích Lớp Mạng VPC, Subnets, NAT Gateway Hạ tầng mạng cô lập, bảo mật Nền Tảng Container ECS Fargate, ECR Điều phối container serverless Cân Bằng Tải ALB, Route 53, ACM Phân phối lưu lượng và SSL termination Lớp Dữ Liệu RDS PostgreSQL, ElastiCache, S3 CSDL quan hệ, caching, lưu trữ object Dịch Vụ AI API Gateway, SQS, Lambda, DynamoDB Pipeline xử lý AI serverless CI/CD CodePipeline, CodeBuild Pipeline triển khai tự động Bảo Mật IAM, Secrets Manager, WAF Quản lý danh tính và bảo vệ Giám Sát CloudWatch Logs, Alarms Quan sát và cảnh báo Điểm Nổi Bật Kiến Trúc Thiết Kế Tính Sẵn Sàng Cao:\nTriển khai Multi-AZ trên hai Availability Zones Failover active-passive cho ECS services RDS Multi-AZ với failover tự động Application Load Balancer với health checks Kiến Trúc AI Serverless:\nAPI Gateway cho các RESTful AI endpoints SQS cho xử lý message bất đồng bộ Lambda functions cho Writing Assessment, Speaking Assessment, và RAG-based Flashcard Generation DynamoDB để lưu trữ kết quả AI Tích hợp Amazon Bedrock cho các AI models (Gemma 3 12B, Titan Embeddings) Google Gemini API cho smart query generation Phương Pháp Bảo Mật Tốt Nhất:\nPrivate subnets cho application và database tiers Security groups với least-privilege access AWS WAF cho application-level protection Secrets Manager cho quản lý credentials IAM roles với quyền tối thiểu cần thiết Điều Kiện Tiên Quyết Trước khi bắt đầu workshop này, hãy đảm bảo bạn có:\nTài khoản AWS với quyền phù hợp AWS CLI đã cài đặt và cấu hình Hiểu biết cơ bản về các dịch vụ AWS (VPC, EC2, ECS) Docker đã cài đặt locally cho container builds Git cho version control Thời Gian Hoàn Thành Phần Thời Gian Ước Tính Điều kiện tiên quyết 15 phút VPC \u0026amp; Network Setup 30 phút ECS \u0026amp; Container Setup 45 phút Load Balancer Configuration 30 phút Database \u0026amp; Storage Setup 45 phút AI Service Architecture 60 phút CI/CD Pipeline 30 phút Security \u0026amp; IAM 30 phút Monitoring Setup 20 phút Tổng ~5 giờ Nội Dung Tổng Quan Workshop Điều Kiện Tiên Quyết VPC \u0026amp; Network Setup ECS \u0026amp; Container Setup Load Balancer Configuration Database \u0026amp; Storage Setup AI Service Architecture CI/CD Pipeline Security \u0026amp; IAM Monitoring \u0026amp; Logging Clean Up "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.6-ai-service/5.6.5-bedrock-integration/","title":"Bedrock Integration","tags":[],"description":"","content":"Tổng Quan Cấu hình Amazon Bedrock cho AI model access bao gồm Gemma 3 12B và Titan Embeddings.\nEnable Model Access Điều hướng đến Amazon Bedrock → Model access Request access đến: Amazon Titan Text Express (cho assessments) Amazon Titan Embeddings V2 (cho RAG) Meta Llama 3 hoặc Anthropic Claude (optional) Test Bedrock API import boto3 import json bedrock = boto3.client(\u0026#39;bedrock-runtime\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;) # Test Titan Text response = bedrock.invoke_model( modelId=\u0026#39;amazon.titan-text-express-v1\u0026#39;, body=json.dumps({ \u0026#39;inputText\u0026#39;: \u0026#39;Hello, how are you?\u0026#39;, \u0026#39;textGenerationConfig\u0026#39;: { \u0026#39;maxTokenCount\u0026#39;: 100, \u0026#39;temperature\u0026#39;: 0.7 } }) ) print(json.loads(response[\u0026#39;body\u0026#39;].read())) Titan Embeddings cho RAG # Generate embeddings response = bedrock.invoke_model( modelId=\u0026#39;amazon.titan-embed-text-v2:0\u0026#39;, body=json.dumps({ \u0026#39;inputText\u0026#39;: \u0026#39;Document chunk text here\u0026#39; }) ) embedding = json.loads(response[\u0026#39;body\u0026#39;].read())[\u0026#39;embedding\u0026#39;] # Lưu trong OpenSearch hoặc dùng cho similarity search Google Gemini Integration Cho smart query generation:\nimport google.generativeai as genai genai.configure(api_key=os.environ[\u0026#39;GEMINI_API_KEY\u0026#39;]) model = genai.GenerativeModel(\u0026#39;gemini-2.5-flash\u0026#39;) response = model.generate_content( f\u0026#34;\u0026#34;\u0026#34;Analyze this document and generate 10 intelligent questions: {document_text} \u0026#34;\u0026#34;\u0026#34; ) Tối Ưu Chi Phí Sử dụng Titan Text Express cho assessments (lower cost) Batch embeddings generation khi có thể Implement caching cho repeated queries Sử dụng Google Gemini free tier cho query generation Bước Tiếp Theo Tiến hành đến CI/CD Pipeline.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6 Nắm vững các dịch vụ lưu trữ AWS cơ bản và use cases của chúng. Nâng cao kỹ năng lập trình Python thông qua các bài tập thực hành. Thiết kế và hoàn thiện kiến trúc hạ tầng dự án. Tham gia webinar \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; để khám phá thực hành DevSecOps và Amazon Q Developer. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu Amazon S3 cơ bản: Kiến trúc Bucket, đảm bảo độ bền, và khả năng host static website.\n- Khám phá S3 Storage Classes (Standard, Standard-IA) và Amazon Glacier cho giải pháp cold storage.\n- Hoàn thành: Static Website Hosting with Amazon S3. 14/10/2025 15/10/2025 AWS S3 Documentation 3 - Học các loại AWS Storage Gateway (File, Volume, Tape Gateway) và patterns tích hợp.\n- Hiểu Object Lifecycle Management policies để tối ưu chi phí.\n- Thực hành Python cơ bản: data structures, functions, và error handling.\n- Tham gia webinar: \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; với sự góp mặt của anh Hoàng Kha. 16/10/2025 17/10/2025 AWS Storage Gateway\nAWS Events 4 - Nghiên cứu khái niệm disaster recovery: RTO, RPO, và các chiến lược Backup \u0026amp; Restore.\n- Khám phá dịch vụ AWS Backup cho quản lý backup tập trung.\n- Thực hành: Tạo S3 buckets, upload files, cấu hình static website hosting, và test lifecycle policies.\n- Nghiên cứu phương pháp DevSecOps: CI/CD pipelines, SAST/DAST tools, Infrastructure as Code. 18/10/2025 19/10/2025 AWS Backup 5 - Hoàn thiện sơ đồ kiến trúc hạ tầng dự án với các mối quan hệ component chi tiết.\n- Tái cấu trúc code skeleton để phù hợp với thiết kế kiến trúc đã cập nhật.\n- Chuẩn hóa lựa chọn ngôn ngữ lập trình và framework cho tính nhất quán của team.\n- Khám phá khả năng Amazon Q Developer: AI-powered code generation, testing, và vulnerability scanning. 20/10/2025 21/10/2025 Amazon Q Developer Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Static Website Hosting with Amazon S3 Lưu trữ ✅ Data Protection with AWS Backup Reliability ✅ Content Delivery with Amazon CloudFront Mạng ✅ Kết quả đạt được tuần 6 Thành thạo Dịch vụ Lưu trữ:\nHiểu toàn diện về kiến trúc Amazon S3: Buckets, độ bền (99.999999999%), và static website hosting Nắm vững S3 Storage Classes: Standard, Standard-IA, Glacier cho các access patterns khác nhau Học patterns tích hợp AWS Storage Gateway cho hybrid cloud storage Hiểu Object Lifecycle Management cho automated data tiering và tối ưu chi phí Disaster Recovery \u0026amp; Backup:\nNắm bắt fundamentals disaster recovery: RTO (Recovery Time Objective) và RPO (Recovery Point Objective) Học dịch vụ AWS Backup cho quản lý backup tập trung across services Hiểu các chiến lược Backup \u0026amp; Restore cho business continuity Kỹ năng Phát triển:\nNâng cao lập trình Python thông qua các bài tập thực hành Tạo thành công S3 buckets, cấu hình static websites, và test lifecycle policies Cải thiện hiểu biết về data structures và error handling Lập kế hoạch Dự án:\nHoàn thiện sơ đồ kiến trúc hạ tầng toàn diện Tái cấu trúc code skeleton với cấu trúc thư mục phù hợp Chuẩn hóa technology stack cho hợp tác team Insights DevSecOps:\nTham gia webinar \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; (16/10/2025) Học tích hợp DevSecOps: Security trong SDLC sử dụng Jenkins (CI/CD), SonarQube (SAST), OWASP ZAP (DAST), Terraform (IaC) Khám phá Amazon Q Developer: AI assistant cho code generation, testing, vulnerability scanning, và AWS optimization Bài học chính:\nS3 là nền tảng cho object storage trên AWS - hiểu storage classes là cực kỳ quan trọng cho tối ưu chi phí Lifecycle policies tự động hóa quản lý dữ liệu và giảm chi phí lưu trữ đáng kể AWS Backup cung cấp quản lý backup thống nhất across multiple AWS services DevSecOps tích hợp security xuyên suốt development lifecycle, không phải là afterthought "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.6-ai-service/","title":"AI Service Architecture","tags":[],"description":"","content":"Tổng Quan Phần này bao gồm kiến trúc serverless AI service sử dụng API Gateway, SQS, Lambda, DynamoDB, và Amazon Bedrock cho intelligent assessment và content generation.\nKiến Trúc AI Service AI service triển khai theo mô hình fully serverless:\nUser → API Gateway → SQS Queue → Lambda → AI Model → DynamoDB → Response Ba Lambda Functions:\nFunction Mục Đích AI Model Writing Evaluate IELTS writing assessment Gemma 3 12B / Gemini Speaking Evaluate Audio transcription + assessment Transcribe + Gemma 3 12B Flashcard Generate RAG-based flashcard creation Titan Embeddings + Gemini Nội Dung API Gateway SQS Queues Lambda Functions DynamoDB Bedrock Integration Request Flow User submits request (writing sample, audio, document) API Gateway validates và enqueues message đến SQS SQS triggers appropriate Lambda function Lambda processes với AI model (Bedrock/Gemini) Results stored trong DynamoDB User retrieves results qua API Thời Gian Ước Tính: ~60 phút Ước Tính Chi Phí Tóm Tắt Chi Phí Hàng Tháng:\nChi Phí Ban Đầu Chi Phí Hàng Tháng Tổng Chi Phí 12 Tháng Tiền Tệ $0.00 $23.61 $283.32 USD Lưu ý: Bao gồm chi phí ban đầu\nChi Tiết Phân Tích Chi Phí:\nDịch Vụ Mô Tả Khu Vực Chi Phí Hàng Tháng (USD) Chi Phí Hàng Năm (USD) AWS Lambda Writing Evaluator Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda Speaking Evaluator Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda Evaluation Status Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda S3 Upload Asia Pacific (Singapore) $0.00 $0.00 Amazon API Gateway HTTP API Asia Pacific (Singapore) $0.42 $5.04 S3 Standard Audio bucket Asia Pacific (Singapore) $0.51 $6.12 S3 Standard Documents Bucket Asia Pacific (Singapore) $0.53 $6.36 DynamoDB Evaluations Table Asia Pacific (Singapore) $0.37 $4.44 DynamoDB Flashcard Sets Table Asia Pacific (Singapore) $0.52 $6.24 Amazon SQS Writing/Speaking/Flashcard queues Asia Pacific (Singapore) $0.00 $0.00 AWS Secrets Manager Secrets management Asia Pacific (Singapore) $0.45 $5.40 Amazon CloudWatch RAG Lambda logs Asia Pacific (Singapore) $0.01 $0.08 Amazon Bedrock Bedrock inference US East (N. Virginia) $0.50 $6.00 OpenAI GPT inference US East (N. Virginia) $20.30 $243.65 Tổng Cộng $23.61 $283.32 AWS Pricing Calculator chỉ cung cấp ước tính về phí AWS của bạn và không bao gồm bất kỳ loại thuế nào có thể áp dụng. Phí thực tế của bạn phụ thuộc vào nhiều yếu tố, bao gồm việc sử dụng thực tế các dịch vụ AWS của bạn.\nXem chi tiết phân tích chi phí: AWS Pricing Calculator\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Tổng Quan Thực Tập Trong suốt thời gian thực tập tại Amazon Web Services (AWS) từ 08/09 đến 09/12/2024, tôi đã có cơ hội quý báu để học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường điện toán đám mây thực tế.\nTôi đã tham gia xây dựng Nền tảng Học IELTS Bandup - một ứng dụng AI toàn diện giúp học sinh chuẩn bị cho kỳ thi IELTS thông qua đánh giá Writing và Speaking tự động, cũng như tạo Flashcard thông minh từ tài liệu học tập.\nThành Tựu Chính Qua dự án này, tôi đã phát triển và cải thiện các kỹ năng:\nKiến Trúc Cloud \u0026amp; Dịch Vụ AWS:\nThiết kế và triển khai kiến trúc serverless có khả năng mở rộng sử dụng AWS Lambda, API Gateway và SQS Cấu hình mạng VPC với public/private subnets, NAT Gateway và Security Groups Thiết lập điều phối container với Amazon ECS và Fargate Quản lý lưu trữ dữ liệu với Amazon S3, DynamoDB và ElastiCache (Redis) Tích hợp dịch vụ AI bao gồm Amazon Bedrock (Titan Embeddings) và Google Gemini API Phát Triển \u0026amp; DevOps:\nXây dựng Lambda functions bằng Python cho đánh giá AI Triển khai pipeline RAG (Retrieval-Augmented Generation) cho tạo flashcard Thiết lập CI/CD pipelines với GitLab và AWS CodePipeline Thực hành nguyên tắc Infrastructure as Code Tích Hợp AI/ML:\nTích hợp Google Gemini API cho xử lý audio gốc (tiết kiệm 72% chi phí so với phương pháp truyền thống) Triển khai Amazon Titan Text Embeddings V2 cho tìm kiếm vector similarity Thiết kế chiến lược prompt engineering cho chấm điểm band IELTS Tác Phong Làm Việc Trong suốt thời gian thực tập, tôi luôn cố gắng:\nHoàn thành nhiệm vụ được giao với chất lượng cao và chú ý đến chi tiết Tuân thủ chính sách công ty và AWS best practices về bảo mật và tối ưu chi phí Tích cực giao tiếp với mentors và thành viên nhóm để cải thiện hiệu quả công việc Ghi chép công việc kỹ lưỡng để chuyển giao kiến thức Tiêu Chí Tự Đánh Giá Để phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết các dịch vụ AWS, áp dụng nguyên tắc kiến trúc cloud, thành thạo công cụ phát triển ✅ ☐ ☐ 2 Khả năng học hỏi Học nhanh các dịch vụ AWS mới, công nghệ AI và thực hành phát triển ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu giải pháp, nghiên cứu tài liệu mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành Lambda functions, documentation và deployments đúng hạn với chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ lịch trình, coding standards và quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback về code reviews và quyết định kiến trúc ✅ ☐ ☐ 7 Giao tiếp Trình bày giải pháp kỹ thuật, viết documentation và báo cáo tiến độ rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Phối hợp hiệu quả với mentors và tham gia thảo luận nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, tuân thủ AWS security best practices, duy trì tính chuyên nghiệp ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Debug Lambda functions, tối ưu chi phí (tiết kiệm 72% cho xử lý audio), tìm giải pháp sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hoàn thành 4 Lambda functions, documentation toàn diện và demo hoạt động ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Kiến Thức Thu Được Kỹ Năng Kỹ Thuật:\nHiểu sâu về kiến trúc serverless AWS Kinh nghiệm tích hợp AI/ML trong hệ thống production Thành thạo Python cho phát triển Lambda function Kiến thức về RAG pipelines và vector embeddings Kỹ Năng Mềm:\nViết tài liệu kỹ thuật Phân tích vấn đề và debug có hệ thống Chiến lược tối ưu chi phí cloud Làm việc trong môi trường doanh nghiệp Cần Cải Thiện Kỷ luật: Nâng cao quản lý thời gian và tuân thủ nghiêm ngặt lịch họp và deadline Giao tiếp: Cải thiện kỹ năng trình bày kỹ thuật và khả năng giải thích khái niệm phức tạp cho người không chuyên Giải quyết vấn đề: Phát triển phương pháp có cấu trúc hơn để debug và troubleshooting Networking: Xây dựng quan hệ chuyên nghiệp mạnh mẽ hơn trong cộng đồng AWS Lời Cảm Ơn Tôi xin bày tỏ lòng biết ơn chân thành đến:\nCác mentors tại AWS vì sự hướng dẫn và kiên nhẫn Team đã hỗ trợ và hợp tác AWS đã cung cấp cơ hội học tập tuyệt vời này Kỳ thực tập này là trải nghiệm có ý nghĩa chuyển đổi, đã nâng cao đáng kể kỹ năng của tôi về điện toán đám mây và tích hợp AI. Tôi tin tưởng rằng kiến thức và kinh nghiệm thu được sẽ có giá trị trong sự nghiệp tương lai của mình.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7 Tập trung ôn tập toàn diện và củng cố kiến thức chuẩn bị cho kỳ thi giữa kỳ. Luyện tập các bài lab và câu hỏi trắc nghiệm trên các nền tảng AWS Builders và AWSboy để làm quen với format đề thi. Hệ thống hóa các dịch vụ AWS cơ bản đã học: EC2, S3, VPC, IAM, RDS, Lambda, DynamoDB. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hệ thống hóa kiến thức dịch vụ Compute (EC2, Lambda). - Thực hành: Hoàn thành bài tập/lab về tạo, cấu hình, quản lý vòng đời của EC2 Instances. - Ôn tập tạo Lambda function, triggers, và execution models. 22/10/2024 22/10/2024 AWS Builders, AWSboy 3 - Ôn tập kiến thức dịch vụ Storage (S3, EBS, EFS). - Thực hành: Hoàn thành bài tập về S3 storage classes (Standard, IA, Glacier), EBS volume types, và EFS use cases. - Thực hành S3 bucket policies và access control. 23/10/2024 23/10/2024 AWS Builders, AWSboy 4 - Củng cố kiến thức về Networking (VPC, Subnets, Route Tables, Internet Gateway, Security Groups, NACLs). - Thực hành: Luyện tập câu hỏi về cấu hình VPC, Security Group rules vs NACL rules, và routing principles. - Ôn tập VPC Peering và Transit Gateway concepts. 24/10/2024 24/10/2024 AWS Builders, AWSboy 5 - Ôn tập Database services (RDS, DynamoDB) và Security/Identity (IAM). - Thực hành: Tập trung vào các khái niệm IAM Policies, IAM Roles, và IAM Users cơ bản. - Thực hành thiết kế DynamoDB table và cấu hình RDS instance. 25/10/2024 25/10/2024 AWS Builders, AWSboy 6 - Tổng kết và Luyện đề: Làm các bài thi thử toàn diện trên nền tảng AWS Builders và AWSboy. - Rà soát các lĩnh vực yếu được xác định trong bài thi thử để nghiên cứu thêm. - Tạo ghi chú tóm tắt để tham khảo nhanh trước kỳ thi. 26/10/2024 26/10/2024 AWS Builders, AWSboy Kết quả đạt được tuần 7 Hoàn thành ôn tập toàn diện các nhóm dịch vụ AWS cơ bản: Compute, Storage, Networking, Database, Security (IAM). Luyện tập thành công nhiều labs và câu hỏi trắc nghiệm trên các nền tảng AWS Builders và AWSboy. Nắm vững các thông số cơ bản của EC2 (Instance Types, AMI, EBS volumes) và hoạt động của S3 (Storage Classes, Object/Bucket management). Hiểu rõ mối quan hệ và cấu hình của các thành phần trong VPC (Public/Private Subnets, Routing, Security Groups vs NACLs). Tự tin hơn với kiến thức đã học, sẵn sàng cho kỳ thi giữa kỳ sắp tới. Tạo ghi chú học tập toàn diện bao gồm tất cả các danh mục dịch vụ AWS chính. Xác định và giải quyết các khoảng trống kiến thức thông qua các phiên thực hành có mục tiêu. Bài học chính:\nSecurity Groups là stateful (return traffic tự động được phép), NACLs là stateless (cần rules hai chiều) EC2 instance types được tối ưu cho các workloads khác nhau (compute, memory, storage, GPU) S3 storage classes cân bằng chi phí vs. tần suất truy cập IAM policies tuân theo nguyên tắc explicit deny - policy hạn chế nhất thắng VPC routing tuân theo nguyên tắc most specific route match "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tôi viết phần này để ghi lại trải nghiệm của riêng mình với chương trình First Cloud Journey (FCJ) và gửi gắm vài góp ý để các bạn thực tập sau có thể tận dụng cơ hội tốt hơn nữa.\nĐánh Giá Chung 1. Môi trường làm việc\nAWS mang đến đúng kiểu môi trường tôi nghĩ chỉ có sau nhiều năm làm việc: văn phòng tiện nghi, phòng tập trung yên tĩnh và hệ thống công cụ hoạt động trơn tru. Điều bất ngờ nhất là sự gần gũi của mọi người xung quanh. Các anh chị kỹ sư senior luôn sẵn sàng dừng lại để giải thích bối cảnh, còn quản lý thì chủ động bảo tôi nhắn tin khi gặp bế tắc. Mô hình hybrid giúp tôi linh hoạt: những ngày cần tập trung thì làm remote, còn khi cần brainstorm thì lên văn phòng.\nVì FCJ xem sự tò mò là điểm mạnh, tôi tự tin đặt nhiều câu hỏi hơn bình thường. Với sandbox account và credits sẵn có, tôi dựng hạ tầng thực, phá hỏng nó rồi sửa lại dưới sự hướng dẫn—điều mà sách vở không thể mang lại.\n2. Sự hỗ trợ của Mentor / Team Admin\nMentor của tôi đóng vai trò huấn luyện thay vì chỉ đưa đáp án. Khi mang đến một blocker, tôi luôn được gợi mở đọc whitepaper, thử công cụ hoặc phân tích log để tự rút ra lời giải. Những điểm nổi bật:\n1:1 hàng tuần để demo tiến độ, retros các sai sót và lên kế hoạch cho rủi ro sắp tới Code review kỹ lưỡng nhấn mạnh khả năng đọc, test và vận hành của mỗi commit Phiên đào sâu kiến trúc để tôi hiểu các đánh đổi chứ không chỉ nhìn sơ đồ cuối cùng Định hướng nghề nghiệp xoay quanh certifications, danh mục dự án và lộ trình sau khi tốt nghiệp Song song, team admin lo trọn hậu cần—from quyền IAM đến hỗ trợ thiết bị—trước khi tôi kịp nhận ra vấn đề. Nhờ vậy tôi có thể dồn toàn bộ thời gian cho việc ship tính năng.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nDự án Bandup IELTS vừa bám sát nền tảng khoa học máy tính vừa kéo tôi sang địa hạt cloud thực chiến:\nKiến Thức Học Thuật Áp Dụng Kỹ Năng Mới Phát Triển Lập trình Python AWS Lambda \u0026amp; dàn nhạc serverless Cấu trúc dữ liệu \u0026amp; thuật toán RAG pipelines \u0026amp; vector search Kiến thức cơ sở dữ liệu DynamoDB, ElastiCache, mô hình dữ liệu Kiến thức mạng máy tính Thiết kế VPC, phân subnet, kiểm soát bảo mật Kỹ thuật phần mềm Tự động hóa CI/CD, Infrastructure as Code Bài tập trên lớp hiếm khi đòi hỏi SLA hay tích hợp AI thật sự. Việc tự tay xây dựng luồng audio với Gemini và embedding với Titan giúp tôi thấm rõ những yếu tố như độ trễ, thông lượng và chi phí.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nFCJ kết hợp giữa khung học tập có định hướng và sự tự chủ thực chiến. Trong 12 tuần tôi đã:\nLàm việc với hơn 15 dịch vụ AWS thuộc compute, integration, data và AI (Lambda, API Gateway, SQS, DynamoDB, S3, ECS, Fargate, Bedrock, \u0026hellip;) Sở hữu trọn vòng đời tính năng: từ định nghĩa scope, viết code, test đến triển khai 4 Lambda functions Rèn kỹ năng tối ưu chi phí, chứng minh được mức tiết kiệm 72% nhờ quy trình audio native của Gemini Ghi chép đầy đủ thông qua bộ workshop này để người đi sau có lộ trình rõ ràng Thử nghiệm tích hợp AI/ML mang lại giá trị ngay cho người học Những buổi checkpoint với mentor giữ cho tôi không đi chệch hướng, đồng thời vẫn đủ tự do để thử nghiệm và học từ sai sót.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nMỗi Leadership Principle của Amazon mà tôi từng đọc đều xuất hiện trong đời sống hằng ngày. Ví dụ:\nĐồng đội đầu tư thời gian kèm tôi hoàn thiện demo dù đã tối muộn Khi gây ra sự cố, cả nhóm làm post-mortem không đổ lỗi mà rút kinh nghiệm Đề xuất về luồng audio native với Gemini không chỉ được lắng nghe mà còn trở thành chuẩn mặc định Tinh thần “Day 1” không chỉ là khẩu hiệu; mọi người liên tục hỏi làm sao để Bandup phục vụ học viên tốt hơn Cảm giác được góp sức thực sự chứ không phải chỉ quan sát khiến tôi gắn bó ngay từ tuần đầu.\n6. Chính sách / phúc lợi cho thực tập sinh\nFCJ thực sự đầu tư cho thực tập sinh:\n✅ Phụ cấp xứng đáng với giá trị công việc ✅ Giờ giấc linh hoạt giúp cân bằng lịch học đại học ✅ Truy cập không giới hạn Skill Builder, whitepaper và tech talk nội bộ ✅ Kết nối với kỹ sư từ nhiều org khác nhau để trao đổi nghề nghiệp ✅ Sản phẩm thực tế đủ sức đưa thẳng vào portfolio Câu Hỏi Phản Ánh Điều khiến tôi hài lòng nhất trong kỳ thực tập?\nĐược ship tính năng mà người học thực sự sử dụng. Khoảnh khắc Speaking Evaluator nuốt file audio, xử lý qua Gemini rồi trả về điểm band thông qua Lambda pipeline do tôi xây dựng khiến tôi nhận ra: code của mình đang giúp ai đó học tốt hơn.\nĐiều gì có thể cải thiện cho thế hệ thực tập tiếp theo?\nCấp quyền AWS sớm hơn để mọi người lao vào xây dựng ngay ngày đầu Bộ onboarding có cấu trúc gồm kiến thức AWS nền tảng, cách cấu hình CLI và các lưu ý bảo mật Ghép cặp giữa các thực tập sinh trên cùng sáng kiến để học hỏi lẫn nhau Cơ hội luân chuyển/shadow các team AWS khác để hiểu bức tranh rộng hơn Tôi có giới thiệu chương trình này cho bạn bè không?\nChắc chắn. Nếu thích cloud engineering, FCJ mang lại:\nQuyền truy cập trực tiếp vào dịch vụ AWS và quy trình production Mentor tận tâm đồng hành Quyền sở hữu đối với các deliverable quan trọng Thành quả rõ ràng để trình bày với nhà tuyển dụng Bạn chỉ cần tinh thần tò mò và sự nỗ lực nghiêm túc.\nĐề Xuất \u0026amp; Kỳ Vọng Tương Lai Một vài ý tưởng để FCJ tiếp tục nâng tầm:\nPlaybook tập trung cho thực tập sinh với hướng dẫn setup môi trường, tip xử lý sự cố và mẫu kiến trúc Buổi show-and-tell cách tuần để thực tập sinh demo tiến độ, nhận góp ý và luyện kỹ năng trình bày Khuyến khích thi chứng chỉ như voucher hoặc nhóm học Cloud Practitioner/Solutions Architect Nhóm alumni FCJ kết nối người đi trước với thế hệ hiện tại để chia sẻ kinh nghiệm Tôi có muốn tiếp tục đồng hành?\nTất nhiên. Tôi đặt mục tiêu:\nQuay lại sau khi tốt nghiệp với vai trò cloud engineer hoặc solutions architect Làm mentor cho khóa FCJ kế tiếp để truyền lửa và kinh nghiệm Cập nhật bộ workshop này giúp đàn em onboard nhanh hơn Lời kết\nFCJ đã tái định hình cách tôi nghĩ về việc xây dựng trên nền tảng đám mây. Tôi bước vào với kiến thức sách vở và sự tò mò; tôi rời đi với quy trình làm việc đã được kiểm chứng, kỹ năng giao tiếp tốt hơn và sự tự tin khi thiết kế hệ thống an toàn, mở rộng được. Cảm ơn tất cả mọi người tại AWS đã đầu tư cho hành trình của tôi. 🙏\n\u0026ldquo;Sự trưởng thành đến khi tò mò gặp gỡ tinh thần trách nhiệm. FCJ chính là điểm giao đó đối với tôi.\u0026rdquo;\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.7-cicd-pipeline/","title":"CI/CD với CodeBuild &amp; CodePipeline","tags":[],"description":"","content":"Quy trình CI/CD với AWS CodeBuild \u0026amp; CodePipeline Tài liệu này hướng dẫn triển khai quy trình CI/CD dùng AWS CodePipeline và CodeBuild với GitLab làm SCM. Khi tạo một Release mới trong repository GitLab, CodePipeline sẽ được kích hoạt, CodeBuild chạy hai dự án frontend và backend dựa trên frontend-buildspec.yml và backend-buildspec.yml hiện có, sau đó CodePipeline deploy lên ECS.\nBạn sẽ làm gì 5.3.1 – Cấu hình dự án CodeBuild (frontend/backend) và trigger theo Release GitLab 5.3.2 – Thiết kế CodePipeline để deploy ECS và tích hợp artifact sau build Điều kiện tiên quyết Quyền IAM cho CodeBuild, CodePipeline, S3, Secrets Manager (nếu dùng token GitLab) và IAM pass role. Ứng dụng mẫu có buildspec.yml (chúng tôi sẽ cung cấp mẫu tối thiểu trong bước). S3 bucket cho artifact của pipeline (trình hướng dẫn CodePipeline sẽ tạo/chọn giúp bạn). Sơ đồ tổng quan Luồng chính: Tag push từ GitLab -\u0026gt; API Gateway/Lambda -\u0026gt; upload archive lên S3 -\u0026gt; CodePipeline (S3 Source) kích hoạt -\u0026gt; CodeBuild build -\u0026gt; (Tùy chọn) Deploy.\nĐặt sơ đồ tại: static/images/5-Workshop/5.3-S3-vpc/ci-overview.png.\nMẹo: Dùng đường dẫn ảnh tuyệt đối /images/... và lưu screenshot trong static/images/5-Workshop/5.3-S3-vpc/.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8 Hoàn thành kỳ thi giữa kỳ (Ngày 31/10) với kết quả tốt. Bắt đầu triển khai các chức năng CRUD (Create, Read, Update, Delete) nền tảng cho dự án Bandup IELTS. Nghiên cứu và lập kế hoạch tích hợp dịch vụ AWS Serverless (Lambda, API Gateway, DynamoDB) cho kiến trúc dự án. Thiết lập môi trường phát triển và xây dựng cấu trúc dự án. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập tổng hợp lần cuối kiến thức chuẩn bị cho kỳ thi giữa kỳ. - Rà soát các câu hỏi khó và các khái niệm thường bị nhầm lẫn (IAM Policies vs Roles, Security Groups vs NACLs, VPC routing). - Thực hành quản lý thời gian cho việc hoàn thành bài thi. 28/10/2024 28/10/2024 Ghi chú cá nhân, AWS Builders 3 - Chuẩn bị tâm lý và thiết lập công cụ cho kỳ thi. - Thực hành: Bắt đầu thiết lập môi trường phát triển cho dự án Bandup IELTS. - Cài đặt và cấu hình Python development tools, AWS CLI, và IDE setup. 29/10/2024 30/10/2024 AWS CLI Documentation 4 - Thi giữa kỳ (Ngày 31/10) - Hoàn thành mục tiêu quan trọng nhất. - Phản ánh sau kỳ thi về hiệu suất và các lĩnh vực cần cải thiện. 31/10/2024 31/10/2024 Địa điểm thi 5 - Bắt đầu triển khai chức năng CRUD cơ bản đầu tiên (Create operation: tạo flashcard sets). - Nghiên cứu và triển khai thử nghiệm AWS Lambda functions cho serverless compute. - Nghiên cứu thiết kế DynamoDB table để lưu trữ dữ liệu flashcard. 01/11/2024 01/11/2024 Tài liệu AWS Lambda \u0026amp; DynamoDB 6 - Lập kế hoạch tích hợp kiến trúc Serverless: + Nghiên cứu API Gateway cho RESTful API endpoints. + Thiết kế luồng dữ liệu: Frontend → API Gateway → Lambda → DynamoDB. + Định nghĩa cấu trúc Lambda function và event handling patterns. - Triển khai chức năng Read cơ bản để truy xuất flashcard sets từ DynamoDB. 02/11/2024 02/11/2024 Tài liệu API Gateway, Serverless patterns Kết quả đạt được tuần 8 Hoàn thành kỳ thi giữa kỳ (Ngày 31/10) thành công. Thiết lập thành công môi trường phát triển cơ bản cho dự án với Python, AWS CLI, và cấu hình IDE. Bắt đầu xây dựng chức năng Create/Read đầu tiên cho dự án Bandup IELTS sử dụng AWS Lambda và DynamoDB. Nghiên cứu và thiết kế serverless architecture pattern: API Gateway cho HTTP endpoints Lambda functions cho business logic DynamoDB cho NoSQL data storage Củng cố kiến thức về các dịch vụ Serverless thiết yếu (Lambda, DynamoDB, API Gateway) quan trọng cho phát triển dự án. Tạo cấu trúc dự án ban đầu với tổ chức thư mục phù hợp. Triển khai Lambda function handler đầu tiên cho Create operation. Bài học chính:\nKiến trúc Serverless loại bỏ overhead quản lý server Lambda functions là event-driven và scale tự động DynamoDB cung cấp độ trễ millisecond đơn cho NoSQL workloads API Gateway hoạt động như entry point cho serverless APIs Cấu trúc dự án phù hợp ngay từ đầu đơn giản hóa phát triển tương lai "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/5-workshop/5.8-cleanup/","title":"Dọn Dẹp Tài Nguyên","tags":[],"description":"","content":"Tổng Quan Phần này hướng dẫn bạn dọn dẹp tất cả tài nguyên AWS đã tạo trong workshop này để tránh các khoản phí phát sinh. Thực hiện theo thứ tự các bước vì một số tài nguyên phụ thuộc vào tài nguyên khác.\nQuan trọng: Việc xóa tài nguyên không thể hoàn tác. Hãy đảm bảo bạn đã sao lưu bất kỳ dữ liệu nào cần thiết trước khi tiếp tục.\nThời Gian Ước Tính: ~30 phút Bước 1: Xóa Tài Nguyên CI/CD Pipeline Đầu tiên, xóa CI/CD pipeline để dừng mọi deployment tự động.\nTruy cập console AWS CodePipeline Chọn pipeline của bạn (ví dụ: ielts-pipeline) Click Delete pipeline → Xác nhận xóa Truy cập console AWS CodeBuild Xóa tất cả build projects liên quan đến workshop Xóa bất kỳ S3 buckets nào được sử dụng cho pipeline artifacts Bước 2: Xóa ECS Services và Cluster Dừng và xóa tất cả ECS services trước khi xóa cluster.\nTruy cập console Amazon ECS Chọn cluster của bạn (ví dụ: ielts-cluster) Vào tab Services Với mỗi service: Chọn service Click Update → Đặt Desired tasks thành 0 → Update Chờ các running tasks dừng lại Click Delete service → Xác nhận Sau khi tất cả services đã xóa, quay lại Clusters Chọn cluster → Delete cluster → Xác nhận Bước 3: Xóa ECR Repositories Xóa container images và repositories.\nTruy cập console Amazon ECR Chọn từng repository: ielts-frontend ielts-backend Click Delete → Nhập tên repository để xác nhận Bước 4: Xóa Tài Nguyên AI Service Xóa các thành phần AI serverless theo thứ tự:\n4.1 Xóa Lambda Functions Truy cập console AWS Lambda Xóa từng function: writing-evaluator speaking-evaluator flashcard-generator evaluation-status s3-upload Chọn function → Actions → Delete → Xác nhận 4.2 Xóa API Gateway Truy cập console Amazon API Gateway Chọn API của bạn (ví dụ: ielts-ai-api) Click Actions → Delete API → Xác nhận 4.3 Xóa SQS Queues Truy cập console Amazon SQS Xóa từng queue: writing-evaluation-queue writing-evaluation-dlq speaking-evaluation-queue speaking-evaluation-dlq flashcard-generation-queue flashcard-generation-dlq Chọn queue → Delete → Xác nhận 4.4 Xóa DynamoDB Tables Truy cập console Amazon DynamoDB Xóa từng table: evaluations flashcard-sets Chọn table → Delete → Xác nhận xóa Bước 5: Xóa Tài Nguyên Load Balancer Truy cập console EC2 → Load Balancers Chọn ALB của bạn (ví dụ: ielts-alb) Click Actions → Delete → Xác nhận Vào Target Groups Xóa tất cả target groups liên quan đến workshop Vào Listeners và xóa bất kỳ listeners còn lại Bước 6: Xóa Tài Nguyên Database 6.1 Xóa RDS Instance Truy cập console Amazon RDS Chọn database instance của bạn Click Actions → Delete Bỏ chọn Create final snapshot (nếu không cần) Chọn I acknowledge\u0026hellip; → Delete Việc xóa RDS có thể mất 5-10 phút để hoàn thành.\n6.2 Xóa ElastiCache (Redis) Truy cập console Amazon ElastiCache Chọn Redis cluster của bạn Click Delete → Xác nhận 6.3 Xóa RDS Subnet Group Trong RDS console, vào Subnet groups Chọn subnet group của bạn → Delete Bước 7: Xóa S3 Buckets Truy cập console Amazon S3 Với mỗi bucket đã tạo trong workshop: ielts-audio-bucket ielts-documents-bucket Bất kỳ pipeline artifact buckets nào Chọn bucket → Empty → Xác nhận Sau khi làm trống, chọn bucket → Delete → Xác nhận S3 buckets phải được làm trống trước khi có thể xóa.\nBước 8: Xóa Secrets Manager Secrets Truy cập console AWS Secrets Manager Chọn từng secret đã tạo cho workshop Click Actions → Delete secret Đặt thời gian khôi phục thành 7 ngày (tối thiểu) hoặc chọn xóa ngay lập tức Xác nhận xóa Bước 9: Xóa Tài Nguyên CloudWatch Truy cập console Amazon CloudWatch Vào Log groups Xóa các log groups: /aws/lambda/writing-evaluator /aws/lambda/speaking-evaluator /aws/lambda/flashcard-generator /ecs/ielts-frontend /ecs/ielts-backend Vào Alarms và xóa bất kỳ alarms đã tạo Bước 10: Xóa VPC và Tài Nguyên Mạng Xóa tài nguyên mạng theo thứ tự cụ thể này:\n10.1 Xóa NAT Gateway Truy cập console VPC → NAT Gateways Chọn NAT Gateway của bạn Click Actions → Delete NAT gateway → Xác nhận Chờ trạng thái chuyển thành Deleted 10.2 Giải Phóng Elastic IPs Vào Elastic IPs Chọn bất kỳ Elastic IPs nào liên kết với NAT Gateway Click Actions → Release Elastic IP addresses → Xác nhận 10.3 Xóa VPC Endpoints Vào Endpoints Chọn tất cả VPC endpoints đã tạo cho workshop Click Actions → Delete VPC endpoints → Xác nhận 10.4 Xóa Security Groups Vào Security Groups Xóa security groups theo thứ tự này (do phụ thuộc): Application security groups trước Database security groups Load balancer security groups Không xóa default security group 10.5 Xóa Subnets Vào Subnets Chọn tất cả subnets trong workshop VPC của bạn Click Actions → Delete subnet → Xác nhận 10.6 Xóa Route Tables Vào Route Tables Xóa custom route tables (không phải main route table) Chọn route table → Actions → Delete route table 10.7 Xóa Internet Gateway Vào Internet Gateways Chọn IGW → Actions → Detach from VPC → Xác nhận Chọn lại IGW → Actions → Delete internet gateway → Xác nhận 10.8 Xóa VPC Vào Your VPCs Chọn workshop VPC của bạn Click Actions → Delete VPC → Xác nhận Bước 11: Xóa Tài Nguyên IAM Truy cập console IAM Vào Roles và xóa: ecsTaskExecutionRole (nếu được tạo cho workshop này) ielts-lambda-execution-role Bất kỳ roles cụ thể nào khác của workshop Vào Policies và xóa custom policies đã tạo cho workshop Cẩn thận không xóa tài nguyên IAM được sử dụng bởi các ứng dụng khác.\nDanh Sách Kiểm Tra Xác Minh Sau khi hoàn thành dọn dẹp, xác minh tất cả tài nguyên đã được xóa:\nTài Nguyên Console Dịch Vụ Trạng Thái CodePipeline CodePipeline ☐ Đã xóa ECS Cluster ECS ☐ Đã xóa ECR Repositories ECR ☐ Đã xóa Lambda Functions Lambda ☐ Đã xóa API Gateway API Gateway ☐ Đã xóa SQS Queues SQS ☐ Đã xóa DynamoDB Tables DynamoDB ☐ Đã xóa Load Balancer EC2 ☐ Đã xóa RDS Instance RDS ☐ Đã xóa ElastiCache ElastiCache ☐ Đã xóa S3 Buckets S3 ☐ Đã xóa Secrets Secrets Manager ☐ Đã xóa CloudWatch Logs CloudWatch ☐ Đã xóa NAT Gateway VPC ☐ Đã xóa VPC VPC ☐ Đã xóa IAM Roles IAM ☐ Đã xóa Xác Minh Chi Phí Để đảm bảo không có khoản phí bất ngờ:\nVào console AWS Billing Kiểm tra Bills cho tháng hiện tại Xem Cost Explorer để xác minh không còn tài nguyên hoạt động Thiết lập Budget alert nếu bạn có kế hoạch tiếp tục sử dụng AWS Chờ 24-48 giờ và kiểm tra lại billing dashboard để xác nhận tất cả tài nguyên đã được dọn dẹp và không có khoản phí nào đang phát sinh.\n"},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9 Hoàn tất quá trình chuyển đổi sang framework phát triển AWS SAM (Serverless Application Model). Tái cấu trúc (Refactor) và triển khai lại các chức năng CRUD theo patterns kiến trúc SAM. Giải quyết các vấn đề liên quan đến môi trường để đạt được trạng thái triển khai thành công lên AWS. Tích hợp Docker cho môi trường build chuẩn hóa và quản lý dependencies. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu chuyên sâu về AWS SAM: Hiểu cấu trúc template.yaml, SAM CLI commands, và cách các tài nguyên Serverless (Lambda, API Gateway) hoạt động trong mô hình SAM. - Lập kế hoạch chiến lược migration: Chuyển đổi các Lambda functions hiện có sang cấu trúc tương thích SAM. - Nghiên cứu khả năng SAM local testing (sam local invoke, sam local start-api). 04/11/2024 04/11/2024 Tài liệu AWS SAM, AWS Study Group 3 - Tái cấu trúc mã nguồn: Viết lại các chức năng CRUD (Create/Read operations) sử dụng SAM patterns (Lambda handlers và API Gateway events). - Tích hợp Docker: Cài đặt và cấu hình Docker để đảm bảo môi trường Python runtime nhất quán cho quá trình sam build. - Tạo Dockerfile cho Lambda layer dependencies. 05/11/2024 06/11/2024 Tài liệu Docker, SAM CLI 4 - Gỡ lỗi và kiểm thử Local: Thực hiện sam local invoke để test các Lambda functions riêng lẻ. - Gặp sự cố nghiêm trọng trong môi trường Local: Dependency conflicts, Python version mismatches, vấn đề kết nối DynamoDB local. - Cố gắng giải quyết các rào cản local testing thông qua điều chỉnh cấu hình. 06/11/2024 07/11/2024 Báo cáo lỗi SAM CLI, Stack Overflow 5 - Ra quyết định chiến lược: Backend Team quyết định áp dụng chiến lược deploy-then-test trên môi trường AWS thực tế để vượt qua các hạn chế gỡ lỗi Local, chấp nhận rủi ro đã tính toán. - Tập trung khắc phục các lỗi cấu hình trong template.yaml (resource definitions, IAM permissions, environment variables). - Xác thực SAM template syntax và resource dependencies. 07/11/2024 08/11/2024 CloudFormation Template Validator 6 - Triển khai thành công: Thực hiện sam deploy --guided và triển khai thành công dự án lên môi trường AWS. - Xác thực cơ bản: Kiểm tra các API endpoints đã tạo bằng Postman/curl, xác nhận chức năng CRUD đã hoạt động. - Ghi lại quy trình triển khai và cấu hình cho team tham khảo. 08/11/2024 08/11/2024 Log triển khai AWS CloudFormation Kết quả đạt được tuần 9 Hoàn thành chuyển đổi công nghệ sang mô hình phát triển AWS SAM cho toàn bộ dự án. Tái cấu trúc thành công các chức năng CRUD vào cấu trúc Serverless của SAM với tổ chức handler phù hợp. Đã giải quyết vấn đề môi trường bằng cách sử dụng Docker để đảm bảo quá trình sam build sử dụng đúng Python version và dependencies. Đạt được cột mốc quan trọng: Triển khai thành công dự án lên môi trường AWS, vượt qua các trục trặc gỡ lỗi Local. Dự án Bandup IELTS hiện có phiên bản API hoạt động trên môi trường Cloud thực tế (mặc dù vẫn cần kiểm thử sâu hơn). Thiết lập deployment workflow và best practices cho hợp tác team. Tạo template.yaml toàn diện với resource definitions và IAM permissions phù hợp. Bài học chính:\nSAM đơn giản hóa phát triển serverless application với infrastructure as code Docker đảm bảo môi trường build nhất quán across các máy phát triển khác nhau Chiến lược deploy-then-test có thể khả thi khi local testing có vấn đề SAM templates cung cấp single source of truth cho serverless infrastructure IAM permissions phù hợp trong SAM templates là cực kỳ quan trọng cho Lambda function execution "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10 Ổn định môi trường triển khai AWS SAM/Serverless và giải quyết các vấn đề quan trọng. Tập trung gỡ lỗi các vấn đề cốt lõi: Cấu hình CORS, template validation errors, và định dạng API response. Tích hợp Frontend/Backend để cho phép kiểm thử end-to-end trên giao diện người dùng. Hoàn thiện các chức năng Read và Delete cơ bản với error handling phù hợp. Tham gia sự kiện AWS Cloud Mastery Series để nhận hướng dẫn chuyên gia và giải quyết thách thức dự án. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Gỡ lỗi CORS: Phân tích cấu hình CORS trong API Gateway (CORS headers, preflight OPTIONS requests) và Lambda response headers để cho phép Frontend truy cập. - Khắc phục template validation errors: Rà soát và tối ưu file template.yaml để tránh deployment loop errors và resource dependency issues trong sam deploy. 11/11/2024 11/11/2024 Tài liệu API Gateway/CORS 3 - Củng cố chức năng Read (Truy xuất flashcard sets): Đảm bảo dữ liệu được query từ DynamoDB chính xác và trả về đúng định dạng JSON cho Frontend consumption. - Triển khai error handling cho missing records và invalid queries. - Thêm logging cho mục đích debugging. 12/11/2024 12/11/2024 Tài liệu DynamoDB Query 4 - Tích hợp Frontend: Bắt đầu kết hợp Frontend codebase với dự án và test các API endpoints đã deploy. - Thành công hiển thị danh sách flashcard sets trên giao diện người dùng. - Kiểm thử kết nối API và data rendering trong React/Vue components. 13/11/2024 13/11/2024 Tài liệu Frontend Framework 5 - Triển khai và kiểm thử chức năng Delete (Xóa flashcard sets). - Gặp lỗi: Xác định vấn đề authorization với Cognito User Sub ID khi thực hiện Delete function - Lambda không thể extract/process Sub ID từ Cognito token chính xác. - Bắt đầu troubleshooting authentication flow. 14/11/2024 14/11/2024 Tài liệu AWS Cognito 6 - Tham gia sự kiện AWS Cloud Mastery Series: + Nhận hướng dẫn chuyên gia và giải đáp các câu hỏi về Serverless architecture, Lambda best practices, và authentication patterns. - Phân tích lỗi Update/Delete: Áp dụng hướng dẫn từ Mentor để giải quyết vấn đề authorization và Cognito token parsing problems. - Ghi lại các giải pháp để tham khảo trong tương lai. 15/11/2024 15/11/2024 Mentor, AWS Cloud Mastery Series Kết quả đạt được tuần 10 Khắc phục thành công lỗi CORS và ổn định quá trình triển khai SAM (giảm thiểu template validation errors). Tham gia sự kiện AWS Cloud Mastery Series và thu thập thông tin thiết yếu để giải quyết các blockers lớn của dự án. Hoàn thành tích hợp Frontend và Backend, đạt được giao diện người dùng chức năng đầu tiên cho kiểm thử end-to-end. Đã triển khai thành công chức năng Read (Truy xuất flashcard sets) và Delete (Xóa flashcard sets), hoạt động trên giao diện web. Xác định và có hướng giải quyết cho các điểm nghẽn quan trọng: Lỗi authorization: Lambda không thể lấy/xử lý không đúng Cognito Sub ID từ JWT token, ảnh hưởng đến các thao tác cần quyền Dependency chức năng Update: Yêu cầu authentication flow phù hợp và token validation Dự án đã chuyển sang giai đoạn kiểm thử người dùng cơ bản với các thao tác CRUD hoạt động. Thiết lập debugging workflow và error handling patterns cho team. Bài học chính:\nCORS yêu cầu cấu hình phù hợp trong cả API Gateway và Lambda response headers Cognito JWT tokens phải được decode đúng cách để extract user identity (Sub ID) Tích hợp Frontend-Backend yêu cầu chú ý cẩn thận đến API contracts và data formats Error handling và logging là thiết yếu cho debugging production issues AWS Cloud Mastery Series cung cấp insights thực tế quý giá từ các practitioners giàu kinh nghiệm "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tham gia sự kiện AWS Cloud Mastery Series #2 để tiếp tục giải đáp các vấn đề kỹ thuật chuyên sâu. Tái cấu trúc và thống nhất cấu trúc Frontend để tăng tính ổn định và dễ bảo trì. Triển khai kiến trúc Multi-Stack để tối ưu hóa tốc độ triển khai và quản lý dự án Serverless. Tích hợp các chức năng CRUD cơ bản với AI Image Processing (sử dụng Rekognition) vào trang web. Khắc phục triệt để các lỗi triển khai (đặc biệt là lỗi CORS) để ổn định hệ thống. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu CN - Tham gia sự kiện AWS Cloud Mastery Series #2 (Ngày 17/11): Tiếp tục nhận hướng dẫn và giải đáp thắc mắc chuyên sâu hơn về lỗi xác thực và luồng AI. 17/11/2024 17/11/2024 Mentor, AWS Cloud Mastery Series 2 - Thống nhất và tái cấu trúc Frontend: Tiến hành họp nhóm để thống nhất lại cấu trúc code Frontend nhằm đảm bảo tính đồng bộ và dễ bảo trì. - Nghiên cứu giải pháp Multi-Stack: Bắt đầu phân tích cách tách file template.yaml thành các Stack nhỏ hơn (Multi-Stack) để tối ưu hóa quá trình sam deploy. 18/11/2024 18/11/2024 Tài liệu Kiến trúc Serverless 3 - Triển khai kiến trúc Multi-Stack: Bắt đầu tách và cấu hình các Stack riêng biệt (như Stack cho Backend API, Stack cho Frontend Hosting). - Tiến hành tích hợp AI Image Processing: Kết hợp các chức năng CRUD cơ bản với logic xử lý ảnh (ví dụ: gọi API Rekognition/S3 trigger) để chuẩn bị cho chức năng Update. 19/11/2024 19/11/2024 Codebase Backend, AWS Rekognition 4 - Gặp lỗi sau khi tích hợp AI: Hệ thống tiếp tục gặp lỗi sau khi kết hợp chức năng AI, yêu cầu phải xóa Stack cũ và Deploy lại hoàn toàn. - Leader phát triển Stack dự phòng: Leader tạo một Stack Multi-Stack riêng biệt, đã tối ưu hóa, để dự phòng và làm tham chiếu cho việc triển khai tối ưu hóa sau này. 20/11/2024 20/11/2024 Stack dự phòng của Leader 5 - Lỗi CORS tái diễn: Sau khi deploy lại, hệ thống tiếp tục gặp lỗi CORS. - Gỡ lỗi CORS chuyên sâu: Dành thời gian phân tích triệt để nguyên nhân gốc rễ và sửa chữa dứt điểm lỗi CORS, đảm bảo các headers phản hồi được cấu hình chính xác trên cả API Gateway và Lambda. 21/11/2024 21/11/2024 Cấu hình API Gateway/Lambda 6 - Họp bàn và ổn định hóa dự án: Họp nhóm để kiểm tra cấu trúc Frontend mới, ổn định lại Stack dự án chính và đồng bộ hóa các bản sửa lỗi CORS và Template. - Tối ưu hóa bảo trì: Đưa ra giải pháp sử dụng Stack riêng (do leader phát triển) để đảm bảo tính linh hoạt và dễ tối ưu hóa trong quá trình phát triển tiếp theo. 22/11/2024 22/11/2024 Báo cáo cấu trúc mới Kết quả đạt được tuần 11: Tham gia chuỗi sự kiện AWS Cloud Mastery Series #2, thu thập thêm kiến thức sâu hơn về Serverless, Rekognition, và giải pháp cho các lỗi xác thực. Tái cấu trúc thành công Frontend và thống nhất được cấu trúc chung cho dự án, cải thiện khả năng bảo trì. Triển khai kiến trúc Multi-Stack (hoặc ít nhất là có giải pháp/Stack dự phòng) giúp đẩy nhanh quá trình deploy và dễ dàng quản lý tài nguyên. Khắc phục được triệt để lỗi CORS sau khi tìm ra nguyên nhân gốc rễ, đảm bảo đường truyền giữa Frontend và Backend ổn định. Lĩnh hội được cách khắc phục các lỗi Template cơ bản và hiểu rõ hơn về các vấn đề triển khai trên AWS SAM. Phát triển thêm Stack riêng biệt để dự phòng/tối ưu hóa, tăng tính linh hoạt và an toàn cho dự án trong các lần cập nhật lớn sau này. Dự án đã bước vào giai đoạn thử nghiệm chức năng AI, mặc dù vẫn còn lỗi, nhưng đã có hướng đi rõ ràng để gỡ rối. "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn thiện 100% các chức năng CRUD cơ bản và AI xử lý ảnh (bao gồm chức năng Update). Nâng cấp kiến trúc xử lý ảnh bằng cách tích hợp SQS để phân luồng và xử lý bất đồng bộ. Hoàn thành các tính năng thiết yếu cuối cùng của dự án: Bảo mật, Ghim Map, và SNS. Hoàn thiện các giao diện chính của Frontend, chuẩn bị mua tên miền và tham gia sự kiện AWS Cloud Mastery Series cuối cùng. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hoàn thiện chức năng Update và AI: Khắc phục triệt để các lỗi cuối cùng (Sub ID, Rekognition) để chức năng CRUD và xử lý ảnh hoạt động trọn vẹn. 25/11/2024 25/11/2024 Hướng dẫn Mentor, Codebase Backend 3 - Nâng cấp luồng AI với SQS: Triển khai AWS SQS để tạo hàng đợi xử lý ảnh bất đồng bộ, giúp phân luồng và cải thiện hiệu suất khi lượng ảnh tải lên lớn. - Tạo luồng xử lý rõ ràng: Định nghĩa lại luồng đi của dữ liệu (Upload -\u0026gt; S3 -\u0026gt; SQS -\u0026gt; Lambda (AI) -\u0026gt; DynamoDB). 26/11/2024 26/11/2024 Tài liệu AWS SQS, Kiến trúc Lambda 4 - Frontend hoàn thiện giao diện: Hoàn tất các giao diện cho các trang chính (Homepage, Chi tiết bài viết, Trang quản lý cá nhân). - Triển khai Ghim Map: Tích hợp chức năng Ghim Map (Map Pinning) cho các bài viết, sử dụng dữ liệu định vị (geo data) trong DynamoDB hoặc một dịch vụ map phù hợp. 27/11/2024 27/11/2024 Codebase Frontend, DynamoDB Geo 5 - Hoàn thiện Bảo mật (Authorization): Tối ưu hóa việc xác thực và phân quyền (IAM Policy/Cognito), đặc biệt là việc lấy Sub chính xác cho các thao tác của người dùng. - Triển khai SNS: Tích hợp AWS SNS cho các tính năng thông báo cơ bản (ví dụ: thông báo khi bài viết được xử lý xong/tải lên thành công). 28/11/2024 28/11/2024 Tài liệu AWS SNS, Cognito/IAM 6 - Tham gia sự kiện AWS Cloud Mastery Series cuối cùng: Nhận hướng dẫn tổng thể về dự án, kiểm tra và hoàn thiện các phần còn thiếu (tên miền, bảo mật, SNS) trước khi demo. - Tên miền: Tiến hành nghiên cứu và chuẩn bị mua tên miền cho trang web, cấu hình DNS cơ bản (Route 53) nếu cần thiết (dựa trên hướng dẫn mentor). 29/11/2024 29/11/2024 Mentor, AWS Cloud Mastery Series, Route 53 Kết quả đạt được tuần 12: Hoàn thành 100% các chức năng CRUD cơ bản và AI xử lý ảnh, đảm bảo tính ổn định của hệ thống. Nâng cấp kiến trúc xử lý ảnh bằng cách tích hợp SQS và xác định các luồng xử lý bất đồng bộ rõ ràng, cải thiện hiệu suất và độ tin cậy. Hoàn thiện các tính năng thiết yếu: Đã triển khai Bảo mật, Ghim Map và thông báo bằng SNS. Giao diện Frontend cơ bản đã hoàn thiện, sẵn sàng cho việc trình bày. Tham gia thành công sự kiện AWS Cloud Mastery Series cuối cùng, nhận được hướng dẫn tổng thể để hoàn thiện dự án. Đã nghiên cứu và lên kế hoạch mua tên miền cho sản phẩm. Dự án đã đạt đến trạng thái Sẵn sàng trình bày (Demo Readiness). "},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://nhatanhaxtanh.github.io/nhatanh/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]